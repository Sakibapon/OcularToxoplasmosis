{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f95f0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865f0638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Laptop GPU, compute capability 8.6\n",
      "WARNING:tensorflow:From C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\mixed_precision\\loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca79c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:/Ocular toxoplasmosis binzarized/Oculur Toxoplasmosis/train_augmented\"\n",
    "test_dir = \"D:/Ocular toxoplasmosis binzarized/Oculur Toxoplasmosis/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2d3b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3659 images belonging to 2 classes.\n",
      "Found 83 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "input_shape = (112, 112)\n",
    "\n",
    "datagen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False)\n",
    "\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)\n",
    "steps_per_epoch = generator_train.n / batch_size\n",
    "steps_test = generator_test.n / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f9cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(model):\n",
    "    transfer_layer = model.get_layer(model.get_layer(index = -1).name)\n",
    "    conv_model = Model(inputs=model.input, outputs=transfer_layer.output)\n",
    "    new_model = Sequential()\n",
    "    new_model.add(conv_model)\n",
    "    new_model.add(Flatten())\n",
    "    new_model.add(Dense(2, activation='softmax'))\n",
    "    optimizer = Adam(lr=1e-5)\n",
    "    loss = 'categorical_crossentropy'\n",
    "    metrics = ['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "    new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dd9867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12048\\183852360.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_vgg19 = vgg19.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 133s 550ms/step - loss: 0.3248 - categorical_accuracy: 0.8573 - precision: 0.8573 - recall: 0.8568 - auc: 0.9350 - val_loss: 0.4029 - val_categorical_accuracy: 0.8072 - val_precision: 0.8072 - val_recall: 0.8072 - val_auc: 0.9189\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 123s 539ms/step - loss: 0.1355 - categorical_accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9887 - val_loss: 0.1868 - val_categorical_accuracy: 0.9398 - val_precision: 0.9398 - val_recall: 0.9398 - val_auc: 0.9797\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 126s 549ms/step - loss: 0.0822 - categorical_accuracy: 0.9667 - precision: 0.9669 - recall: 0.9667 - auc: 0.9960 - val_loss: 0.2877 - val_categorical_accuracy: 0.8795 - val_precision: 0.8795 - val_recall: 0.8795 - val_auc: 0.9591\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 127s 556ms/step - loss: 0.0532 - categorical_accuracy: 0.9822 - precision: 0.9822 - recall: 0.9822 - auc: 0.9983 - val_loss: 0.4998 - val_categorical_accuracy: 0.8434 - val_precision: 0.8434 - val_recall: 0.8434 - val_auc: 0.9294\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 126s 548ms/step - loss: 0.0464 - categorical_accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850 - auc: 0.9985 - val_loss: 0.9897 - val_categorical_accuracy: 0.7590 - val_precision: 0.7590 - val_recall: 0.7590 - val_auc: 0.8437\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 126s 550ms/step - loss: 0.0283 - categorical_accuracy: 0.9893 - precision: 0.9893 - recall: 0.9893 - auc: 0.9995 - val_loss: 1.1505 - val_categorical_accuracy: 0.7952 - val_precision: 0.7952 - val_recall: 0.7952 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 127s 555ms/step - loss: 0.0191 - categorical_accuracy: 0.9918 - precision: 0.9918 - recall: 0.9918 - auc: 0.9998 - val_loss: 0.6664 - val_categorical_accuracy: 0.8916 - val_precision: 0.8916 - val_recall: 0.8916 - val_auc: 0.9184\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - 125s 548ms/step - loss: 0.0258 - categorical_accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - auc: 0.9996 - val_loss: 0.5188 - val_categorical_accuracy: 0.9036 - val_precision: 0.9036 - val_recall: 0.9036 - val_auc: 0.9599\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - 126s 551ms/step - loss: 0.0097 - categorical_accuracy: 0.9967 - precision: 0.9967 - recall: 0.9967 - auc: 1.0000 - val_loss: 0.8580 - val_categorical_accuracy: 0.8434 - val_precision: 0.8434 - val_recall: 0.8434 - val_auc: 0.8985\n",
      "Epoch 10/10\n",
      "228/228 [==============================] - 125s 548ms/step - loss: 0.0199 - categorical_accuracy: 0.9921 - precision: 0.9921 - recall: 0.9921 - auc: 0.9995 - val_loss: 0.8011 - val_categorical_accuracy: 0.8795 - val_precision: 0.8795 - val_recall: 0.8795 - val_auc: 0.8942\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.VGG19(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "vgg19 = model_creator(model)\n",
    "history_vgg19 = vgg19.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9045cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12048\\576356427.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_inception = inception.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 138s 556ms/step - loss: 0.5944 - categorical_accuracy: 0.6816 - precision_1: 0.6815 - recall_1: 0.6813 - auc_1: 0.7533 - val_loss: 0.7951 - val_categorical_accuracy: 0.5904 - val_precision_1: 0.5904 - val_recall_1: 0.5904 - val_auc_1: 0.6564\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 123s 540ms/step - loss: 0.4183 - categorical_accuracy: 0.8019 - precision_1: 0.8018 - recall_1: 0.8016 - auc_1: 0.8893 - val_loss: 0.9222 - val_categorical_accuracy: 0.6988 - val_precision_1: 0.6988 - val_recall_1: 0.6988 - val_auc_1: 0.7329\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 124s 541ms/step - loss: 0.3282 - categorical_accuracy: 0.8554 - precision_1: 0.8554 - recall_1: 0.8552 - auc_1: 0.9353 - val_loss: 1.3350 - val_categorical_accuracy: 0.7470 - val_precision_1: 0.7470 - val_recall_1: 0.7470 - val_auc_1: 0.7805\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 124s 539ms/step - loss: 0.2847 - categorical_accuracy: 0.8737 - precision_1: 0.8737 - recall_1: 0.8735 - auc_1: 0.9511 - val_loss: 1.6410 - val_categorical_accuracy: 0.7711 - val_precision_1: 0.7711 - val_recall_1: 0.7711 - val_auc_1: 0.7846\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 124s 540ms/step - loss: 0.2565 - categorical_accuracy: 0.8983 - precision_1: 0.8991 - recall_1: 0.8983 - auc_1: 0.9602 - val_loss: 1.5429 - val_categorical_accuracy: 0.7952 - val_precision_1: 0.7952 - val_recall_1: 0.7952 - val_auc_1: 0.8123\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 123s 538ms/step - loss: 0.2211 - categorical_accuracy: 0.9090 - precision_1: 0.9090 - recall_1: 0.9090 - auc_1: 0.9708 - val_loss: 1.3548 - val_categorical_accuracy: 0.7831 - val_precision_1: 0.7831 - val_recall_1: 0.7831 - val_auc_1: 0.8219\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 124s 540ms/step - loss: 0.1970 - categorical_accuracy: 0.9183 - precision_1: 0.9183 - recall_1: 0.9183 - auc_1: 0.9769 - val_loss: 2.2747 - val_categorical_accuracy: 0.7590 - val_precision_1: 0.7590 - val_recall_1: 0.7590 - val_auc_1: 0.7926\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - 124s 540ms/step - loss: 0.1668 - categorical_accuracy: 0.9369 - precision_1: 0.9369 - recall_1: 0.9369 - auc_1: 0.9834 - val_loss: 1.5161 - val_categorical_accuracy: 0.7711 - val_precision_1: 0.7711 - val_recall_1: 0.7711 - val_auc_1: 0.8095\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - 125s 544ms/step - loss: 0.1615 - categorical_accuracy: 0.9366 - precision_1: 0.9366 - recall_1: 0.9366 - auc_1: 0.9838 - val_loss: 1.5067 - val_categorical_accuracy: 0.7590 - val_precision_1: 0.7590 - val_recall_1: 0.7590 - val_auc_1: 0.8017\n",
      "Epoch 10/10\n",
      "228/228 [==============================] - 125s 545ms/step - loss: 0.1383 - categorical_accuracy: 0.9494 - precision_1: 0.9494 - recall_1: 0.9494 - auc_1: 0.9885 - val_loss: 2.0120 - val_categorical_accuracy: 0.8193 - val_precision_1: 0.8193 - val_recall_1: 0.8193 - val_auc_1: 0.8069\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.InceptionV3(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "inception = model_creator(model)\n",
    "history_inception = inception.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d80df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12048\\789522733.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_mobile = mobile.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 129s 545ms/step - loss: 0.7890 - categorical_accuracy: 0.6999 - precision_2: 0.6998 - recall_2: 0.6996 - auc_2: 0.7685 - val_loss: 0.9343 - val_categorical_accuracy: 0.6506 - val_precision_2: 0.6506 - val_recall_2: 0.6506 - val_auc_2: 0.7639\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 122s 533ms/step - loss: 0.4853 - categorical_accuracy: 0.8221 - precision_2: 0.8221 - recall_2: 0.8221 - auc_2: 0.8986 - val_loss: 0.7298 - val_categorical_accuracy: 0.7470 - val_precision_2: 0.7470 - val_recall_2: 0.7470 - val_auc_2: 0.8122\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 122s 534ms/step - loss: 0.4050 - categorical_accuracy: 0.8516 - precision_2: 0.8516 - recall_2: 0.8516 - auc_2: 0.9278 - val_loss: 0.7173 - val_categorical_accuracy: 0.7470 - val_precision_2: 0.7470 - val_recall_2: 0.7470 - val_auc_2: 0.8334\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 125s 545ms/step - loss: 0.3462 - categorical_accuracy: 0.8762 - precision_2: 0.8762 - recall_2: 0.8762 - auc_2: 0.9443 - val_loss: 0.6121 - val_categorical_accuracy: 0.7952 - val_precision_2: 0.7952 - val_recall_2: 0.7952 - val_auc_2: 0.8679\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 123s 538ms/step - loss: 0.2880 - categorical_accuracy: 0.9002 - precision_2: 0.9002 - recall_2: 0.9002 - auc_2: 0.9580 - val_loss: 0.6283 - val_categorical_accuracy: 0.7831 - val_precision_2: 0.7831 - val_recall_2: 0.7831 - val_auc_2: 0.8752\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 124s 541ms/step - loss: 0.2697 - categorical_accuracy: 0.9057 - precision_2: 0.9057 - recall_2: 0.9057 - auc_2: 0.9625 - val_loss: 0.5966 - val_categorical_accuracy: 0.7831 - val_precision_2: 0.7831 - val_recall_2: 0.7831 - val_auc_2: 0.8880\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 124s 539ms/step - loss: 0.2070 - categorical_accuracy: 0.9210 - precision_2: 0.9210 - recall_2: 0.9210 - auc_2: 0.9757 - val_loss: 0.5339 - val_categorical_accuracy: 0.7952 - val_precision_2: 0.7952 - val_recall_2: 0.7952 - val_auc_2: 0.9058\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - 127s 555ms/step - loss: 0.2051 - categorical_accuracy: 0.9273 - precision_2: 0.9275 - recall_2: 0.9270 - auc_2: 0.9766 - val_loss: 0.6098 - val_categorical_accuracy: 0.7952 - val_precision_2: 0.7952 - val_recall_2: 0.7952 - val_auc_2: 0.9002\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - 126s 550ms/step - loss: 0.1767 - categorical_accuracy: 0.9366 - precision_2: 0.9366 - recall_2: 0.9366 - auc_2: 0.9814 - val_loss: 0.6130 - val_categorical_accuracy: 0.8193 - val_precision_2: 0.8193 - val_recall_2: 0.8193 - val_auc_2: 0.9096\n",
      "Epoch 10/10\n",
      "228/228 [==============================] - 128s 560ms/step - loss: 0.1746 - categorical_accuracy: 0.9374 - precision_2: 0.9374 - recall_2: 0.9374 - auc_2: 0.9828 - val_loss: 0.6293 - val_categorical_accuracy: 0.8193 - val_precision_2: 0.8193 - val_recall_2: 0.8193 - val_auc_2: 0.9104\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.MobileNet(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "mobile = model_creator(model)\n",
    "history_mobile = mobile.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf476612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12048\\3413688818.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_dense = dense.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 150s 583ms/step - loss: 0.5650 - categorical_accuracy: 0.7406 - precision_3: 0.7408 - recall_3: 0.7406 - auc_3: 0.8226 - val_loss: 0.4172 - val_categorical_accuracy: 0.8072 - val_precision_3: 0.8072 - val_recall_3: 0.8072 - val_auc_3: 0.8928\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 129s 562ms/step - loss: 0.3182 - categorical_accuracy: 0.8650 - precision_3: 0.8650 - recall_3: 0.8647 - auc_3: 0.9397 - val_loss: 0.3204 - val_categorical_accuracy: 0.8795 - val_precision_3: 0.8795 - val_recall_3: 0.8795 - val_auc_3: 0.9353\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 129s 565ms/step - loss: 0.2227 - categorical_accuracy: 0.9082 - precision_3: 0.9084 - recall_3: 0.9079 - auc_3: 0.9695 - val_loss: 0.2999 - val_categorical_accuracy: 0.9036 - val_precision_3: 0.9036 - val_recall_3: 0.9036 - val_auc_3: 0.9501\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 129s 564ms/step - loss: 0.1877 - categorical_accuracy: 0.9248 - precision_3: 0.9248 - recall_3: 0.9248 - auc_3: 0.9783 - val_loss: 0.2637 - val_categorical_accuracy: 0.9157 - val_precision_3: 0.9157 - val_recall_3: 0.9157 - val_auc_3: 0.9599\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 130s 566ms/step - loss: 0.1301 - categorical_accuracy: 0.9535 - precision_3: 0.9535 - recall_3: 0.9535 - auc_3: 0.9895 - val_loss: 0.2722 - val_categorical_accuracy: 0.9036 - val_precision_3: 0.9036 - val_recall_3: 0.9036 - val_auc_3: 0.9605\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 129s 564ms/step - loss: 0.1097 - categorical_accuracy: 0.9617 - precision_3: 0.9617 - recall_3: 0.9617 - auc_3: 0.9925 - val_loss: 0.2736 - val_categorical_accuracy: 0.8916 - val_precision_3: 0.8916 - val_recall_3: 0.8916 - val_auc_3: 0.9657\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 126s 552ms/step - loss: 0.0958 - categorical_accuracy: 0.9626 - precision_3: 0.9626 - recall_3: 0.9626 - auc_3: 0.9944 - val_loss: 0.2693 - val_categorical_accuracy: 0.9036 - val_precision_3: 0.9036 - val_recall_3: 0.9036 - val_auc_3: 0.9655\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - 125s 544ms/step - loss: 0.0764 - categorical_accuracy: 0.9719 - precision_3: 0.9719 - recall_3: 0.9719 - auc_3: 0.9968 - val_loss: 0.3066 - val_categorical_accuracy: 0.8916 - val_precision_3: 0.8916 - val_recall_3: 0.8916 - val_auc_3: 0.9623\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - 124s 540ms/step - loss: 0.0708 - categorical_accuracy: 0.9740 - precision_3: 0.9740 - recall_3: 0.9740 - auc_3: 0.9970 - val_loss: 0.2480 - val_categorical_accuracy: 0.9036 - val_precision_3: 0.9036 - val_recall_3: 0.9036 - val_auc_3: 0.9740\n",
      "Epoch 10/10\n",
      "228/228 [==============================] - 125s 544ms/step - loss: 0.0558 - categorical_accuracy: 0.9820 - precision_3: 0.9820 - recall_3: 0.9820 - auc_3: 0.9980 - val_loss: 0.3250 - val_categorical_accuracy: 0.8916 - val_precision_3: 0.8916 - val_recall_3: 0.8916 - val_auc_3: 0.9593\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.DenseNet121(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "dense = model_creator(model)\n",
    "history_dense = dense.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5772e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12048\\28214634.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_xcep = xcep.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 136s 563ms/step - loss: 0.5511 - categorical_accuracy: 0.7037 - precision_4: 0.7039 - recall_4: 0.7035 - auc_4: 0.7880 - val_loss: 0.4808 - val_categorical_accuracy: 0.7711 - val_precision_4: 0.7683 - val_recall_4: 0.7590 - val_auc_4: 0.8645\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 127s 555ms/step - loss: 0.3380 - categorical_accuracy: 0.8598 - precision_4: 0.8598 - recall_4: 0.8595 - auc_4: 0.9381 - val_loss: 0.3917 - val_categorical_accuracy: 0.8193 - val_precision_4: 0.8193 - val_recall_4: 0.8193 - val_auc_4: 0.9049\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 127s 556ms/step - loss: 0.2360 - categorical_accuracy: 0.9098 - precision_4: 0.9098 - recall_4: 0.9098 - auc_4: 0.9705 - val_loss: 0.4301 - val_categorical_accuracy: 0.7952 - val_precision_4: 0.7952 - val_recall_4: 0.7952 - val_auc_4: 0.8941\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 126s 549ms/step - loss: 0.1831 - categorical_accuracy: 0.9325 - precision_4: 0.9328 - recall_4: 0.9325 - auc_4: 0.9814 - val_loss: 0.4271 - val_categorical_accuracy: 0.7952 - val_precision_4: 0.7952 - val_recall_4: 0.7952 - val_auc_4: 0.9060\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 129s 564ms/step - loss: 0.1463 - categorical_accuracy: 0.9475 - precision_4: 0.9475 - recall_4: 0.9475 - auc_4: 0.9878 - val_loss: 0.4328 - val_categorical_accuracy: 0.8313 - val_precision_4: 0.8313 - val_recall_4: 0.8313 - val_auc_4: 0.9115\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 128s 559ms/step - loss: 0.1219 - categorical_accuracy: 0.9546 - precision_4: 0.9546 - recall_4: 0.9546 - auc_4: 0.9915 - val_loss: 0.4152 - val_categorical_accuracy: 0.8434 - val_precision_4: 0.8434 - val_recall_4: 0.8434 - val_auc_4: 0.9239\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 129s 564ms/step - loss: 0.1040 - categorical_accuracy: 0.9606 - precision_4: 0.9606 - recall_4: 0.9606 - auc_4: 0.9934 - val_loss: 0.4082 - val_categorical_accuracy: 0.8675 - val_precision_4: 0.8675 - val_recall_4: 0.8675 - val_auc_4: 0.9316\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - 127s 557ms/step - loss: 0.0890 - categorical_accuracy: 0.9664 - precision_4: 0.9664 - recall_4: 0.9661 - auc_4: 0.9957 - val_loss: 0.4138 - val_categorical_accuracy: 0.8554 - val_precision_4: 0.8554 - val_recall_4: 0.8554 - val_auc_4: 0.9350\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - 127s 554ms/step - loss: 0.0673 - categorical_accuracy: 0.9768 - precision_4: 0.9768 - recall_4: 0.9768 - auc_4: 0.9974 - val_loss: 0.3892 - val_categorical_accuracy: 0.8675 - val_precision_4: 0.8675 - val_recall_4: 0.8675 - val_auc_4: 0.9433\n",
      "Epoch 10/10\n",
      "228/228 [==============================] - 127s 556ms/step - loss: 0.0507 - categorical_accuracy: 0.9850 - precision_4: 0.9850 - recall_4: 0.9850 - auc_4: 0.9986 - val_loss: 0.3764 - val_categorical_accuracy: 0.8675 - val_precision_4: 0.8675 - val_recall_4: 0.8675 - val_auc_4: 0.9493\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.Xception(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "xcep = model_creator(model)\n",
    "history_xcep = xcep.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71a9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12048\\388627917.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_vgg16 = vgg16.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 133s 567ms/step - loss: 0.3339 - categorical_accuracy: 0.8502 - precision_5: 0.8502 - recall_5: 0.8500 - auc_5: 0.9319 - val_loss: 0.6138 - val_categorical_accuracy: 0.7470 - val_precision_5: 0.7470 - val_recall_5: 0.7470 - val_auc_5: 0.8384\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 128s 560ms/step - loss: 0.1564 - categorical_accuracy: 0.9363 - precision_5: 0.9366 - recall_5: 0.9363 - auc_5: 0.9851 - val_loss: 0.6489 - val_categorical_accuracy: 0.8072 - val_precision_5: 0.8072 - val_recall_5: 0.8072 - val_auc_5: 0.8929\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 126s 553ms/step - loss: 0.0926 - categorical_accuracy: 0.9680 - precision_5: 0.9680 - recall_5: 0.9680 - auc_5: 0.9947 - val_loss: 1.1376 - val_categorical_accuracy: 0.7831 - val_precision_5: 0.7831 - val_recall_5: 0.7831 - val_auc_5: 0.8368\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 124s 541ms/step - loss: 0.0560 - categorical_accuracy: 0.9779 - precision_5: 0.9779 - recall_5: 0.9779 - auc_5: 0.9980 - val_loss: 1.8481 - val_categorical_accuracy: 0.6747 - val_precision_5: 0.6747 - val_recall_5: 0.6747 - val_auc_5: 0.7551\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 123s 538ms/step - loss: 0.0453 - categorical_accuracy: 0.9836 - precision_5: 0.9836 - recall_5: 0.9836 - auc_5: 0.9988 - val_loss: 0.8513 - val_categorical_accuracy: 0.8554 - val_precision_5: 0.8554 - val_recall_5: 0.8554 - val_auc_5: 0.8935\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 123s 539ms/step - loss: 0.0274 - categorical_accuracy: 0.9907 - precision_5: 0.9907 - recall_5: 0.9907 - auc_5: 0.9996 - val_loss: 0.8286 - val_categorical_accuracy: 0.8554 - val_precision_5: 0.8554 - val_recall_5: 0.8554 - val_auc_5: 0.9043\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 124s 542ms/step - loss: 0.0263 - categorical_accuracy: 0.9907 - precision_5: 0.9907 - recall_5: 0.9907 - auc_5: 0.9996 - val_loss: 1.4326 - val_categorical_accuracy: 0.8072 - val_precision_5: 0.8072 - val_recall_5: 0.8072 - val_auc_5: 0.8592\n",
      "Epoch 8/10\n",
      "228/228 [==============================] - 124s 541ms/step - loss: 0.0152 - categorical_accuracy: 0.9940 - precision_5: 0.9940 - recall_5: 0.9940 - auc_5: 0.9999 - val_loss: 0.6900 - val_categorical_accuracy: 0.9157 - val_precision_5: 0.9157 - val_recall_5: 0.9157 - val_auc_5: 0.9377\n",
      "Epoch 9/10\n",
      "228/228 [==============================] - 125s 545ms/step - loss: 0.0106 - categorical_accuracy: 0.9970 - precision_5: 0.9970 - recall_5: 0.9967 - auc_5: 0.9999 - val_loss: 0.4657 - val_categorical_accuracy: 0.9277 - val_precision_5: 0.9277 - val_recall_5: 0.9277 - val_auc_5: 0.9437\n",
      "Epoch 10/10\n",
      "228/228 [==============================] - 124s 541ms/step - loss: 0.0138 - categorical_accuracy: 0.9959 - precision_5: 0.9959 - recall_5: 0.9959 - auc_5: 0.9999 - val_loss: 0.5079 - val_categorical_accuracy: 0.9157 - val_precision_5: 0.9157 - val_recall_5: 0.9157 - val_auc_5: 0.9520\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.VGG16(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "vgg16 = model_creator(model)\n",
    "history_vgg16 = vgg16.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0cf83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
