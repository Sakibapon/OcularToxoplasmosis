{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "092dc405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:29:33.595066Z",
     "iopub.status.busy": "2023-06-21T17:29:33.594775Z",
     "iopub.status.idle": "2023-06-21T17:29:48.866066Z",
     "shell.execute_reply": "2023-06-21T17:29:48.865087Z",
     "shell.execute_reply.started": "2023-06-21T17:29:33.595042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D,BatchNormalization,Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b0e8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:29:48.869198Z",
     "iopub.status.busy": "2023-06-21T17:29:48.867918Z",
     "iopub.status.idle": "2023-06-21T17:29:49.146954Z",
     "shell.execute_reply": "2023-06-21T17:29:49.146078Z",
     "shell.execute_reply.started": "2023-06-21T17:29:48.869152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 298 images belonging to 2 classes.\n",
      "Found 75 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "batch_size = 8\n",
    "\n",
    "train_data_dir = r\"D:\\Personal\\Ocular Toxoplasmosis\\data\\BinaryClassification\\train\"\n",
    "validation_data_dir = r\"D:\\Personal\\Ocular Toxoplasmosis\\data\\BinaryClassification\\val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(image_size, image_size), batch_size=batch_size, class_mode='categorical')\n",
    "val_generator = validation_datagen.flow_from_directory( validation_data_dir, target_size=(image_size, image_size), batch_size=batch_size, \n",
    "                                                       class_mode='categorical', shuffle=False)\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "# Calculate class weights\n",
    "labels = train_generator.classes\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = dict(zip(np.unique(labels), class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f051a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:30:04.467689Z",
     "iopub.status.busy": "2023-06-21T17:30:04.467314Z",
     "iopub.status.idle": "2023-06-21T17:30:04.492499Z",
     "shell.execute_reply": "2023-06-21T17:30:04.490969Z",
     "shell.execute_reply.started": "2023-06-21T17:30:04.467654Z"
    }
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "\n",
    "def modelfunction(base):\n",
    "    \n",
    "    x = base.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    predictions = tf.keras.layers.Dense(units=num_classes, activation = 'softmax', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.02, l2=0.02))(x)\n",
    "    model = Model(inputs=base.input, outputs=predictions)\n",
    "    return model \n",
    "\n",
    "def get_callbacks(weight):\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(weight, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.2, min_lr=0.0002)\n",
    "    callbacks = [earlystop, checkpoint, learning_rate_reduction]\n",
    "    return callbacks\n",
    "\n",
    "def evaluate(model, generator_test, model_name):\n",
    "    history = model.evaluate(generator_test)\n",
    "    \n",
    "    data = {}\n",
    "    data['Model'] = model_name\n",
    "    data['loss'] = history[0]\n",
    "    data['accuracy'] = history[1]\n",
    "    data['auc'] = history[2]\n",
    "    data['precision'] = history[3]\n",
    "    data['recall'] = history[4]\n",
    "    data['f1_score'] = history[5]\n",
    "    data['cohen_kappa'] = history[6]\n",
    "    l.append(data)\n",
    "\n",
    "    y_pred = model.predict(generator_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = generator_test.classes\n",
    "    class_labels = list(generator_test.class_indices.keys())\n",
    "    cr = classification_report(y_true, y_pred_classes)\n",
    "    print(cr)\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    data['cm'] = cm\n",
    "    data['cr'] = cr\n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.show()\n",
    "    \n",
    "def model_training(base, weight, epochs):\n",
    "\n",
    "    model = modelfunction(base)\n",
    "    print(\"\\n\\n\\n-------------------- Model Initialized --------------------\")\n",
    "    \n",
    "    callbacks = get_callbacks(weight)\n",
    "    metrics = ['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
    "               tfa.metrics.CohenKappa(num_classes = num_classes), tfa.metrics.F1Score(num_classes = num_classes)]\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics= metrics)\n",
    "\n",
    "    history = model.fit(train_generator, steps_per_epoch=170 // batch_size, epochs=epochs, callbacks=callbacks, \n",
    "                        validation_data= val_generator, class_weight = class_weights)\n",
    "    \n",
    "    print(\"\\n\\n\\n-------------------- Evaluation --------------------\")\n",
    "    evaluate(model, val_generator, weight)\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440585c",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71ae0d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T12:43:40.728763Z",
     "iopub.status.busy": "2023-06-21T12:43:40.728129Z",
     "iopub.status.idle": "2023-06-21T12:51:15.487361Z",
     "shell.execute_reply": "2023-06-21T12:51:15.486479Z",
     "shell.execute_reply.started": "2023-06-21T12:43:40.728733Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Model Initialized --------------------\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.8841 - accuracy: 0.3272 - auc_5: 0.3210 - precision_5: 0.3272 - recall_5: 0.3272 - cohen_kappa: -0.9535 - f1_score: 0.3107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric CohenKappa implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.55383, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 19s 667ms/step - loss: 2.8841 - accuracy: 0.3272 - auc_5: 0.3210 - precision_5: 0.3272 - recall_5: 0.3272 - cohen_kappa: -0.9535 - f1_score: 0.3107 - val_loss: 2.5538 - val_accuracy: 0.5867 - val_auc_5: 0.5243 - val_precision_5: 0.5867 - val_recall_5: 0.5867 - val_cohen_kappa: -0.9986 - val_f1_score: 0.5864 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.6222 - accuracy: 0.3580 - auc_5: 0.3673 - precision_5: 0.3580 - recall_5: 0.3580 - cohen_kappa: -0.9807 - f1_score: 0.3517\n",
      "Epoch 2: val_loss improved from 2.55383 to 2.47142, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 11s 543ms/step - loss: 2.6222 - accuracy: 0.3580 - auc_5: 0.3673 - precision_5: 0.3580 - recall_5: 0.3580 - cohen_kappa: -0.9807 - f1_score: 0.3517 - val_loss: 2.4714 - val_accuracy: 0.5467 - val_auc_5: 0.5781 - val_precision_5: 0.5467 - val_recall_5: 0.5467 - val_cohen_kappa: -0.9716 - val_f1_score: 0.5400 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4000 - accuracy: 0.5655 - auc_5: 0.5859 - precision_5: 0.5655 - recall_5: 0.5655 - cohen_kappa: -0.9994 - f1_score: 0.5653\n",
      "Epoch 3: val_loss improved from 2.47142 to 2.45170, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 12s 574ms/step - loss: 2.4000 - accuracy: 0.5655 - auc_5: 0.5859 - precision_5: 0.5655 - recall_5: 0.5655 - cohen_kappa: -0.9994 - f1_score: 0.5653 - val_loss: 2.4517 - val_accuracy: 0.5600 - val_auc_5: 0.6105 - val_precision_5: 0.5600 - val_recall_5: 0.5600 - val_cohen_kappa: -0.9651 - val_f1_score: 0.5520 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3274 - accuracy: 0.5802 - auc_5: 0.6296 - precision_5: 0.5802 - recall_5: 0.5802 - cohen_kappa: -0.9924 - f1_score: 0.5786\n",
      "Epoch 4: val_loss improved from 2.45170 to 2.40500, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 11s 508ms/step - loss: 2.3274 - accuracy: 0.5802 - auc_5: 0.6296 - precision_5: 0.5802 - recall_5: 0.5802 - cohen_kappa: -0.9924 - f1_score: 0.5786 - val_loss: 2.4050 - val_accuracy: 0.6133 - val_auc_5: 0.6469 - val_precision_5: 0.6133 - val_recall_5: 0.6133 - val_cohen_kappa: -0.9501 - val_f1_score: 0.6032 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2504 - accuracy: 0.6488 - auc_5: 0.6822 - precision_5: 0.6488 - recall_5: 0.6488 - cohen_kappa: -0.9421 - f1_score: 0.6380\n",
      "Epoch 5: val_loss improved from 2.40500 to 2.33470, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 10s 495ms/step - loss: 2.2504 - accuracy: 0.6488 - auc_5: 0.6822 - precision_5: 0.6488 - recall_5: 0.6488 - cohen_kappa: -0.9421 - f1_score: 0.6380 - val_loss: 2.3347 - val_accuracy: 0.6267 - val_auc_5: 0.6956 - val_precision_5: 0.6267 - val_recall_5: 0.6267 - val_cohen_kappa: -0.9023 - val_f1_score: 0.6064 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1619 - accuracy: 0.6726 - auc_5: 0.7286 - precision_5: 0.6726 - recall_5: 0.6726 - cohen_kappa: -0.9747 - f1_score: 0.6684\n",
      "Epoch 6: val_loss improved from 2.33470 to 2.28555, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 13s 604ms/step - loss: 2.1619 - accuracy: 0.6726 - auc_5: 0.7286 - precision_5: 0.6726 - recall_5: 0.6726 - cohen_kappa: -0.9747 - f1_score: 0.6684 - val_loss: 2.2856 - val_accuracy: 0.7067 - val_auc_5: 0.7357 - val_precision_5: 0.7067 - val_recall_5: 0.7067 - val_cohen_kappa: -0.8000 - val_f1_score: 0.6700 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9902 - accuracy: 0.7976 - auc_5: 0.8693 - precision_5: 0.7976 - recall_5: 0.7976 - cohen_kappa: -0.9600 - f1_score: 0.7934\n",
      "Epoch 7: val_loss improved from 2.28555 to 2.25021, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 13s 613ms/step - loss: 1.9902 - accuracy: 0.7976 - auc_5: 0.8693 - precision_5: 0.7976 - recall_5: 0.7976 - cohen_kappa: -0.9600 - f1_score: 0.7934 - val_loss: 2.2502 - val_accuracy: 0.7467 - val_auc_5: 0.7623 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.7241 - val_f1_score: 0.6984 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0190 - accuracy: 0.7679 - auc_5: 0.8482 - precision_5: 0.7679 - recall_5: 0.7679 - cohen_kappa: -0.9075 - f1_score: 0.7560\n",
      "Epoch 8: val_loss did not improve from 2.25021\n",
      "21/21 [==============================] - 14s 668ms/step - loss: 2.0190 - accuracy: 0.7679 - auc_5: 0.8482 - precision_5: 0.7679 - recall_5: 0.7679 - cohen_kappa: -0.9075 - f1_score: 0.7560 - val_loss: 2.2512 - val_accuracy: 0.7200 - val_auc_5: 0.7666 - val_precision_5: 0.7200 - val_recall_5: 0.7200 - val_cohen_kappa: -0.7553 - val_f1_score: 0.6747 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9784 - accuracy: 0.8086 - auc_5: 0.8922 - precision_5: 0.8086 - recall_5: 0.8086 - cohen_kappa: -0.9379 - f1_score: 0.8023\n",
      "Epoch 9: val_loss improved from 2.25021 to 2.24783, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 14s 662ms/step - loss: 1.9784 - accuracy: 0.8086 - auc_5: 0.8922 - precision_5: 0.8086 - recall_5: 0.8086 - cohen_kappa: -0.9379 - f1_score: 0.8023 - val_loss: 2.2478 - val_accuracy: 0.7200 - val_auc_5: 0.7735 - val_precision_5: 0.7200 - val_recall_5: 0.7200 - val_cohen_kappa: -0.7241 - val_f1_score: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9389 - accuracy: 0.8272 - auc_5: 0.8970 - precision_5: 0.8272 - recall_5: 0.8272 - cohen_kappa: -0.8626 - f1_score: 0.8134\n",
      "Epoch 10: val_loss improved from 2.24783 to 2.23775, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 12s 587ms/step - loss: 1.9389 - accuracy: 0.8272 - auc_5: 0.8970 - precision_5: 0.8272 - recall_5: 0.8272 - cohen_kappa: -0.8626 - f1_score: 0.8134 - val_loss: 2.2378 - val_accuracy: 0.7333 - val_auc_5: 0.7881 - val_precision_5: 0.7333 - val_recall_5: 0.7333 - val_cohen_kappa: -0.7082 - val_f1_score: 0.6784 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9392 - accuracy: 0.8086 - auc_5: 0.8999 - precision_5: 0.8086 - recall_5: 0.8086 - cohen_kappa: -0.9108 - f1_score: 0.7993\n",
      "Epoch 11: val_loss did not improve from 2.23775\n",
      "21/21 [==============================] - 14s 661ms/step - loss: 1.9392 - accuracy: 0.8086 - auc_5: 0.8999 - precision_5: 0.8086 - recall_5: 0.8086 - cohen_kappa: -0.9108 - f1_score: 0.7993 - val_loss: 2.2391 - val_accuracy: 0.7467 - val_auc_5: 0.7920 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9301 - accuracy: 0.8395 - auc_5: 0.9268 - precision_5: 0.8395 - recall_5: 0.8395 - cohen_kappa: -0.8740 - f1_score: 0.8279\n",
      "Epoch 12: val_loss improved from 2.23775 to 2.22846, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 15s 714ms/step - loss: 1.9301 - accuracy: 0.8395 - auc_5: 0.9268 - precision_5: 0.8395 - recall_5: 0.8395 - cohen_kappa: -0.8740 - f1_score: 0.8279 - val_loss: 2.2285 - val_accuracy: 0.7467 - val_auc_5: 0.7957 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9205 - accuracy: 0.8452 - auc_5: 0.9129 - precision_5: 0.8452 - recall_5: 0.8452 - cohen_kappa: -0.9027 - f1_score: 0.8369\n",
      "Epoch 13: val_loss improved from 2.22846 to 2.22319, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 14s 685ms/step - loss: 1.9205 - accuracy: 0.8452 - auc_5: 0.9129 - precision_5: 0.8452 - recall_5: 0.8452 - cohen_kappa: -0.9027 - f1_score: 0.8369 - val_loss: 2.2232 - val_accuracy: 0.7467 - val_auc_5: 0.7954 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.8427 - accuracy: 0.8827 - auc_5: 0.9514 - precision_5: 0.8827 - recall_5: 0.8827 - cohen_kappa: -0.8684 - f1_score: 0.8738\n",
      "Epoch 14: val_loss improved from 2.22319 to 2.21947, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 16s 779ms/step - loss: 1.8427 - accuracy: 0.8827 - auc_5: 0.9514 - precision_5: 0.8827 - recall_5: 0.8827 - cohen_kappa: -0.8684 - f1_score: 0.8738 - val_loss: 2.2195 - val_accuracy: 0.7467 - val_auc_5: 0.7998 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8645 - accuracy: 0.8765 - auc_5: 0.9428 - precision_5: 0.8765 - recall_5: 0.8765 - cohen_kappa: -0.7728 - f1_score: 0.8584\n",
      "Epoch 15: val_loss improved from 2.21947 to 2.21456, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 14s 677ms/step - loss: 1.8645 - accuracy: 0.8765 - auc_5: 0.9428 - precision_5: 0.8765 - recall_5: 0.8765 - cohen_kappa: -0.7728 - f1_score: 0.8584 - val_loss: 2.2146 - val_accuracy: 0.7467 - val_auc_5: 0.8036 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8887 - accuracy: 0.8750 - auc_5: 0.9475 - precision_5: 0.8750 - recall_5: 0.8750 - cohen_kappa: -0.7670 - f1_score: 0.8560\n",
      "Epoch 16: val_loss improved from 2.21456 to 2.20784, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 16s 730ms/step - loss: 1.8887 - accuracy: 0.8750 - auc_5: 0.9475 - precision_5: 0.8750 - recall_5: 0.8750 - cohen_kappa: -0.7670 - f1_score: 0.8560 - val_loss: 2.2078 - val_accuracy: 0.7467 - val_auc_5: 0.8103 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8331 - accuracy: 0.8827 - auc_5: 0.9456 - precision_5: 0.8827 - recall_5: 0.8827 - cohen_kappa: -0.7933 - f1_score: 0.8674\n",
      "Epoch 17: val_loss did not improve from 2.20784\n",
      "21/21 [==============================] - 12s 576ms/step - loss: 1.8331 - accuracy: 0.8827 - auc_5: 0.9456 - precision_5: 0.8827 - recall_5: 0.8827 - cohen_kappa: -0.7933 - f1_score: 0.8674 - val_loss: 2.2084 - val_accuracy: 0.7467 - val_auc_5: 0.8068 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7956 - accuracy: 0.8951 - auc_5: 0.9653 - precision_5: 0.8951 - recall_5: 0.8951 - cohen_kappa: -0.8324 - f1_score: 0.8845\n",
      "Epoch 18: val_loss improved from 2.20784 to 2.20246, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 13s 600ms/step - loss: 1.7956 - accuracy: 0.8951 - auc_5: 0.9653 - precision_5: 0.8951 - recall_5: 0.8951 - cohen_kappa: -0.8324 - f1_score: 0.8845 - val_loss: 2.2025 - val_accuracy: 0.7467 - val_auc_5: 0.8082 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6811 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7733 - accuracy: 0.9048 - auc_5: 0.9761 - precision_5: 0.9048 - recall_5: 0.9048 - cohen_kappa: -0.8605 - f1_score: 0.8970\n",
      "Epoch 19: val_loss did not improve from 2.20246\n",
      "21/21 [==============================] - 12s 586ms/step - loss: 1.7733 - accuracy: 0.9048 - auc_5: 0.9761 - precision_5: 0.9048 - recall_5: 0.9048 - cohen_kappa: -0.8605 - f1_score: 0.8970 - val_loss: 2.2036 - val_accuracy: 0.7333 - val_auc_5: 0.8145 - val_precision_5: 0.7333 - val_recall_5: 0.7333 - val_cohen_kappa: -0.6085 - val_f1_score: 0.6476 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7358 - accuracy: 0.9444 - auc_5: 0.9851 - precision_5: 0.9444 - recall_5: 0.9444 - cohen_kappa: -0.7658 - f1_score: 0.9359\n",
      "Epoch 20: val_loss did not improve from 2.20246\n",
      "21/21 [==============================] - 13s 641ms/step - loss: 1.7358 - accuracy: 0.9444 - auc_5: 0.9851 - precision_5: 0.9444 - recall_5: 0.9444 - cohen_kappa: -0.7658 - f1_score: 0.9359 - val_loss: 2.2064 - val_accuracy: 0.7600 - val_auc_5: 0.8161 - val_precision_5: 0.7600 - val_recall_5: 0.7600 - val_cohen_kappa: -0.5743 - val_f1_score: 0.6711 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7760 - accuracy: 0.9226 - auc_5: 0.9735 - precision_5: 0.9226 - recall_5: 0.9226 - cohen_kappa: -0.6824 - f1_score: 0.9046\n",
      "Epoch 21: val_loss did not improve from 2.20246\n",
      "21/21 [==============================] - 11s 527ms/step - loss: 1.7760 - accuracy: 0.9226 - auc_5: 0.9735 - precision_5: 0.9226 - recall_5: 0.9226 - cohen_kappa: -0.6824 - f1_score: 0.9046 - val_loss: 2.2031 - val_accuracy: 0.7600 - val_auc_5: 0.8179 - val_precision_5: 0.7600 - val_recall_5: 0.7600 - val_cohen_kappa: -0.5743 - val_f1_score: 0.6711 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7431 - accuracy: 0.9524 - auc_5: 0.9856 - precision_5: 0.9524 - recall_5: 0.9524 - cohen_kappa: -0.7603 - f1_score: 0.9449\n",
      "Epoch 22: val_loss improved from 2.20246 to 2.19673, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 11s 540ms/step - loss: 1.7431 - accuracy: 0.9524 - auc_5: 0.9856 - precision_5: 0.9524 - recall_5: 0.9524 - cohen_kappa: -0.7603 - f1_score: 0.9449 - val_loss: 2.1967 - val_accuracy: 0.7600 - val_auc_5: 0.8196 - val_precision_5: 0.7600 - val_recall_5: 0.7600 - val_cohen_kappa: -0.5743 - val_f1_score: 0.6711 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8743 - accuracy: 0.8580 - auc_5: 0.9372 - precision_5: 0.8580 - recall_5: 0.8580 - cohen_kappa: -0.7516 - f1_score: 0.8346\n",
      "Epoch 23: val_loss improved from 2.19673 to 2.19602, saving model to MobileNet.h5\n",
      "21/21 [==============================] - 11s 504ms/step - loss: 1.8743 - accuracy: 0.8580 - auc_5: 0.9372 - precision_5: 0.8580 - recall_5: 0.8580 - cohen_kappa: -0.7516 - f1_score: 0.8346 - val_loss: 2.1960 - val_accuracy: 0.7467 - val_auc_5: 0.8194 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.5571 - val_f1_score: 0.6460 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8820 - accuracy: 0.8571 - auc_5: 0.9403 - precision_5: 0.8571 - recall_5: 0.8571 - cohen_kappa: -0.7465 - f1_score: 0.8329\n",
      "Epoch 24: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 11s 497ms/step - loss: 1.8820 - accuracy: 0.8571 - auc_5: 0.9403 - precision_5: 0.8571 - recall_5: 0.8571 - cohen_kappa: -0.7465 - f1_score: 0.8329 - val_loss: 2.2013 - val_accuracy: 0.7333 - val_auc_5: 0.8169 - val_precision_5: 0.7333 - val_recall_5: 0.7333 - val_cohen_kappa: -0.5398 - val_f1_score: 0.6197 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7570 - accuracy: 0.9568 - auc_5: 0.9914 - precision_5: 0.9568 - recall_5: 0.9568 - cohen_kappa: -0.8066 - f1_score: 0.9516\n",
      "Epoch 25: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 1.7570 - accuracy: 0.9568 - auc_5: 0.9914 - precision_5: 0.9568 - recall_5: 0.9568 - cohen_kappa: -0.8066 - f1_score: 0.9516 - val_loss: 2.2086 - val_accuracy: 0.7467 - val_auc_5: 0.8215 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7186 - accuracy: 0.9524 - auc_5: 0.9884 - precision_5: 0.9524 - recall_5: 0.9524 - cohen_kappa: -0.7326 - f1_score: 0.9437\n",
      "Epoch 26: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 1.7186 - accuracy: 0.9524 - auc_5: 0.9884 - precision_5: 0.9524 - recall_5: 0.9524 - cohen_kappa: -0.7326 - f1_score: 0.9437 - val_loss: 2.2105 - val_accuracy: 0.7333 - val_auc_5: 0.8257 - val_precision_5: 0.7333 - val_recall_5: 0.7333 - val_cohen_kappa: -0.4360 - val_f1_score: 0.5609 - lr: 1.0000e-05\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.7462 - accuracy: 0.9506 - auc_5: 0.9849 - precision_5: 0.9506 - recall_5: 0.9506 - cohen_kappa: -0.7587 - f1_score: 0.9428\n",
      "Epoch 27: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 10s 492ms/step - loss: 1.7462 - accuracy: 0.9506 - auc_5: 0.9849 - precision_5: 0.9506 - recall_5: 0.9506 - cohen_kappa: -0.7587 - f1_score: 0.9428 - val_loss: 2.2193 - val_accuracy: 0.7467 - val_auc_5: 0.8268 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7172 - accuracy: 0.9444 - auc_5: 0.9881 - precision_5: 0.9444 - recall_5: 0.9444 - cohen_kappa: -0.7516 - f1_score: 0.9353\n",
      "Epoch 28: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 1.7172 - accuracy: 0.9444 - auc_5: 0.9881 - precision_5: 0.9444 - recall_5: 0.9444 - cohen_kappa: -0.7516 - f1_score: 0.9353 - val_loss: 2.2158 - val_accuracy: 0.7467 - val_auc_5: 0.8272 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6855 - accuracy: 0.9643 - auc_5: 0.9962 - precision_5: 0.9643 - recall_5: 0.9643 - cohen_kappa: -0.7465 - f1_score: 0.9582\n",
      "Epoch 29: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 15s 697ms/step - loss: 1.6855 - accuracy: 0.9643 - auc_5: 0.9962 - precision_5: 0.9643 - recall_5: 0.9643 - cohen_kappa: -0.7465 - f1_score: 0.9582 - val_loss: 2.2116 - val_accuracy: 0.7467 - val_auc_5: 0.8279 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7396 - accuracy: 0.9345 - auc_5: 0.9821 - precision_5: 0.9345 - recall_5: 0.9345 - cohen_kappa: -0.7256 - f1_score: 0.9221\n",
      "Epoch 30: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 15s 729ms/step - loss: 1.7396 - accuracy: 0.9345 - auc_5: 0.9821 - precision_5: 0.9345 - recall_5: 0.9345 - cohen_kappa: -0.7256 - f1_score: 0.9221 - val_loss: 2.2141 - val_accuracy: 0.7467 - val_auc_5: 0.8292 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7854 - accuracy: 0.9405 - auc_5: 0.9725 - precision_5: 0.9405 - recall_5: 0.9405 - cohen_kappa: -0.7603 - f1_score: 0.9311\n",
      "Epoch 31: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 13s 622ms/step - loss: 1.7854 - accuracy: 0.9405 - auc_5: 0.9725 - precision_5: 0.9405 - recall_5: 0.9405 - cohen_kappa: -0.7603 - f1_score: 0.9311 - val_loss: 2.2095 - val_accuracy: 0.7467 - val_auc_5: 0.8284 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6869 - accuracy: 0.9702 - auc_5: 0.9932 - precision_5: 0.9702 - recall_5: 0.9702 - cohen_kappa: -0.7256 - f1_score: 0.9646\n",
      "Epoch 32: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 12s 584ms/step - loss: 1.6869 - accuracy: 0.9702 - auc_5: 0.9932 - precision_5: 0.9702 - recall_5: 0.9702 - cohen_kappa: -0.7256 - f1_score: 0.9646 - val_loss: 2.2048 - val_accuracy: 0.7467 - val_auc_5: 0.8290 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7121 - accuracy: 0.9464 - auc_5: 0.9931 - precision_5: 0.9464 - recall_5: 0.9464 - cohen_kappa: -0.7113 - f1_score: 0.9356Restoring model weights from the end of the best epoch: 23.\n",
      "\n",
      "Epoch 33: val_loss did not improve from 2.19602\n",
      "21/21 [==============================] - 13s 604ms/step - loss: 1.7121 - accuracy: 0.9464 - auc_5: 0.9931 - precision_5: 0.9464 - recall_5: 0.9464 - cohen_kappa: -0.7113 - f1_score: 0.9356 - val_loss: 2.2027 - val_accuracy: 0.7467 - val_auc_5: 0.8325 - val_precision_5: 0.7467 - val_recall_5: 0.7467 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5939 - lr: 1.0000e-05\n",
      "Epoch 33: early stopping\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Evaluation --------------------\n",
      "10/10 [==============================] - 3s 227ms/step - loss: 2.1960 - accuracy: 0.7467 - auc_5: 0.8194 - precision_5: 0.7467 - recall_5: 0.7467 - cohen_kappa: -0.5571 - f1_score: 0.6460\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.83        54\n",
      "           1       0.57      0.38      0.46        21\n",
      "\n",
      "    accuracy                           0.75        75\n",
      "   macro avg       0.68      0.63      0.65        75\n",
      "weighted avg       0.73      0.75      0.73        75\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MobileNet = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_tensor=None, input_shape=None)\n",
    "\n",
    "MobileNet_model = model_training(MobileNet,'MobileNet.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18688a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T12:51:15.493583Z",
     "iopub.status.busy": "2023-06-21T12:51:15.489997Z",
     "iopub.status.idle": "2023-06-21T12:58:21.909264Z",
     "shell.execute_reply": "2023-06-21T12:58:21.908337Z",
     "shell.execute_reply.started": "2023-06-21T12:51:15.493550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "-------------------- Model Initialized --------------------\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.7101 - accuracy: 0.4012 - auc_6: 0.3924 - precision_6: 0.4012 - recall_6: 0.4012 - cohen_kappa: -0.9605 - f1_score: 0.3889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric CohenKappa implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.92809, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 18s 647ms/step - loss: 2.7101 - accuracy: 0.4012 - auc_6: 0.3924 - precision_6: 0.4012 - recall_6: 0.4012 - cohen_kappa: -0.9605 - f1_score: 0.3889 - val_loss: 2.9281 - val_accuracy: 0.4400 - val_auc_6: 0.3961 - val_precision_6: 0.4400 - val_recall_6: 0.4400 - val_cohen_kappa: -0.9716 - val_f1_score: 0.4318 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5022 - accuracy: 0.5062 - auc_6: 0.5244 - precision_6: 0.5062 - recall_6: 0.5062 - cohen_kappa: -0.9973 - f1_score: 0.5055\n",
      "Epoch 2: val_loss improved from 2.92809 to 2.61598, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 522ms/step - loss: 2.5022 - accuracy: 0.5062 - auc_6: 0.5244 - precision_6: 0.5062 - recall_6: 0.5062 - cohen_kappa: -0.9973 - f1_score: 0.5055 - val_loss: 2.6160 - val_accuracy: 0.4800 - val_auc_6: 0.4886 - val_precision_6: 0.4800 - val_recall_6: 0.4800 - val_cohen_kappa: -0.9943 - val_f1_score: 0.4785 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3988 - accuracy: 0.4938 - auc_6: 0.5412 - precision_6: 0.4938 - recall_6: 0.4938 - cohen_kappa: -1.0000 - f1_score: 0.4938\n",
      "Epoch 3: val_loss improved from 2.61598 to 2.45622, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 508ms/step - loss: 2.3988 - accuracy: 0.4938 - auc_6: 0.5412 - precision_6: 0.4938 - recall_6: 0.4938 - cohen_kappa: -1.0000 - f1_score: 0.4938 - val_loss: 2.4562 - val_accuracy: 0.5200 - val_auc_6: 0.5802 - val_precision_6: 0.5200 - val_recall_6: 0.5200 - val_cohen_kappa: -0.9996 - val_f1_score: 0.5199 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2785 - accuracy: 0.6420 - auc_6: 0.6862 - precision_6: 0.6420 - recall_6: 0.6420 - cohen_kappa: -0.9638 - f1_score: 0.6352\n",
      "Epoch 4: val_loss improved from 2.45622 to 2.35929, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 517ms/step - loss: 2.2785 - accuracy: 0.6420 - auc_6: 0.6862 - precision_6: 0.6420 - recall_6: 0.6420 - cohen_kappa: -0.9638 - f1_score: 0.6352 - val_loss: 2.3593 - val_accuracy: 0.6400 - val_auc_6: 0.6641 - val_precision_6: 0.6400 - val_recall_6: 0.6400 - val_cohen_kappa: -0.8911 - val_f1_score: 0.6180 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1444 - accuracy: 0.7346 - auc_6: 0.7876 - precision_6: 0.7346 - recall_6: 0.7346 - cohen_kappa: -0.9459 - f1_score: 0.7270\n",
      "Epoch 5: val_loss improved from 2.35929 to 2.26709, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 520ms/step - loss: 2.1444 - accuracy: 0.7346 - auc_6: 0.7876 - precision_6: 0.7346 - recall_6: 0.7346 - cohen_kappa: -0.9459 - f1_score: 0.7270 - val_loss: 2.2671 - val_accuracy: 0.7067 - val_auc_6: 0.7397 - val_precision_6: 0.7067 - val_recall_6: 0.7067 - val_cohen_kappa: -0.7399 - val_f1_score: 0.6551 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0339 - accuracy: 0.7202 - auc_6: 0.8343 - precision_6: 0.7202 - recall_6: 0.7202 - cohen_kappa: -0.9496 - f1_score: 0.7128\n",
      "Epoch 6: val_loss improved from 2.26709 to 2.22846, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 12s 561ms/step - loss: 2.0339 - accuracy: 0.7202 - auc_6: 0.8343 - precision_6: 0.7202 - recall_6: 0.7202 - cohen_kappa: -0.9496 - f1_score: 0.7128 - val_loss: 2.2285 - val_accuracy: 0.7200 - val_auc_6: 0.7710 - val_precision_6: 0.7200 - val_recall_6: 0.7200 - val_cohen_kappa: -0.7241 - val_f1_score: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9964 - accuracy: 0.7778 - auc_6: 0.8706 - precision_6: 0.7778 - recall_6: 0.7778 - cohen_kappa: -0.9337 - f1_score: 0.7699\n",
      "Epoch 7: val_loss improved from 2.22846 to 2.21698, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 531ms/step - loss: 1.9964 - accuracy: 0.7778 - auc_6: 0.8706 - precision_6: 0.7778 - recall_6: 0.7778 - cohen_kappa: -0.9337 - f1_score: 0.7699 - val_loss: 2.2170 - val_accuracy: 0.7067 - val_auc_6: 0.7854 - val_precision_6: 0.7067 - val_recall_6: 0.7067 - val_cohen_kappa: -0.7082 - val_f1_score: 0.6462 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0271 - accuracy: 0.7840 - auc_6: 0.8458 - precision_6: 0.7840 - recall_6: 0.7840 - cohen_kappa: -0.8447 - f1_score: 0.7641\n",
      "Epoch 8: val_loss improved from 2.21698 to 2.21293, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 14s 660ms/step - loss: 2.0271 - accuracy: 0.7840 - auc_6: 0.8458 - precision_6: 0.7840 - recall_6: 0.7840 - cohen_kappa: -0.8447 - f1_score: 0.7641 - val_loss: 2.2129 - val_accuracy: 0.6933 - val_auc_6: 0.7934 - val_precision_6: 0.6933 - val_recall_6: 0.6933 - val_cohen_kappa: -0.6920 - val_f1_score: 0.6251 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9610 - accuracy: 0.7901 - auc_6: 0.9080 - precision_6: 0.7901 - recall_6: 0.7901 - cohen_kappa: -0.8851 - f1_score: 0.7765\n",
      "Epoch 9: val_loss improved from 2.21293 to 2.20590, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 497ms/step - loss: 1.9610 - accuracy: 0.7901 - auc_6: 0.9080 - precision_6: 0.7901 - recall_6: 0.7901 - cohen_kappa: -0.8851 - f1_score: 0.7765 - val_loss: 2.2059 - val_accuracy: 0.6933 - val_auc_6: 0.7999 - val_precision_6: 0.6933 - val_recall_6: 0.6933 - val_cohen_kappa: -0.6920 - val_f1_score: 0.6251 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9107 - accuracy: 0.8512 - auc_6: 0.9308 - precision_6: 0.8512 - recall_6: 0.8512 - cohen_kappa: -0.8548 - f1_score: 0.8386\n",
      "Epoch 10: val_loss improved from 2.20590 to 2.19502, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 520ms/step - loss: 1.9107 - accuracy: 0.8512 - auc_6: 0.9308 - precision_6: 0.8512 - recall_6: 0.8512 - cohen_kappa: -0.8548 - f1_score: 0.8386 - val_loss: 2.1950 - val_accuracy: 0.7200 - val_auc_6: 0.8085 - val_precision_6: 0.7200 - val_recall_6: 0.7200 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6476 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8580 - accuracy: 0.8827 - auc_6: 0.9562 - precision_6: 0.8827 - recall_6: 0.8827 - cohen_kappa: -0.8447 - f1_score: 0.8719\n",
      "Epoch 11: val_loss improved from 2.19502 to 2.19326, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 506ms/step - loss: 1.8580 - accuracy: 0.8827 - auc_6: 0.9562 - precision_6: 0.8827 - recall_6: 0.8827 - cohen_kappa: -0.8447 - f1_score: 0.8719 - val_loss: 2.1933 - val_accuracy: 0.7200 - val_auc_6: 0.8094 - val_precision_6: 0.7200 - val_recall_6: 0.7200 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6476 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8796 - accuracy: 0.8750 - auc_6: 0.9406 - precision_6: 0.8750 - recall_6: 0.8750 - cohen_kappa: -0.8432 - f1_score: 0.8634\n",
      "Epoch 12: val_loss improved from 2.19326 to 2.19324, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 523ms/step - loss: 1.8796 - accuracy: 0.8750 - auc_6: 0.9406 - precision_6: 0.8750 - recall_6: 0.8750 - cohen_kappa: -0.8432 - f1_score: 0.8634 - val_loss: 2.1932 - val_accuracy: 0.7333 - val_auc_6: 0.8103 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.6423 - val_f1_score: 0.6591 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8717 - accuracy: 0.8580 - auc_6: 0.9406 - precision_6: 0.8580 - recall_6: 0.8580 - cohen_kappa: -0.8324 - f1_score: 0.8437\n",
      "Epoch 13: val_loss improved from 2.19324 to 2.18592, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 547ms/step - loss: 1.8717 - accuracy: 0.8580 - auc_6: 0.9406 - precision_6: 0.8580 - recall_6: 0.8580 - cohen_kappa: -0.8324 - f1_score: 0.8437 - val_loss: 2.1859 - val_accuracy: 0.7333 - val_auc_6: 0.8144 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.6423 - val_f1_score: 0.6591 - lr: 1.0000e-05\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.8374 - accuracy: 0.9286 - auc_6: 0.9677 - precision_6: 0.9286 - recall_6: 0.9286 - cohen_kappa: -0.8491 - f1_score: 0.9222\n",
      "Epoch 14: val_loss improved from 2.18592 to 2.18218, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 511ms/step - loss: 1.8374 - accuracy: 0.9286 - auc_6: 0.9677 - precision_6: 0.9286 - recall_6: 0.9286 - cohen_kappa: -0.8491 - f1_score: 0.9222 - val_loss: 2.1822 - val_accuracy: 0.7200 - val_auc_6: 0.8198 - val_precision_6: 0.7200 - val_recall_6: 0.7200 - val_cohen_kappa: -0.5571 - val_f1_score: 0.6087 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8078 - accuracy: 0.8750 - auc_6: 0.9694 - precision_6: 0.8750 - recall_6: 0.8750 - cohen_kappa: -0.8548 - f1_score: 0.8644\n",
      "Epoch 15: val_loss improved from 2.18218 to 2.18217, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 513ms/step - loss: 1.8078 - accuracy: 0.8750 - auc_6: 0.9694 - precision_6: 0.8750 - recall_6: 0.8750 - cohen_kappa: -0.8548 - f1_score: 0.8644 - val_loss: 2.1822 - val_accuracy: 0.7200 - val_auc_6: 0.8286 - val_precision_6: 0.7200 - val_recall_6: 0.7200 - val_cohen_kappa: -0.5225 - val_f1_score: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8982 - accuracy: 0.8333 - auc_6: 0.9284 - precision_6: 0.8333 - recall_6: 0.8333 - cohen_kappa: -0.8324 - f1_score: 0.8165\n",
      "Epoch 16: val_loss improved from 2.18217 to 2.17394, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 502ms/step - loss: 1.8982 - accuracy: 0.8333 - auc_6: 0.9284 - precision_6: 0.8333 - recall_6: 0.8333 - cohen_kappa: -0.8324 - f1_score: 0.8165 - val_loss: 2.1739 - val_accuracy: 0.7467 - val_auc_6: 0.8235 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5915 - val_f1_score: 0.6592 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8435 - accuracy: 0.8869 - auc_6: 0.9546 - precision_6: 0.8869 - recall_6: 0.8869 - cohen_kappa: -0.7534 - f1_score: 0.8684\n",
      "Epoch 17: val_loss improved from 2.17394 to 2.16918, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 12s 552ms/step - loss: 1.8435 - accuracy: 0.8869 - auc_6: 0.9546 - precision_6: 0.8869 - recall_6: 0.8869 - cohen_kappa: -0.7534 - f1_score: 0.8684 - val_loss: 2.1692 - val_accuracy: 0.7467 - val_auc_6: 0.8274 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5915 - val_f1_score: 0.6592 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8025 - accuracy: 0.9345 - auc_6: 0.9790 - precision_6: 0.9345 - recall_6: 0.9345 - cohen_kappa: -0.8064 - f1_score: 0.9267\n",
      "Epoch 18: val_loss improved from 2.16918 to 2.16661, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 534ms/step - loss: 1.8025 - accuracy: 0.9345 - auc_6: 0.9790 - precision_6: 0.9345 - recall_6: 0.9345 - cohen_kappa: -0.8064 - f1_score: 0.9267 - val_loss: 2.1666 - val_accuracy: 0.7467 - val_auc_6: 0.8336 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5571 - val_f1_score: 0.6460 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8227 - accuracy: 0.8827 - auc_6: 0.9663 - precision_6: 0.8827 - recall_6: 0.8827 - cohen_kappa: -0.7933 - f1_score: 0.8674\n",
      "Epoch 19: val_loss improved from 2.16661 to 2.15945, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 10s 495ms/step - loss: 1.8227 - accuracy: 0.8827 - auc_6: 0.9663 - precision_6: 0.8827 - recall_6: 0.8827 - cohen_kappa: -0.7933 - f1_score: 0.8674 - val_loss: 2.1594 - val_accuracy: 0.7467 - val_auc_6: 0.8341 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5915 - val_f1_score: 0.6592 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7516 - accuracy: 0.9506 - auc_6: 0.9834 - precision_6: 0.9506 - recall_6: 0.9506 - cohen_kappa: -0.7728 - f1_score: 0.9434\n",
      "Epoch 20: val_loss did not improve from 2.15945\n",
      "21/21 [==============================] - 10s 501ms/step - loss: 1.7516 - accuracy: 0.9506 - auc_6: 0.9834 - precision_6: 0.9506 - recall_6: 0.9506 - cohen_kappa: -0.7728 - f1_score: 0.9434 - val_loss: 2.1605 - val_accuracy: 0.7467 - val_auc_6: 0.8382 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5571 - val_f1_score: 0.6460 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7833 - accuracy: 0.9321 - auc_6: 0.9815 - precision_6: 0.9321 - recall_6: 0.9321 - cohen_kappa: -0.7373 - f1_score: 0.9200\n",
      "Epoch 21: val_loss did not improve from 2.15945\n",
      "21/21 [==============================] - 10s 484ms/step - loss: 1.7833 - accuracy: 0.9321 - auc_6: 0.9815 - precision_6: 0.9321 - recall_6: 0.9321 - cohen_kappa: -0.7373 - f1_score: 0.9200 - val_loss: 2.1666 - val_accuracy: 0.7333 - val_auc_6: 0.8398 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.5398 - val_f1_score: 0.6197 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7756 - accuracy: 0.9136 - auc_6: 0.9807 - precision_6: 0.9136 - recall_6: 0.9136 - cohen_kappa: -0.6853 - f1_score: 0.8937\n",
      "Epoch 22: val_loss did not improve from 2.15945\n",
      "21/21 [==============================] - 10s 475ms/step - loss: 1.7756 - accuracy: 0.9136 - auc_6: 0.9807 - precision_6: 0.9136 - recall_6: 0.9136 - cohen_kappa: -0.6853 - f1_score: 0.8937 - val_loss: 2.1792 - val_accuracy: 0.7333 - val_auc_6: 0.8373 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.5052 - val_f1_score: 0.6028 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8165 - accuracy: 0.9198 - auc_6: 0.9757 - precision_6: 0.9198 - recall_6: 0.9198 - cohen_kappa: -0.8324 - f1_score: 0.9117\n",
      "Epoch 23: val_loss did not improve from 2.15945\n",
      "21/21 [==============================] - 10s 473ms/step - loss: 1.8165 - accuracy: 0.9198 - auc_6: 0.9757 - precision_6: 0.9198 - recall_6: 0.9198 - cohen_kappa: -0.8324 - f1_score: 0.9117 - val_loss: 2.1739 - val_accuracy: 0.7333 - val_auc_6: 0.8417 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.4706 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7708 - accuracy: 0.9444 - auc_6: 0.9840 - precision_6: 0.9444 - recall_6: 0.9444 - cohen_kappa: -0.8066 - f1_score: 0.9378\n",
      "Epoch 24: val_loss did not improve from 2.15945\n",
      "21/21 [==============================] - 10s 472ms/step - loss: 1.7708 - accuracy: 0.9444 - auc_6: 0.9840 - precision_6: 0.9444 - recall_6: 0.9444 - cohen_kappa: -0.8066 - f1_score: 0.9378 - val_loss: 2.1827 - val_accuracy: 0.7333 - val_auc_6: 0.8487 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.4706 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7343 - accuracy: 0.9444 - auc_6: 0.9875 - precision_6: 0.9444 - recall_6: 0.9444 - cohen_kappa: -0.6929 - f1_score: 0.9321\n",
      "Epoch 25: val_loss did not improve from 2.15945\n",
      "21/21 [==============================] - 10s 478ms/step - loss: 1.7343 - accuracy: 0.9444 - auc_6: 0.9875 - precision_6: 0.9444 - recall_6: 0.9444 - cohen_kappa: -0.6929 - f1_score: 0.9321 - val_loss: 2.1743 - val_accuracy: 0.7333 - val_auc_6: 0.8512 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.4706 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7513 - accuracy: 0.9506 - auc_6: 0.9870 - precision_6: 0.9506 - recall_6: 0.9506 - cohen_kappa: -0.7728 - f1_score: 0.9434\n",
      "Epoch 26: val_loss improved from 2.15945 to 2.15670, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 10s 494ms/step - loss: 1.7513 - accuracy: 0.9506 - auc_6: 0.9870 - precision_6: 0.9506 - recall_6: 0.9506 - cohen_kappa: -0.7728 - f1_score: 0.9434 - val_loss: 2.1567 - val_accuracy: 0.7467 - val_auc_6: 0.8524 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4879 - val_f1_score: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.8618 - accuracy: 0.8929 - auc_6: 0.9551 - precision_6: 0.8929 - recall_6: 0.8929 - cohen_kappa: -0.7041 - f1_score: 0.8703\n",
      "Epoch 27: val_loss improved from 2.15670 to 2.13879, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 511ms/step - loss: 1.8618 - accuracy: 0.8929 - auc_6: 0.9551 - precision_6: 0.8929 - recall_6: 0.8929 - cohen_kappa: -0.7041 - f1_score: 0.8703 - val_loss: 2.1388 - val_accuracy: 0.7467 - val_auc_6: 0.8501 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5571 - val_f1_score: 0.6460 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7305 - accuracy: 0.9583 - auc_6: 0.9878 - precision_6: 0.9583 - recall_6: 0.9583 - cohen_kappa: -0.7256 - f1_score: 0.9505\n",
      "Epoch 28: val_loss did not improve from 2.13879\n",
      "21/21 [==============================] - 10s 490ms/step - loss: 1.7305 - accuracy: 0.9583 - auc_6: 0.9878 - precision_6: 0.9583 - recall_6: 0.9583 - cohen_kappa: -0.7256 - f1_score: 0.9505 - val_loss: 2.1466 - val_accuracy: 0.7467 - val_auc_6: 0.8492 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5571 - val_f1_score: 0.6460 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6982 - accuracy: 0.9821 - auc_6: 0.9926 - precision_6: 0.9821 - recall_6: 0.9821 - cohen_kappa: -0.6969 - f1_score: 0.9783\n",
      "Epoch 29: val_loss did not improve from 2.13879\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 1.6982 - accuracy: 0.9821 - auc_6: 0.9926 - precision_6: 0.9821 - recall_6: 0.9821 - cohen_kappa: -0.6969 - f1_score: 0.9783 - val_loss: 2.1492 - val_accuracy: 0.7333 - val_auc_6: 0.8517 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.5398 - val_f1_score: 0.6197 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6847 - accuracy: 0.9762 - auc_6: 0.9984 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.7041 - f1_score: 0.9712\n",
      "Epoch 30: val_loss did not improve from 2.13879\n",
      "21/21 [==============================] - 11s 505ms/step - loss: 1.6847 - accuracy: 0.9762 - auc_6: 0.9984 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.7041 - f1_score: 0.9712 - val_loss: 2.1549 - val_accuracy: 0.7467 - val_auc_6: 0.8494 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5225 - val_f1_score: 0.6309 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7237 - accuracy: 0.9583 - auc_6: 0.9915 - precision_6: 0.9583 - recall_6: 0.9583 - cohen_kappa: -0.7670 - f1_score: 0.9520\n",
      "Epoch 31: val_loss did not improve from 2.13879\n",
      "21/21 [==============================] - 11s 503ms/step - loss: 1.7237 - accuracy: 0.9583 - auc_6: 0.9915 - precision_6: 0.9583 - recall_6: 0.9583 - cohen_kappa: -0.7670 - f1_score: 0.9520 - val_loss: 2.1606 - val_accuracy: 0.7467 - val_auc_6: 0.8521 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4879 - val_f1_score: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7575 - accuracy: 0.9405 - auc_6: 0.9806 - precision_6: 0.9405 - recall_6: 0.9405 - cohen_kappa: -0.7185 - f1_score: 0.9288\n",
      "Epoch 32: val_loss did not improve from 2.13879\n",
      "21/21 [==============================] - 10s 491ms/step - loss: 1.7575 - accuracy: 0.9405 - auc_6: 0.9806 - precision_6: 0.9405 - recall_6: 0.9405 - cohen_kappa: -0.7185 - f1_score: 0.9288 - val_loss: 2.1514 - val_accuracy: 0.7467 - val_auc_6: 0.8542 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5225 - val_f1_score: 0.6309 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7009 - accuracy: 0.9702 - auc_6: 0.9967 - precision_6: 0.9702 - recall_6: 0.9702 - cohen_kappa: -0.7113 - f1_score: 0.9642\n",
      "Epoch 33: val_loss did not improve from 2.13879\n",
      "21/21 [==============================] - 10s 493ms/step - loss: 1.7009 - accuracy: 0.9702 - auc_6: 0.9967 - precision_6: 0.9702 - recall_6: 0.9702 - cohen_kappa: -0.7113 - f1_score: 0.9642 - val_loss: 2.1502 - val_accuracy: 0.7333 - val_auc_6: 0.8548 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.5052 - val_f1_score: 0.6028 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6735 - accuracy: 0.9753 - auc_6: 0.9977 - precision_6: 0.9753 - recall_6: 0.9753 - cohen_kappa: -0.7300 - f1_score: 0.9707\n",
      "Epoch 34: val_loss did not improve from 2.13879\n",
      "21/21 [==============================] - 10s 476ms/step - loss: 1.6735 - accuracy: 0.9753 - auc_6: 0.9977 - precision_6: 0.9753 - recall_6: 0.9753 - cohen_kappa: -0.7300 - f1_score: 0.9707 - val_loss: 2.1545 - val_accuracy: 0.7467 - val_auc_6: 0.8564 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4879 - val_f1_score: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7360 - accuracy: 0.9286 - auc_6: 0.9824 - precision_6: 0.9286 - recall_6: 0.9286 - cohen_kappa: -0.6602 - f1_score: 0.9102\n",
      "Epoch 35: val_loss improved from 2.13879 to 2.13584, saving model to Vgg19.h5\n",
      "21/21 [==============================] - 11s 496ms/step - loss: 1.7360 - accuracy: 0.9286 - auc_6: 0.9824 - precision_6: 0.9286 - recall_6: 0.9286 - cohen_kappa: -0.6602 - f1_score: 0.9102 - val_loss: 2.1358 - val_accuracy: 0.7467 - val_auc_6: 0.8526 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.5225 - val_f1_score: 0.6309 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6716 - accuracy: 0.9630 - auc_6: 0.9985 - precision_6: 0.9630 - recall_6: 0.9630 - cohen_kappa: -0.6853 - f1_score: 0.9545\n",
      "Epoch 36: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 10s 474ms/step - loss: 1.6716 - accuracy: 0.9630 - auc_6: 0.9985 - precision_6: 0.9630 - recall_6: 0.9630 - cohen_kappa: -0.6853 - f1_score: 0.9545 - val_loss: 2.1454 - val_accuracy: 0.7333 - val_auc_6: 0.8532 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.5052 - val_f1_score: 0.6028 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6764 - accuracy: 0.9762 - auc_6: 0.9955 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.6750 - f1_score: 0.9705\n",
      "Epoch 37: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 10s 479ms/step - loss: 1.6764 - accuracy: 0.9762 - auc_6: 0.9955 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.6750 - f1_score: 0.9705 - val_loss: 2.1463 - val_accuracy: 0.7467 - val_auc_6: 0.8562 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4879 - val_f1_score: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6479 - accuracy: 0.9762 - auc_6: 0.9992 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.6897 - f1_score: 0.9708\n",
      "Epoch 38: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 10s 496ms/step - loss: 1.6479 - accuracy: 0.9762 - auc_6: 0.9992 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.6897 - f1_score: 0.9708 - val_loss: 2.1544 - val_accuracy: 0.7600 - val_auc_6: 0.8544 - val_precision_6: 0.7600 - val_recall_6: 0.7600 - val_cohen_kappa: -0.4706 - val_f1_score: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7065 - accuracy: 0.9762 - auc_6: 0.9933 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.7185 - f1_score: 0.9715\n",
      "Epoch 39: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 10s 489ms/step - loss: 1.7065 - accuracy: 0.9762 - auc_6: 0.9933 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.7185 - f1_score: 0.9715 - val_loss: 2.1624 - val_accuracy: 0.7733 - val_auc_6: 0.8527 - val_precision_6: 0.7733 - val_recall_6: 0.7733 - val_cohen_kappa: -0.4533 - val_f1_score: 0.6366 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6724 - accuracy: 0.9643 - auc_6: 0.9982 - precision_6: 0.9643 - recall_6: 0.9643 - cohen_kappa: -0.7185 - f1_score: 0.9573\n",
      "Epoch 40: val_loss did not improve from 2.13584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 10s 491ms/step - loss: 1.6724 - accuracy: 0.9643 - auc_6: 0.9982 - precision_6: 0.9643 - recall_6: 0.9643 - cohen_kappa: -0.7185 - f1_score: 0.9573 - val_loss: 2.1789 - val_accuracy: 0.7600 - val_auc_6: 0.8580 - val_precision_6: 0.7600 - val_recall_6: 0.7600 - val_cohen_kappa: -0.4360 - val_f1_score: 0.6048 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7348 - accuracy: 0.9691 - auc_6: 0.9953 - precision_6: 0.9691 - recall_6: 0.9691 - cohen_kappa: -0.7797 - f1_score: 0.9648\n",
      "Epoch 41: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 10s 495ms/step - loss: 1.7348 - accuracy: 0.9691 - auc_6: 0.9953 - precision_6: 0.9691 - recall_6: 0.9691 - cohen_kappa: -0.7797 - f1_score: 0.9648 - val_loss: 2.2368 - val_accuracy: 0.7467 - val_auc_6: 0.8549 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5709 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6533 - accuracy: 0.9881 - auc_6: 0.9989 - precision_6: 0.9881 - recall_6: 0.9881 - cohen_kappa: -0.7041 - f1_score: 0.9856\n",
      "Epoch 42: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 10s 492ms/step - loss: 1.6533 - accuracy: 0.9881 - auc_6: 0.9989 - precision_6: 0.9881 - recall_6: 0.9881 - cohen_kappa: -0.7041 - f1_score: 0.9856 - val_loss: 2.2378 - val_accuracy: 0.7467 - val_auc_6: 0.8539 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5709 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6653 - accuracy: 0.9762 - auc_6: 0.9984 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.7870 - f1_score: 0.9730\n",
      "Epoch 43: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 11s 501ms/step - loss: 1.6653 - accuracy: 0.9762 - auc_6: 0.9984 - precision_6: 0.9762 - recall_6: 0.9762 - cohen_kappa: -0.7870 - f1_score: 0.9730 - val_loss: 2.2752 - val_accuracy: 0.7467 - val_auc_6: 0.8530 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5709 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6878 - accuracy: 0.9568 - auc_6: 0.9934 - precision_6: 0.9568 - recall_6: 0.9568 - cohen_kappa: -0.6777 - f1_score: 0.9465\n",
      "Epoch 44: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 11s 523ms/step - loss: 1.6878 - accuracy: 0.9568 - auc_6: 0.9934 - precision_6: 0.9568 - recall_6: 0.9568 - cohen_kappa: -0.6777 - f1_score: 0.9465 - val_loss: 2.3184 - val_accuracy: 0.7333 - val_auc_6: 0.8446 - val_precision_6: 0.7333 - val_recall_6: 0.7333 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5347 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6980 - accuracy: 0.9568 - auc_6: 0.9906 - precision_6: 0.9568 - recall_6: 0.9568 - cohen_kappa: -0.7227 - f1_score: 0.9485Restoring model weights from the end of the best epoch: 35.\n",
      "\n",
      "Epoch 45: val_loss did not improve from 2.13584\n",
      "21/21 [==============================] - 12s 583ms/step - loss: 1.6980 - accuracy: 0.9568 - auc_6: 0.9906 - precision_6: 0.9568 - recall_6: 0.9568 - cohen_kappa: -0.7227 - f1_score: 0.9485 - val_loss: 2.2875 - val_accuracy: 0.7467 - val_auc_6: 0.8564 - val_precision_6: 0.7467 - val_recall_6: 0.7467 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5709 - lr: 1.0000e-05\n",
      "Epoch 45: early stopping\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Evaluation --------------------\n",
      "10/10 [==============================] - 4s 303ms/step - loss: 2.1358 - accuracy: 0.7467 - auc_6: 0.8526 - precision_6: 0.7467 - recall_6: 0.7467 - cohen_kappa: -0.5225 - f1_score: 0.6309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84        54\n",
      "           1       0.58      0.33      0.42        21\n",
      "\n",
      "    accuracy                           0.75        75\n",
      "   macro avg       0.68      0.62      0.63        75\n",
      "weighted avg       0.72      0.75      0.72        75\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vgg19 = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_tensor=None, input_shape=None)\n",
    "\n",
    "Vgg19 = model_training(MobileNet,'Vgg19.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00583210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T12:58:21.911762Z",
     "iopub.status.busy": "2023-06-21T12:58:21.910878Z",
     "iopub.status.idle": "2023-06-21T13:14:54.719869Z",
     "shell.execute_reply": "2023-06-21T13:14:54.719013Z",
     "shell.execute_reply.started": "2023-06-21T12:58:21.911725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "-------------------- Model Initialized --------------------\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.9621 - accuracy: 0.4226 - auc_7: 0.4112 - precision_7: 0.4226 - recall_7: 0.4226 - cohen_kappa: -0.9915 - f1_score: 0.4201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric CohenKappa implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.90928, saving model to Xception.h5\n",
      "21/21 [==============================] - 26s 707ms/step - loss: 2.9621 - accuracy: 0.4226 - auc_7: 0.4112 - precision_7: 0.4226 - recall_7: 0.4226 - cohen_kappa: -0.9915 - f1_score: 0.4201 - val_loss: 2.9093 - val_accuracy: 0.6800 - val_auc_7: 0.7708 - val_precision_7: 0.6800 - val_recall_7: 0.6800 - val_cohen_kappa: -0.7399 - val_f1_score: 0.6237 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.8433 - accuracy: 0.6420 - auc_7: 0.6676 - precision_7: 0.6420 - recall_7: 0.6420 - cohen_kappa: -0.9570 - f1_score: 0.6339\n",
      "Epoch 2: val_loss did not improve from 2.90928\n",
      "21/21 [==============================] - 14s 646ms/step - loss: 2.8433 - accuracy: 0.6420 - auc_7: 0.6676 - precision_7: 0.6420 - recall_7: 0.6420 - cohen_kappa: -0.9570 - f1_score: 0.6339 - val_loss: 2.9094 - val_accuracy: 0.6933 - val_auc_7: 0.7288 - val_precision_7: 0.6933 - val_recall_7: 0.6933 - val_cohen_kappa: -0.8415 - val_f1_score: 0.6645 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.7796 - accuracy: 0.6667 - auc_7: 0.7720 - precision_7: 0.6667 - recall_7: 0.6667 - cohen_kappa: -0.9498 - f1_score: 0.6579\n",
      "Epoch 3: val_loss improved from 2.90928 to 2.86759, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 694ms/step - loss: 2.7796 - accuracy: 0.6667 - auc_7: 0.7720 - precision_7: 0.6667 - recall_7: 0.6667 - cohen_kappa: -0.9498 - f1_score: 0.6579 - val_loss: 2.8676 - val_accuracy: 0.7200 - val_auc_7: 0.7801 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.6920 - val_f1_score: 0.6577 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.7058 - accuracy: 0.7381 - auc_7: 0.8238 - precision_7: 0.7381 - recall_7: 0.7381 - cohen_kappa: -0.8927 - f1_score: 0.7224\n",
      "Epoch 4: val_loss improved from 2.86759 to 2.82544, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 689ms/step - loss: 2.7058 - accuracy: 0.7381 - auc_7: 0.8238 - precision_7: 0.7381 - recall_7: 0.7381 - cohen_kappa: -0.8927 - f1_score: 0.7224 - val_loss: 2.8254 - val_accuracy: 0.7200 - val_auc_7: 0.8123 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.6590 - val_f1_score: 0.6476 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.6311 - accuracy: 0.7963 - auc_7: 0.8926 - precision_7: 0.7963 - recall_7: 0.7963 - cohen_kappa: -0.8197 - f1_score: 0.7739\n",
      "Epoch 5: val_loss improved from 2.82544 to 2.79350, saving model to Xception.h5\n",
      "21/21 [==============================] - 14s 692ms/step - loss: 2.6311 - accuracy: 0.7963 - auc_7: 0.8926 - precision_7: 0.7963 - recall_7: 0.7963 - cohen_kappa: -0.8197 - f1_score: 0.7739 - val_loss: 2.7935 - val_accuracy: 0.7200 - val_auc_7: 0.8172 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.5571 - val_f1_score: 0.6087 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.6128 - accuracy: 0.8642 - auc_7: 0.9064 - precision_7: 0.8642 - recall_7: 0.8642 - cohen_kappa: -0.8261 - f1_score: 0.8499\n",
      "Epoch 6: val_loss improved from 2.79350 to 2.77184, saving model to Xception.h5\n",
      "21/21 [==============================] - 14s 688ms/step - loss: 2.6128 - accuracy: 0.8642 - auc_7: 0.9064 - precision_7: 0.8642 - recall_7: 0.8642 - cohen_kappa: -0.8261 - f1_score: 0.8499 - val_loss: 2.7718 - val_accuracy: 0.7333 - val_auc_7: 0.8234 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.5052 - val_f1_score: 0.6028 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5723 - accuracy: 0.8631 - auc_7: 0.9197 - precision_7: 0.8631 - recall_7: 0.8631 - cohen_kappa: -0.8432 - f1_score: 0.8504\n",
      "Epoch 7: val_loss improved from 2.77184 to 2.75300, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 727ms/step - loss: 2.5723 - accuracy: 0.8631 - auc_7: 0.9197 - precision_7: 0.8631 - recall_7: 0.8631 - cohen_kappa: -0.8432 - f1_score: 0.8504 - val_loss: 2.7530 - val_accuracy: 0.7333 - val_auc_7: 0.8281 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.5052 - val_f1_score: 0.6028 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5327 - accuracy: 0.8631 - auc_7: 0.9231 - precision_7: 0.8631 - recall_7: 0.8631 - cohen_kappa: -0.8312 - f1_score: 0.8492\n",
      "Epoch 8: val_loss improved from 2.75300 to 2.74704, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 715ms/step - loss: 2.5327 - accuracy: 0.8631 - auc_7: 0.9231 - precision_7: 0.8631 - recall_7: 0.8631 - cohen_kappa: -0.8312 - f1_score: 0.8492 - val_loss: 2.7470 - val_accuracy: 0.7200 - val_auc_7: 0.8249 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5512 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5056 - accuracy: 0.8765 - auc_7: 0.9349 - precision_7: 0.8765 - recall_7: 0.8765 - cohen_kappa: -0.7300 - f1_score: 0.8537\n",
      "Epoch 9: val_loss did not improve from 2.74704\n",
      "21/21 [==============================] - 14s 660ms/step - loss: 2.5056 - accuracy: 0.8765 - auc_7: 0.9349 - precision_7: 0.8765 - recall_7: 0.8765 - cohen_kappa: -0.7300 - f1_score: 0.8537 - val_loss: 2.7471 - val_accuracy: 0.7333 - val_auc_7: 0.8211 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.4360 - val_f1_score: 0.5609 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4423 - accuracy: 0.8765 - auc_7: 0.9711 - precision_7: 0.8765 - recall_7: 0.8765 - cohen_kappa: -0.8000 - f1_score: 0.8611\n",
      "Epoch 10: val_loss did not improve from 2.74704\n",
      "21/21 [==============================] - 14s 653ms/step - loss: 2.4423 - accuracy: 0.8765 - auc_7: 0.9711 - precision_7: 0.8765 - recall_7: 0.8765 - cohen_kappa: -0.8000 - f1_score: 0.8611 - val_loss: 2.7521 - val_accuracy: 0.7200 - val_auc_7: 0.8197 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5257 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4553 - accuracy: 0.8988 - auc_7: 0.9691 - precision_7: 0.8988 - recall_7: 0.8988 - cohen_kappa: -0.8064 - f1_score: 0.8867\n",
      "Epoch 11: val_loss did not improve from 2.74704\n",
      "21/21 [==============================] - 14s 665ms/step - loss: 2.4553 - accuracy: 0.8988 - auc_7: 0.9691 - precision_7: 0.8988 - recall_7: 0.8988 - cohen_kappa: -0.8064 - f1_score: 0.8867 - val_loss: 2.7609 - val_accuracy: 0.7200 - val_auc_7: 0.8203 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4415 - accuracy: 0.9012 - auc_7: 0.9579 - precision_7: 0.9012 - recall_7: 0.9012 - cohen_kappa: -0.7587 - f1_score: 0.8855\n",
      "Epoch 12: val_loss did not improve from 2.74704\n",
      "21/21 [==============================] - 13s 594ms/step - loss: 2.4415 - accuracy: 0.9012 - auc_7: 0.9579 - precision_7: 0.9012 - recall_7: 0.9012 - cohen_kappa: -0.7587 - f1_score: 0.8855 - val_loss: 2.7509 - val_accuracy: 0.7200 - val_auc_7: 0.8215 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4081 - accuracy: 0.9198 - auc_7: 0.9704 - precision_7: 0.9198 - recall_7: 0.9198 - cohen_kappa: -0.8066 - f1_score: 0.9101\n",
      "Epoch 13: val_loss improved from 2.74704 to 2.74214, saving model to Xception.h5\n",
      "21/21 [==============================] - 16s 803ms/step - loss: 2.4081 - accuracy: 0.9198 - auc_7: 0.9704 - precision_7: 0.9198 - recall_7: 0.9198 - cohen_kappa: -0.8066 - f1_score: 0.9101 - val_loss: 2.7421 - val_accuracy: 0.7200 - val_auc_7: 0.8290 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3904 - accuracy: 0.9012 - auc_7: 0.9656 - precision_7: 0.9012 - recall_7: 0.9012 - cohen_kappa: -0.7728 - f1_score: 0.8867\n",
      "Epoch 14: val_loss improved from 2.74214 to 2.72073, saving model to Xception.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 17s 808ms/step - loss: 2.3904 - accuracy: 0.9012 - auc_7: 0.9656 - precision_7: 0.9012 - recall_7: 0.9012 - cohen_kappa: -0.7728 - f1_score: 0.8867 - val_loss: 2.7207 - val_accuracy: 0.7200 - val_auc_7: 0.8318 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3410 - accuracy: 0.9383 - auc_7: 0.9851 - precision_7: 0.9383 - recall_7: 0.9383 - cohen_kappa: -0.7728 - f1_score: 0.9292\n",
      "Epoch 15: val_loss did not improve from 2.72073\n",
      "21/21 [==============================] - 14s 681ms/step - loss: 2.3410 - accuracy: 0.9383 - auc_7: 0.9851 - precision_7: 0.9383 - recall_7: 0.9383 - cohen_kappa: -0.7728 - f1_score: 0.9292 - val_loss: 2.7222 - val_accuracy: 0.7333 - val_auc_7: 0.8340 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2941 - accuracy: 0.9630 - auc_7: 0.9959 - precision_7: 0.9630 - recall_7: 0.9630 - cohen_kappa: -0.7587 - f1_score: 0.9571\n",
      "Epoch 16: val_loss improved from 2.72073 to 2.71614, saving model to Xception.h5\n",
      "21/21 [==============================] - 16s 747ms/step - loss: 2.2941 - accuracy: 0.9630 - auc_7: 0.9959 - precision_7: 0.9630 - recall_7: 0.9630 - cohen_kappa: -0.7587 - f1_score: 0.9571 - val_loss: 2.7161 - val_accuracy: 0.7333 - val_auc_7: 0.8356 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2900 - accuracy: 0.9630 - auc_7: 0.9867 - precision_7: 0.9630 - recall_7: 0.9630 - cohen_kappa: -0.7728 - f1_score: 0.9575\n",
      "Epoch 17: val_loss improved from 2.71614 to 2.70763, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 745ms/step - loss: 2.2900 - accuracy: 0.9630 - auc_7: 0.9867 - precision_7: 0.9630 - recall_7: 0.9630 - cohen_kappa: -0.7728 - f1_score: 0.9575 - val_loss: 2.7076 - val_accuracy: 0.7333 - val_auc_7: 0.8327 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2505 - accuracy: 0.9702 - auc_7: 0.9968 - precision_7: 0.9702 - recall_7: 0.9702 - cohen_kappa: -0.7396 - f1_score: 0.9650\n",
      "Epoch 18: val_loss did not improve from 2.70763\n",
      "21/21 [==============================] - 14s 684ms/step - loss: 2.2505 - accuracy: 0.9702 - auc_7: 0.9968 - precision_7: 0.9702 - recall_7: 0.9702 - cohen_kappa: -0.7396 - f1_score: 0.9650 - val_loss: 2.7117 - val_accuracy: 0.7333 - val_auc_7: 0.8325 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3264 - accuracy: 0.9506 - auc_7: 0.9790 - precision_7: 0.9506 - recall_7: 0.9506 - cohen_kappa: -0.7300 - f1_score: 0.9415\n",
      "Epoch 19: val_loss improved from 2.70763 to 2.68015, saving model to Xception.h5\n",
      "21/21 [==============================] - 16s 749ms/step - loss: 2.3264 - accuracy: 0.9506 - auc_7: 0.9790 - precision_7: 0.9506 - recall_7: 0.9506 - cohen_kappa: -0.7300 - f1_score: 0.9415 - val_loss: 2.6801 - val_accuracy: 0.7333 - val_auc_7: 0.8361 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2512 - accuracy: 0.9643 - auc_7: 0.9931 - precision_7: 0.9643 - recall_7: 0.9643 - cohen_kappa: -0.7041 - f1_score: 0.9568\n",
      "Epoch 20: val_loss did not improve from 2.68015\n",
      "21/21 [==============================] - 14s 679ms/step - loss: 2.2512 - accuracy: 0.9643 - auc_7: 0.9931 - precision_7: 0.9643 - recall_7: 0.9643 - cohen_kappa: -0.7041 - f1_score: 0.9568 - val_loss: 2.6844 - val_accuracy: 0.7333 - val_auc_7: 0.8356 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3209 - accuracy: 0.9048 - auc_7: 0.9652 - precision_7: 0.9048 - recall_7: 0.9048 - cohen_kappa: -0.6897 - f1_score: 0.8833\n",
      "Epoch 21: val_loss improved from 2.68015 to 2.66889, saving model to Xception.h5\n",
      "21/21 [==============================] - 16s 756ms/step - loss: 2.3209 - accuracy: 0.9048 - auc_7: 0.9652 - precision_7: 0.9048 - recall_7: 0.9048 - cohen_kappa: -0.6897 - f1_score: 0.8833 - val_loss: 2.6689 - val_accuracy: 0.7333 - val_auc_7: 0.8316 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2339 - accuracy: 0.9702 - auc_7: 0.9914 - precision_7: 0.9702 - recall_7: 0.9702 - cohen_kappa: -0.6676 - f1_score: 0.9628\n",
      "Epoch 22: val_loss did not improve from 2.66889\n",
      "21/21 [==============================] - 15s 699ms/step - loss: 2.2339 - accuracy: 0.9702 - auc_7: 0.9914 - precision_7: 0.9702 - recall_7: 0.9702 - cohen_kappa: -0.6676 - f1_score: 0.9628 - val_loss: 2.6726 - val_accuracy: 0.7333 - val_auc_7: 0.8306 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2053 - accuracy: 0.9762 - auc_7: 0.9891 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.6602 - f1_score: 0.9701\n",
      "Epoch 23: val_loss did not improve from 2.66889\n",
      "21/21 [==============================] - 15s 703ms/step - loss: 2.2053 - accuracy: 0.9762 - auc_7: 0.9891 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.6602 - f1_score: 0.9701 - val_loss: 2.6818 - val_accuracy: 0.7333 - val_auc_7: 0.8228 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2345 - accuracy: 0.9259 - auc_7: 0.9877 - precision_7: 0.9259 - recall_7: 0.9259 - cohen_kappa: -0.6701 - f1_score: 0.9077\n",
      "Epoch 24: val_loss did not improve from 2.66889\n",
      "21/21 [==============================] - 14s 683ms/step - loss: 2.2345 - accuracy: 0.9259 - auc_7: 0.9877 - precision_7: 0.9259 - recall_7: 0.9259 - cohen_kappa: -0.6701 - f1_score: 0.9077 - val_loss: 2.6784 - val_accuracy: 0.7333 - val_auc_7: 0.8165 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1723 - accuracy: 0.9702 - auc_7: 0.9978 - precision_7: 0.9702 - recall_7: 0.9702 - cohen_kappa: -0.6378 - f1_score: 0.9618\n",
      "Epoch 25: val_loss did not improve from 2.66889\n",
      "21/21 [==============================] - 15s 714ms/step - loss: 2.1723 - accuracy: 0.9702 - auc_7: 0.9978 - precision_7: 0.9702 - recall_7: 0.9702 - cohen_kappa: -0.6378 - f1_score: 0.9618 - val_loss: 2.6704 - val_accuracy: 0.7333 - val_auc_7: 0.8196 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1869 - accuracy: 0.9444 - auc_7: 0.9929 - precision_7: 0.9444 - recall_7: 0.9444 - cohen_kappa: -0.6777 - f1_score: 0.9312\n",
      "Epoch 26: val_loss improved from 2.66889 to 2.63250, saving model to Xception.h5\n",
      "21/21 [==============================] - 16s 794ms/step - loss: 2.1869 - accuracy: 0.9444 - auc_7: 0.9929 - precision_7: 0.9444 - recall_7: 0.9444 - cohen_kappa: -0.6777 - f1_score: 0.9312 - val_loss: 2.6325 - val_accuracy: 0.7333 - val_auc_7: 0.8376 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1304 - accuracy: 0.9821 - auc_7: 0.9993 - precision_7: 0.9821 - recall_7: 0.9821 - cohen_kappa: -0.6378 - f1_score: 0.9771\n",
      "Epoch 27: val_loss improved from 2.63250 to 2.62243, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 694ms/step - loss: 2.1304 - accuracy: 0.9821 - auc_7: 0.9993 - precision_7: 0.9821 - recall_7: 0.9821 - cohen_kappa: -0.6378 - f1_score: 0.9771 - val_loss: 2.6224 - val_accuracy: 0.7333 - val_auc_7: 0.8380 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1151 - accuracy: 0.9881 - auc_7: 0.9994 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.7870 - f1_score: 0.9865\n",
      "Epoch 28: val_loss did not improve from 2.62243\n",
      "21/21 [==============================] - 15s 715ms/step - loss: 2.1151 - accuracy: 0.9881 - auc_7: 0.9994 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.7870 - f1_score: 0.9865 - val_loss: 2.6278 - val_accuracy: 0.7200 - val_auc_7: 0.8368 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.3507 - val_f1_score: 0.4608 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1067 - accuracy: 0.9762 - auc_7: 0.9994 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.7185 - f1_score: 0.9715\n",
      "Epoch 29: val_loss improved from 2.62243 to 2.61633, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 790ms/step - loss: 2.1067 - accuracy: 0.9762 - auc_7: 0.9994 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.7185 - f1_score: 0.9715 - val_loss: 2.6163 - val_accuracy: 0.7333 - val_auc_7: 0.8373 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1348 - accuracy: 0.9630 - auc_7: 0.9968 - precision_7: 0.9630 - recall_7: 0.9630 - cohen_kappa: -0.7300 - f1_score: 0.9561\n",
      "Epoch 30: val_loss improved from 2.61633 to 2.60293, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 700ms/step - loss: 2.1348 - accuracy: 0.9630 - auc_7: 0.9968 - precision_7: 0.9630 - recall_7: 0.9630 - cohen_kappa: -0.7300 - f1_score: 0.9561 - val_loss: 2.6029 - val_accuracy: 0.7333 - val_auc_7: 0.8393 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0662 - accuracy: 0.9938 - auc_7: 0.9998 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.7079 - f1_score: 0.9926\n",
      "Epoch 31: val_loss improved from 2.60293 to 2.59978, saving model to Xception.h5\n",
      "21/21 [==============================] - 14s 682ms/step - loss: 2.0662 - accuracy: 0.9938 - auc_7: 0.9998 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.7079 - f1_score: 0.9926 - val_loss: 2.5998 - val_accuracy: 0.7333 - val_auc_7: 0.8363 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1114 - accuracy: 0.9691 - auc_7: 0.9949 - precision_7: 0.9691 - recall_7: 0.9691 - cohen_kappa: -0.6929 - f1_score: 0.9623\n",
      "Epoch 32: val_loss did not improve from 2.59978\n",
      "21/21 [==============================] - 14s 636ms/step - loss: 2.1114 - accuracy: 0.9691 - auc_7: 0.9949 - precision_7: 0.9691 - recall_7: 0.9691 - cohen_kappa: -0.6929 - f1_score: 0.9623 - val_loss: 2.6070 - val_accuracy: 0.7333 - val_auc_7: 0.8320 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0665 - accuracy: 0.9762 - auc_7: 0.9957 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.6897 - f1_score: 0.9708\n",
      "Epoch 33: val_loss did not improve from 2.59978\n",
      "21/21 [==============================] - 14s 650ms/step - loss: 2.0665 - accuracy: 0.9762 - auc_7: 0.9957 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.6897 - f1_score: 0.9708 - val_loss: 2.6123 - val_accuracy: 0.7333 - val_auc_7: 0.8263 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0744 - accuracy: 0.9815 - auc_7: 0.9954 - precision_7: 0.9815 - recall_7: 0.9815 - cohen_kappa: -0.6158 - f1_score: 0.9757\n",
      "Epoch 34: val_loss did not improve from 2.59978\n",
      "21/21 [==============================] - 13s 616ms/step - loss: 2.0744 - accuracy: 0.9815 - auc_7: 0.9954 - precision_7: 0.9815 - recall_7: 0.9815 - cohen_kappa: -0.6158 - f1_score: 0.9757 - val_loss: 2.6137 - val_accuracy: 0.7333 - val_auc_7: 0.8208 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0252 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.7658 - f1_score: 0.9929\n",
      "Epoch 35: val_loss did not improve from 2.59978\n",
      "21/21 [==============================] - 13s 637ms/step - loss: 2.0252 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.7658 - f1_score: 0.9929 - val_loss: 2.6068 - val_accuracy: 0.7333 - val_auc_7: 0.8215 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0304 - accuracy: 0.9762 - auc_7: 0.9994 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.7185 - f1_score: 0.9715\n",
      "Epoch 36: val_loss improved from 2.59978 to 2.58614, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 698ms/step - loss: 2.0304 - accuracy: 0.9762 - auc_7: 0.9994 - precision_7: 0.9762 - recall_7: 0.9762 - cohen_kappa: -0.7185 - f1_score: 0.9715 - val_loss: 2.5861 - val_accuracy: 0.7467 - val_auc_7: 0.8229 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9965 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6750 - f1_score: 1.0000\n",
      "Epoch 37: val_loss improved from 2.58614 to 2.57914, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 696ms/step - loss: 1.9965 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6750 - f1_score: 1.0000 - val_loss: 2.5791 - val_accuracy: 0.7467 - val_auc_7: 0.8229 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9970 - accuracy: 0.9940 - auc_7: 0.9998 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6676 - f1_score: 0.9926\n",
      "Epoch 38: val_loss improved from 2.57914 to 2.55526, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 711ms/step - loss: 1.9970 - accuracy: 0.9940 - auc_7: 0.9998 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6676 - f1_score: 0.9926 - val_loss: 2.5553 - val_accuracy: 0.7467 - val_auc_7: 0.8281 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9727 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.6470 - f1_score: 0.9921\n",
      "Epoch 39: val_loss did not improve from 2.55526\n",
      "21/21 [==============================] - 14s 658ms/step - loss: 1.9727 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.6470 - f1_score: 0.9921 - val_loss: 2.5568 - val_accuracy: 0.7467 - val_auc_7: 0.8251 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9753 - accuracy: 0.9877 - auc_7: 0.9995 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.6701 - f1_score: 0.9846\n",
      "Epoch 40: val_loss improved from 2.55526 to 2.55174, saving model to Xception.h5\n",
      "21/21 [==============================] - 15s 709ms/step - loss: 1.9753 - accuracy: 0.9877 - auc_7: 0.9995 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.6701 - f1_score: 0.9846 - val_loss: 2.5517 - val_accuracy: 0.7467 - val_auc_7: 0.8228 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.9540 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7300 - f1_score: 1.0000\n",
      "Epoch 41: val_loss did not improve from 2.55174\n",
      "21/21 [==============================] - 14s 690ms/step - loss: 1.9540 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7300 - f1_score: 1.0000 - val_loss: 2.5531 - val_accuracy: 0.7467 - val_auc_7: 0.8222 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9305 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7004 - f1_score: 1.0000\n",
      "Epoch 42: val_loss did not improve from 2.55174\n",
      "21/21 [==============================] - 14s 665ms/step - loss: 1.9305 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7004 - f1_score: 1.0000 - val_loss: 2.5621 - val_accuracy: 0.7467 - val_auc_7: 0.8196 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9397 - accuracy: 0.9940 - auc_7: 0.9997 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.8190 - f1_score: 0.9934\n",
      "Epoch 43: val_loss did not improve from 2.55174\n",
      "21/21 [==============================] - 14s 642ms/step - loss: 1.9397 - accuracy: 0.9940 - auc_7: 0.9997 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.8190 - f1_score: 0.9934 - val_loss: 2.5656 - val_accuracy: 0.7467 - val_auc_7: 0.8238 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9133 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000\n",
      "Epoch 44: val_loss did not improve from 2.55174\n",
      "21/21 [==============================] - 12s 588ms/step - loss: 1.9133 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000 - val_loss: 2.5568 - val_accuracy: 0.7467 - val_auc_7: 0.8258 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9003 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6701 - f1_score: 1.0000\n",
      "Epoch 45: val_loss improved from 2.55174 to 2.54128, saving model to Xception.h5\n",
      "21/21 [==============================] - 14s 657ms/step - loss: 1.9003 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6701 - f1_score: 1.0000 - val_loss: 2.5413 - val_accuracy: 0.7467 - val_auc_7: 0.8236 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9092 - accuracy: 0.9821 - auc_7: 0.9990 - precision_7: 0.9821 - recall_7: 0.9821 - cohen_kappa: -0.6824 - f1_score: 0.9780\n",
      "Epoch 46: val_loss improved from 2.54128 to 2.52063, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 634ms/step - loss: 1.9092 - accuracy: 0.9821 - auc_7: 0.9990 - precision_7: 0.9821 - recall_7: 0.9821 - cohen_kappa: -0.6824 - f1_score: 0.9780 - val_loss: 2.5206 - val_accuracy: 0.7467 - val_auc_7: 0.8229 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8875 - accuracy: 0.9881 - auc_7: 0.9991 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.6897 - f1_score: 0.9854\n",
      "Epoch 47: val_loss improved from 2.52063 to 2.51115, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 627ms/step - loss: 1.8875 - accuracy: 0.9881 - auc_7: 0.9991 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.6897 - f1_score: 0.9854 - val_loss: 2.5111 - val_accuracy: 0.7467 - val_auc_7: 0.8242 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8673 - accuracy: 0.9877 - auc_7: 0.9998 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.7004 - f1_score: 0.9850\n",
      "Epoch 48: val_loss improved from 2.51115 to 2.50665, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 600ms/step - loss: 1.8673 - accuracy: 0.9877 - auc_7: 0.9998 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.7004 - f1_score: 0.9850 - val_loss: 2.5066 - val_accuracy: 0.7333 - val_auc_7: 0.8254 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8534 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000\n",
      "Epoch 49: val_loss improved from 2.50665 to 2.49242, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 600ms/step - loss: 1.8534 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000 - val_loss: 2.4924 - val_accuracy: 0.7333 - val_auc_7: 0.8260 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8434 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6528 - f1_score: 0.9925\n",
      "Epoch 50: val_loss improved from 2.49242 to 2.47302, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 613ms/step - loss: 1.8434 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6528 - f1_score: 0.9925 - val_loss: 2.4730 - val_accuracy: 0.7467 - val_auc_7: 0.8279 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8450 - accuracy: 0.9940 - auc_7: 0.9999 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6676 - f1_score: 0.9926\n",
      "Epoch 51: val_loss improved from 2.47302 to 2.43865, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 615ms/step - loss: 1.8450 - accuracy: 0.9940 - auc_7: 0.9999 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6676 - f1_score: 0.9926 - val_loss: 2.4386 - val_accuracy: 0.7467 - val_auc_7: 0.8322 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8376 - accuracy: 0.9877 - auc_7: 0.9990 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.8000 - f1_score: 0.9861\n",
      "Epoch 52: val_loss did not improve from 2.43865\n",
      "21/21 [==============================] - 12s 557ms/step - loss: 1.8376 - accuracy: 0.9877 - auc_7: 0.9990 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.8000 - f1_score: 0.9861 - val_loss: 2.4439 - val_accuracy: 0.7467 - val_auc_7: 0.8331 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8218 - accuracy: 0.9938 - auc_7: 0.9995 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.7933 - f1_score: 0.9930\n",
      "Epoch 53: val_loss did not improve from 2.43865\n",
      "21/21 [==============================] - 12s 555ms/step - loss: 1.8218 - accuracy: 0.9938 - auc_7: 0.9995 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.7933 - f1_score: 0.9930 - val_loss: 2.4571 - val_accuracy: 0.7467 - val_auc_7: 0.8244 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.7879 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7256 - f1_score: 0.9929\n",
      "Epoch 54: val_loss did not improve from 2.43865\n",
      "21/21 [==============================] - 12s 580ms/step - loss: 1.7879 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7256 - f1_score: 0.9929 - val_loss: 2.4560 - val_accuracy: 0.7467 - val_auc_7: 0.8238 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7863 - accuracy: 0.9940 - auc_7: 0.9997 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7113 - f1_score: 0.9928\n",
      "Epoch 55: val_loss improved from 2.43865 to 2.43052, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 595ms/step - loss: 1.7863 - accuracy: 0.9940 - auc_7: 0.9997 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7113 - f1_score: 0.9928 - val_loss: 2.4305 - val_accuracy: 0.7467 - val_auc_7: 0.8242 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7842 - accuracy: 0.9940 - auc_7: 0.9999 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7670 - f1_score: 0.9931\n",
      "Epoch 56: val_loss did not improve from 2.43052\n",
      "21/21 [==============================] - 12s 582ms/step - loss: 1.7842 - accuracy: 0.9940 - auc_7: 0.9999 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7670 - f1_score: 0.9931 - val_loss: 2.4362 - val_accuracy: 0.7467 - val_auc_7: 0.8229 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7659 - accuracy: 0.9940 - auc_7: 0.9997 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6969 - f1_score: 0.9928\n",
      "Epoch 57: val_loss improved from 2.43052 to 2.42462, saving model to Xception.h5\n",
      "21/21 [==============================] - 13s 614ms/step - loss: 1.7659 - accuracy: 0.9940 - auc_7: 0.9997 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6969 - f1_score: 0.9928 - val_loss: 2.4246 - val_accuracy: 0.7467 - val_auc_7: 0.8192 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7517 - accuracy: 0.9940 - auc_7: 0.9998 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7256 - f1_score: 0.9929\n",
      "Epoch 58: val_loss improved from 2.42462 to 2.41518, saving model to Xception.h5\n",
      "21/21 [==============================] - 14s 664ms/step - loss: 1.7517 - accuracy: 0.9940 - auc_7: 0.9998 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7256 - f1_score: 0.9929 - val_loss: 2.4152 - val_accuracy: 0.7467 - val_auc_7: 0.8236 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7318 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.5771 - f1_score: 0.9919\n",
      "Epoch 59: val_loss improved from 2.41518 to 2.39854, saving model to Xception.h5\n",
      "21/21 [==============================] - 14s 677ms/step - loss: 1.7318 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.5771 - f1_score: 0.9919 - val_loss: 2.3985 - val_accuracy: 0.7467 - val_auc_7: 0.8219 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7227 - accuracy: 0.9940 - auc_7: 0.9999 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6676 - f1_score: 0.9926\n",
      "Epoch 60: val_loss did not improve from 2.39854\n",
      "21/21 [==============================] - 13s 621ms/step - loss: 1.7227 - accuracy: 0.9940 - auc_7: 0.9999 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6676 - f1_score: 0.9926 - val_loss: 2.4057 - val_accuracy: 0.7467 - val_auc_7: 0.8183 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7053 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6152 - f1_score: 1.0000\n",
      "Epoch 61: val_loss improved from 2.39854 to 2.39375, saving model to Xception.h5\n",
      "21/21 [==============================] - 14s 660ms/step - loss: 1.7053 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6152 - f1_score: 1.0000 - val_loss: 2.3938 - val_accuracy: 0.7467 - val_auc_7: 0.8208 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6909 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7445 - f1_score: 1.0000\n",
      "Epoch 62: val_loss did not improve from 2.39375\n",
      "21/21 [==============================] - 13s 595ms/step - loss: 1.6909 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7445 - f1_score: 1.0000 - val_loss: 2.3942 - val_accuracy: 0.7467 - val_auc_7: 0.8196 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7023 - accuracy: 0.9881 - auc_7: 0.9996 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.6602 - f1_score: 0.9850\n",
      "Epoch 63: val_loss did not improve from 2.39375\n",
      "21/21 [==============================] - 13s 618ms/step - loss: 1.7023 - accuracy: 0.9881 - auc_7: 0.9996 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.6602 - f1_score: 0.9850 - val_loss: 2.3963 - val_accuracy: 0.7467 - val_auc_7: 0.8146 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6847 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6602 - f1_score: 1.0000\n",
      "Epoch 64: val_loss did not improve from 2.39375\n",
      "21/21 [==============================] - 15s 709ms/step - loss: 1.6847 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6602 - f1_score: 1.0000 - val_loss: 2.4122 - val_accuracy: 0.7467 - val_auc_7: 0.8126 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6634 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000\n",
      "Epoch 65: val_loss improved from 2.39375 to 2.38558, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 777ms/step - loss: 1.6634 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000 - val_loss: 2.3856 - val_accuracy: 0.7467 - val_auc_7: 0.8215 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6719 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7300 - f1_score: 1.0000\n",
      "Epoch 66: val_loss improved from 2.38558 to 2.29208, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 784ms/step - loss: 1.6719 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7300 - f1_score: 1.0000 - val_loss: 2.2921 - val_accuracy: 0.7467 - val_auc_7: 0.8402 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.6579 - accuracy: 0.9938 - auc_7: 0.9999 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.5842 - f1_score: 0.9916\n",
      "Epoch 67: val_loss improved from 2.29208 to 2.21692, saving model to Xception.h5\n",
      "21/21 [==============================] - 16s 808ms/step - loss: 1.6579 - accuracy: 0.9938 - auc_7: 0.9999 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.5842 - f1_score: 0.9916 - val_loss: 2.2169 - val_accuracy: 0.7467 - val_auc_7: 0.8503 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6312 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7728 - f1_score: 1.0000\n",
      "Epoch 68: val_loss did not improve from 2.21692\n",
      "21/21 [==============================] - 15s 727ms/step - loss: 1.6312 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7728 - f1_score: 1.0000 - val_loss: 2.2188 - val_accuracy: 0.7467 - val_auc_7: 0.8503 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6122 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6897 - f1_score: 1.0000\n",
      "Epoch 69: val_loss did not improve from 2.21692\n",
      "21/21 [==============================] - 15s 719ms/step - loss: 1.6122 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6897 - f1_score: 1.0000 - val_loss: 2.2170 - val_accuracy: 0.7467 - val_auc_7: 0.8501 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5975 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000\n",
      "Epoch 70: val_loss did not improve from 2.21692\n",
      "21/21 [==============================] - 16s 747ms/step - loss: 1.5975 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000 - val_loss: 2.2521 - val_accuracy: 0.7467 - val_auc_7: 0.8411 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5815 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000\n",
      "Epoch 71: val_loss did not improve from 2.21692\n",
      "21/21 [==============================] - 15s 734ms/step - loss: 1.5815 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000 - val_loss: 2.2280 - val_accuracy: 0.7467 - val_auc_7: 0.8412 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5795 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7004 - f1_score: 1.0000\n",
      "Epoch 72: val_loss improved from 2.21692 to 2.21207, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 782ms/step - loss: 1.5795 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7004 - f1_score: 1.0000 - val_loss: 2.2121 - val_accuracy: 0.7467 - val_auc_7: 0.8395 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5624 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000\n",
      "Epoch 73: val_loss improved from 2.21207 to 2.20781, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 833ms/step - loss: 1.5624 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000 - val_loss: 2.2078 - val_accuracy: 0.7467 - val_auc_7: 0.8412 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5610 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000\n",
      "Epoch 74: val_loss improved from 2.20781 to 2.20731, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 835ms/step - loss: 1.5610 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000 - val_loss: 2.2073 - val_accuracy: 0.7467 - val_auc_7: 0.8428 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.9940 - auc_7: 0.9998 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7534 - f1_score: 0.9931\n",
      "Epoch 75: val_loss did not improve from 2.20731\n",
      "21/21 [==============================] - 16s 736ms/step - loss: 1.5483 - accuracy: 0.9940 - auc_7: 0.9998 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.7534 - f1_score: 0.9931 - val_loss: 2.2221 - val_accuracy: 0.7467 - val_auc_7: 0.8322 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5371 - accuracy: 0.9877 - auc_7: 0.9995 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.7300 - f1_score: 0.9854\n",
      "Epoch 76: val_loss improved from 2.20731 to 2.20355, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 831ms/step - loss: 1.5371 - accuracy: 0.9877 - auc_7: 0.9995 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.7300 - f1_score: 0.9854 - val_loss: 2.2036 - val_accuracy: 0.7467 - val_auc_7: 0.8386 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5109 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6750 - f1_score: 1.0000\n",
      "Epoch 77: val_loss improved from 2.20355 to 2.18862, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 859ms/step - loss: 1.5109 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6750 - f1_score: 1.0000 - val_loss: 2.1886 - val_accuracy: 0.7467 - val_auc_7: 0.8363 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5082 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7185 - f1_score: 1.0000\n",
      "Epoch 78: val_loss improved from 2.18862 to 2.14127, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 834ms/step - loss: 1.5082 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7185 - f1_score: 1.0000 - val_loss: 2.1413 - val_accuracy: 0.7333 - val_auc_7: 0.8395 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5347 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4912 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6000 - f1_score: 1.0000\n",
      "Epoch 79: val_loss improved from 2.14127 to 2.13009, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 820ms/step - loss: 1.4912 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6000 - f1_score: 1.0000 - val_loss: 2.1301 - val_accuracy: 0.7333 - val_auc_7: 0.8409 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5347 - lr: 1.0000e-05\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.4994 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7465 - f1_score: 1.0000\n",
      "Epoch 80: val_loss did not improve from 2.13009\n",
      "21/21 [==============================] - 16s 761ms/step - loss: 1.4994 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7465 - f1_score: 1.0000 - val_loss: 2.1468 - val_accuracy: 0.7467 - val_auc_7: 0.8405 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4687 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6303 - f1_score: 1.0000\n",
      "Epoch 81: val_loss did not improve from 2.13009\n",
      "21/21 [==============================] - 15s 723ms/step - loss: 1.4687 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6303 - f1_score: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.7467 - val_auc_7: 0.8340 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4521 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6701 - f1_score: 1.0000\n",
      "Epoch 82: val_loss did not improve from 2.13009\n",
      "21/21 [==============================] - 16s 754ms/step - loss: 1.4521 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6701 - f1_score: 1.0000 - val_loss: 2.1411 - val_accuracy: 0.7467 - val_auc_7: 0.8364 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4397 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000\n",
      "Epoch 83: val_loss improved from 2.13009 to 2.12246, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 821ms/step - loss: 1.4397 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000 - val_loss: 2.1225 - val_accuracy: 0.7467 - val_auc_7: 0.8384 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4292 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000\n",
      "Epoch 84: val_loss improved from 2.12246 to 2.12228, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 804ms/step - loss: 1.4292 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7326 - f1_score: 1.0000 - val_loss: 2.1223 - val_accuracy: 0.7467 - val_auc_7: 0.8366 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4230 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000\n",
      "Epoch 85: val_loss improved from 2.12228 to 2.08676, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 825ms/step - loss: 1.4230 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000 - val_loss: 2.0868 - val_accuracy: 0.7467 - val_auc_7: 0.8407 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4109 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6453 - f1_score: 1.0000\n",
      "Epoch 86: val_loss did not improve from 2.08676\n",
      "21/21 [==============================] - 16s 761ms/step - loss: 1.4109 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6453 - f1_score: 1.0000 - val_loss: 2.0955 - val_accuracy: 0.7467 - val_auc_7: 0.8407 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3913 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7153 - f1_score: 1.0000\n",
      "Epoch 87: val_loss did not improve from 2.08676\n",
      "21/21 [==============================] - 15s 760ms/step - loss: 1.3913 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7153 - f1_score: 1.0000 - val_loss: 2.1105 - val_accuracy: 0.7333 - val_auc_7: 0.8366 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3963 - accuracy: 0.9881 - auc_7: 0.9996 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.5386 - f1_score: 0.9830\n",
      "Epoch 88: val_loss did not improve from 2.08676\n",
      "21/21 [==============================] - 16s 781ms/step - loss: 1.3963 - accuracy: 0.9881 - auc_7: 0.9996 - precision_7: 0.9881 - recall_7: 0.9881 - cohen_kappa: -0.5386 - f1_score: 0.9830 - val_loss: 2.1178 - val_accuracy: 0.7200 - val_auc_7: 0.8283 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3759 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7004 - f1_score: 1.0000\n",
      "Epoch 89: val_loss did not improve from 2.08676\n",
      "21/21 [==============================] - 16s 763ms/step - loss: 1.3759 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.7004 - f1_score: 1.0000 - val_loss: 2.0936 - val_accuracy: 0.7467 - val_auc_7: 0.8352 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3507 - val_f1_score: 0.5122 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3649 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000\n",
      "Epoch 90: val_loss improved from 2.08676 to 2.05271, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 822ms/step - loss: 1.3649 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6853 - f1_score: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.7467 - val_auc_7: 0.8468 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3507 - val_f1_score: 0.5122 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3588 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6378 - f1_score: 0.9924\n",
      "Epoch 91: val_loss improved from 2.05271 to 2.03384, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 851ms/step - loss: 1.3588 - accuracy: 0.9940 - auc_7: 1.0000 - precision_7: 0.9940 - recall_7: 0.9940 - cohen_kappa: -0.6378 - f1_score: 0.9924 - val_loss: 2.0338 - val_accuracy: 0.7467 - val_auc_7: 0.8441 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3507 - val_f1_score: 0.5122 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.9877 - auc_7: 0.9998 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.6853 - f1_score: 0.9848\n",
      "Epoch 92: val_loss improved from 2.03384 to 2.03236, saving model to Xception.h5\n",
      "21/21 [==============================] - 17s 833ms/step - loss: 1.3476 - accuracy: 0.9877 - auc_7: 0.9998 - precision_7: 0.9877 - recall_7: 0.9877 - cohen_kappa: -0.6853 - f1_score: 0.9848 - val_loss: 2.0324 - val_accuracy: 0.7333 - val_auc_7: 0.8375 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 1.3230 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6897 - f1_score: 1.0000\n",
      "Epoch 93: val_loss improved from 2.03236 to 2.01373, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 845ms/step - loss: 1.3230 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6897 - f1_score: 1.0000 - val_loss: 2.0137 - val_accuracy: 0.7333 - val_auc_7: 0.8398 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3201 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6701 - f1_score: 1.0000\n",
      "Epoch 94: val_loss improved from 2.01373 to 1.97957, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 835ms/step - loss: 1.3201 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6701 - f1_score: 1.0000 - val_loss: 1.9796 - val_accuracy: 0.7200 - val_auc_7: 0.8430 - val_precision_7: 0.7200 - val_recall_7: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3020 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6453 - f1_score: 1.0000\n",
      "Epoch 95: val_loss improved from 1.97957 to 1.94685, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 879ms/step - loss: 1.3020 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6453 - f1_score: 1.0000 - val_loss: 1.9468 - val_accuracy: 0.7333 - val_auc_7: 0.8411 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5347 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3011 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.5842 - f1_score: 0.9916\n",
      "Epoch 96: val_loss improved from 1.94685 to 1.91356, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 855ms/step - loss: 1.3011 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.5842 - f1_score: 0.9916 - val_loss: 1.9136 - val_accuracy: 0.7467 - val_auc_7: 0.8444 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5709 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2838 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.6158 - f1_score: 0.9919\n",
      "Epoch 97: val_loss improved from 1.91356 to 1.87796, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 846ms/step - loss: 1.2838 - accuracy: 0.9938 - auc_7: 1.0000 - precision_7: 0.9938 - recall_7: 0.9938 - cohen_kappa: -0.6158 - f1_score: 0.9919 - val_loss: 1.8780 - val_accuracy: 0.7467 - val_auc_7: 0.8468 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5709 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2690 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6236 - f1_score: 1.0000\n",
      "Epoch 98: val_loss did not improve from 1.87796\n",
      "21/21 [==============================] - 16s 748ms/step - loss: 1.2690 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6236 - f1_score: 1.0000 - val_loss: 1.8793 - val_accuracy: 0.7467 - val_auc_7: 0.8470 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2568 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6453 - f1_score: 1.0000\n",
      "Epoch 99: val_loss improved from 1.87796 to 1.85496, saving model to Xception.h5\n",
      "21/21 [==============================] - 18s 861ms/step - loss: 1.2568 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6453 - f1_score: 1.0000 - val_loss: 1.8550 - val_accuracy: 0.7467 - val_auc_7: 0.8514 - val_precision_7: 0.7467 - val_recall_7: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2419 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6152 - f1_score: 1.0000\n",
      "Epoch 100: val_loss improved from 1.85496 to 1.82621, saving model to Xception.h5\n",
      "21/21 [==============================] - 19s 927ms/step - loss: 1.2419 - accuracy: 1.0000 - auc_7: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - cohen_kappa: -0.6152 - f1_score: 1.0000 - val_loss: 1.8262 - val_accuracy: 0.7333 - val_auc_7: 0.8537 - val_precision_7: 0.7333 - val_recall_7: 0.7333 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5347 - lr: 1.0000e-05\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Evaluation --------------------\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 1.8262 - accuracy: 0.7333 - auc_7: 0.8537 - precision_7: 0.7333 - recall_7: 0.7333 - cohen_kappa: -0.4017 - f1_score: 0.5347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84        54\n",
      "           1       0.60      0.14      0.23        21\n",
      "\n",
      "    accuracy                           0.73        75\n",
      "   macro avg       0.67      0.55      0.53        75\n",
      "weighted avg       0.70      0.73      0.67        75\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xception = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_tensor=None, input_shape=None)\n",
    "\n",
    "Xception = model_training(Xception,'Xception.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90909286",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T13:14:54.721997Z",
     "iopub.status.busy": "2023-06-21T13:14:54.721405Z",
     "iopub.status.idle": "2023-06-21T13:29:29.896400Z",
     "shell.execute_reply": "2023-06-21T13:29:29.895554Z",
     "shell.execute_reply.started": "2023-06-21T13:14:54.721961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "-------------------- Model Initialized --------------------\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 3.0863 - accuracy: 0.5802 - auc_8: 0.6269 - precision_8: 0.5802 - recall_8: 0.5802 - cohen_kappa: -0.7865 - f1_score: 0.5233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric CohenKappa implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.12068, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 41s 1s/step - loss: 3.0863 - accuracy: 0.5802 - auc_8: 0.6269 - precision_8: 0.5802 - recall_8: 0.5802 - cohen_kappa: -0.7865 - f1_score: 0.5233 - val_loss: 3.1207 - val_accuracy: 0.4000 - val_auc_8: 0.3599 - val_precision_8: 0.4000 - val_recall_8: 0.4000 - val_cohen_kappa: -0.9943 - val_f1_score: 0.3983 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.7807 - accuracy: 0.7560 - auc_8: 0.8640 - precision_8: 0.7560 - recall_8: 0.7560 - cohen_kappa: -0.8190 - f1_score: 0.7290\n",
      "Epoch 2: val_loss improved from 3.12068 to 2.95281, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 17s 823ms/step - loss: 2.7807 - accuracy: 0.7560 - auc_8: 0.8640 - precision_8: 0.7560 - recall_8: 0.7560 - cohen_kappa: -0.8190 - f1_score: 0.7290 - val_loss: 2.9528 - val_accuracy: 0.5067 - val_auc_8: 0.6002 - val_precision_8: 0.5067 - val_recall_8: 0.5067 - val_cohen_kappa: -0.9943 - val_f1_score: 0.5053 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.7227 - accuracy: 0.7857 - auc_8: 0.8855 - precision_8: 0.7857 - recall_8: 0.7857 - cohen_kappa: -0.8127 - f1_score: 0.7610\n",
      "Epoch 3: val_loss improved from 2.95281 to 2.89367, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 15s 731ms/step - loss: 2.7227 - accuracy: 0.7857 - auc_8: 0.8855 - precision_8: 0.7857 - recall_8: 0.7857 - cohen_kappa: -0.8127 - f1_score: 0.7610 - val_loss: 2.8937 - val_accuracy: 0.6933 - val_auc_8: 0.7114 - val_precision_8: 0.6933 - val_recall_8: 0.6933 - val_cohen_kappa: -0.8672 - val_f1_score: 0.6699 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.6108 - accuracy: 0.8333 - auc_8: 0.9191 - precision_8: 0.8333 - recall_8: 0.8333 - cohen_kappa: -0.7465 - f1_score: 0.8050\n",
      "Epoch 4: val_loss improved from 2.89367 to 2.85412, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 18s 843ms/step - loss: 2.6108 - accuracy: 0.8333 - auc_8: 0.9191 - precision_8: 0.8333 - recall_8: 0.8333 - cohen_kappa: -0.7465 - f1_score: 0.8050 - val_loss: 2.8541 - val_accuracy: 0.6667 - val_auc_8: 0.7452 - val_precision_8: 0.6667 - val_recall_8: 0.6667 - val_cohen_kappa: -0.7854 - val_f1_score: 0.6211 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5988 - accuracy: 0.8512 - auc_8: 0.9255 - precision_8: 0.8512 - recall_8: 0.8512 - cohen_kappa: -0.7670 - f1_score: 0.8286\n",
      "Epoch 5: val_loss improved from 2.85412 to 2.78983, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 14s 651ms/step - loss: 2.5988 - accuracy: 0.8512 - auc_8: 0.9255 - precision_8: 0.8512 - recall_8: 0.8512 - cohen_kappa: -0.7670 - f1_score: 0.8286 - val_loss: 2.7898 - val_accuracy: 0.6933 - val_auc_8: 0.8037 - val_precision_8: 0.6933 - val_recall_8: 0.6933 - val_cohen_kappa: -0.6920 - val_f1_score: 0.6251 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5508 - accuracy: 0.8951 - auc_8: 0.9567 - precision_8: 0.8951 - recall_8: 0.8951 - cohen_kappa: -0.8066 - f1_score: 0.8825\n",
      "Epoch 6: val_loss improved from 2.78983 to 2.75356, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 13s 648ms/step - loss: 2.5508 - accuracy: 0.8951 - auc_8: 0.9567 - precision_8: 0.8951 - recall_8: 0.8951 - cohen_kappa: -0.8066 - f1_score: 0.8825 - val_loss: 2.7536 - val_accuracy: 0.7200 - val_auc_8: 0.8308 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.5915 - val_f1_score: 0.6233 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5634 - accuracy: 0.8889 - auc_8: 0.9319 - precision_8: 0.8889 - recall_8: 0.8889 - cohen_kappa: -0.8386 - f1_score: 0.8782\n",
      "Epoch 7: val_loss did not improve from 2.75356\n",
      "21/21 [==============================] - 12s 556ms/step - loss: 2.5634 - accuracy: 0.8889 - auc_8: 0.9319 - precision_8: 0.8889 - recall_8: 0.8889 - cohen_kappa: -0.8386 - f1_score: 0.8782 - val_loss: 2.7550 - val_accuracy: 0.7200 - val_auc_8: 0.8331 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.5225 - val_f1_score: 0.5921 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5229 - accuracy: 0.8951 - auc_8: 0.9346 - precision_8: 0.8951 - recall_8: 0.8951 - cohen_kappa: -0.6929 - f1_score: 0.8718\n",
      "Epoch 8: val_loss improved from 2.75356 to 2.74309, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 14s 654ms/step - loss: 2.5229 - accuracy: 0.8951 - auc_8: 0.9346 - precision_8: 0.8951 - recall_8: 0.8951 - cohen_kappa: -0.6929 - f1_score: 0.8718 - val_loss: 2.7431 - val_accuracy: 0.7200 - val_auc_8: 0.8409 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.4879 - val_f1_score: 0.5731 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4405 - accuracy: 0.9259 - auc_8: 0.9746 - precision_8: 0.9259 - recall_8: 0.9259 - cohen_kappa: -0.6853 - f1_score: 0.9089\n",
      "Epoch 9: val_loss improved from 2.74309 to 2.73405, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 14s 647ms/step - loss: 2.4405 - accuracy: 0.9259 - auc_8: 0.9746 - precision_8: 0.9259 - recall_8: 0.9259 - cohen_kappa: -0.6853 - f1_score: 0.9089 - val_loss: 2.7340 - val_accuracy: 0.7467 - val_auc_8: 0.8462 - val_precision_8: 0.7467 - val_recall_8: 0.7467 - val_cohen_kappa: -0.4879 - val_f1_score: 0.6137 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4578 - accuracy: 0.8810 - auc_8: 0.9631 - precision_8: 0.8810 - recall_8: 0.8810 - cohen_kappa: -0.7603 - f1_score: 0.8622\n",
      "Epoch 10: val_loss improved from 2.73405 to 2.73181, saving model to InceptionV3.h5\n",
      "21/21 [==============================] - 13s 630ms/step - loss: 2.4578 - accuracy: 0.8810 - auc_8: 0.9631 - precision_8: 0.8810 - recall_8: 0.8810 - cohen_kappa: -0.7603 - f1_score: 0.8622 - val_loss: 2.7318 - val_accuracy: 0.7600 - val_auc_8: 0.8508 - val_precision_8: 0.7600 - val_recall_8: 0.7600 - val_cohen_kappa: -0.4706 - val_f1_score: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4370 - accuracy: 0.9136 - auc_8: 0.9742 - precision_8: 0.9136 - recall_8: 0.9136 - cohen_kappa: -0.7587 - f1_score: 0.8998\n",
      "Epoch 11: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 566ms/step - loss: 2.4370 - accuracy: 0.9136 - auc_8: 0.9742 - precision_8: 0.9136 - recall_8: 0.9136 - cohen_kappa: -0.7587 - f1_score: 0.8998 - val_loss: 2.7419 - val_accuracy: 0.7600 - val_auc_8: 0.8471 - val_precision_8: 0.7600 - val_recall_8: 0.7600 - val_cohen_kappa: -0.4706 - val_f1_score: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3719 - accuracy: 0.9568 - auc_8: 0.9946 - precision_8: 0.9568 - recall_8: 0.9568 - cohen_kappa: -0.7516 - f1_score: 0.9497\n",
      "Epoch 12: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 563ms/step - loss: 2.3719 - accuracy: 0.9568 - auc_8: 0.9946 - precision_8: 0.9568 - recall_8: 0.9568 - cohen_kappa: -0.7516 - f1_score: 0.9497 - val_loss: 2.7871 - val_accuracy: 0.7200 - val_auc_8: 0.8260 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.4188 - val_f1_score: 0.5257 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4249 - accuracy: 0.9107 - auc_8: 0.9652 - precision_8: 0.9107 - recall_8: 0.9107 - cohen_kappa: -0.7396 - f1_score: 0.8950\n",
      "Epoch 13: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 548ms/step - loss: 2.4249 - accuracy: 0.9107 - auc_8: 0.9652 - precision_8: 0.9107 - recall_8: 0.9107 - cohen_kappa: -0.7396 - f1_score: 0.8950 - val_loss: 2.8011 - val_accuracy: 0.7200 - val_auc_8: 0.8153 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5512 - lr: 1.0000e-05\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - ETA: 0s - loss: 2.3666 - accuracy: 0.9444 - auc_8: 0.9857 - precision_8: 0.9444 - recall_8: 0.9444 - cohen_kappa: -0.6624 - f1_score: 0.9303\n",
      "Epoch 14: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 11s 529ms/step - loss: 2.3666 - accuracy: 0.9444 - auc_8: 0.9857 - precision_8: 0.9444 - recall_8: 0.9444 - cohen_kappa: -0.6624 - f1_score: 0.9303 - val_loss: 2.8082 - val_accuracy: 0.7067 - val_auc_8: 0.8103 - val_precision_8: 0.7067 - val_recall_8: 0.7067 - val_cohen_kappa: -0.4706 - val_f1_score: 0.5417 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4022 - accuracy: 0.9259 - auc_8: 0.9833 - precision_8: 0.9259 - recall_8: 0.9259 - cohen_kappa: -0.7587 - f1_score: 0.9141\n",
      "Epoch 15: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 560ms/step - loss: 2.4022 - accuracy: 0.9259 - auc_8: 0.9833 - precision_8: 0.9259 - recall_8: 0.9259 - cohen_kappa: -0.7587 - f1_score: 0.9141 - val_loss: 2.8126 - val_accuracy: 0.7067 - val_auc_8: 0.8123 - val_precision_8: 0.7067 - val_recall_8: 0.7067 - val_cohen_kappa: -0.4706 - val_f1_score: 0.5417 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3506 - accuracy: 0.9405 - auc_8: 0.9895 - precision_8: 0.9405 - recall_8: 0.9405 - cohen_kappa: -0.7326 - f1_score: 0.9296\n",
      "Epoch 16: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 575ms/step - loss: 2.3506 - accuracy: 0.9405 - auc_8: 0.9895 - precision_8: 0.9405 - recall_8: 0.9405 - cohen_kappa: -0.7326 - f1_score: 0.9296 - val_loss: 2.8293 - val_accuracy: 0.7200 - val_auc_8: 0.8124 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5512 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3589 - accuracy: 0.9321 - auc_8: 0.9798 - precision_8: 0.9321 - recall_8: 0.9321 - cohen_kappa: -0.6624 - f1_score: 0.9148\n",
      "Epoch 17: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 556ms/step - loss: 2.3589 - accuracy: 0.9321 - auc_8: 0.9798 - precision_8: 0.9321 - recall_8: 0.9321 - cohen_kappa: -0.6624 - f1_score: 0.9148 - val_loss: 2.8230 - val_accuracy: 0.7067 - val_auc_8: 0.8148 - val_precision_8: 0.7067 - val_recall_8: 0.7067 - val_cohen_kappa: -0.4706 - val_f1_score: 0.5417 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2932 - accuracy: 0.9815 - auc_8: 0.9976 - precision_8: 0.9815 - recall_8: 0.9815 - cohen_kappa: -0.7797 - f1_score: 0.9789\n",
      "Epoch 18: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 553ms/step - loss: 2.2932 - accuracy: 0.9815 - auc_8: 0.9976 - precision_8: 0.9815 - recall_8: 0.9815 - cohen_kappa: -0.7797 - f1_score: 0.9789 - val_loss: 2.8072 - val_accuracy: 0.7200 - val_auc_8: 0.8190 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5512 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3329 - accuracy: 0.9444 - auc_8: 0.9872 - precision_8: 0.9444 - recall_8: 0.9444 - cohen_kappa: -0.7516 - f1_score: 0.9353\n",
      "Epoch 19: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 552ms/step - loss: 2.3329 - accuracy: 0.9444 - auc_8: 0.9872 - precision_8: 0.9444 - recall_8: 0.9444 - cohen_kappa: -0.7516 - f1_score: 0.9353 - val_loss: 2.8172 - val_accuracy: 0.7333 - val_auc_8: 0.8229 - val_precision_8: 0.7333 - val_recall_8: 0.7333 - val_cohen_kappa: -0.4360 - val_f1_score: 0.5609 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3119 - accuracy: 0.9524 - auc_8: 0.9913 - precision_8: 0.9524 - recall_8: 0.9524 - cohen_kappa: -0.6750 - f1_score: 0.9409Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Epoch 20: val_loss did not improve from 2.73181\n",
      "21/21 [==============================] - 12s 591ms/step - loss: 2.3119 - accuracy: 0.9524 - auc_8: 0.9913 - precision_8: 0.9524 - recall_8: 0.9524 - cohen_kappa: -0.6750 - f1_score: 0.9409 - val_loss: 2.8073 - val_accuracy: 0.7200 - val_auc_8: 0.8247 - val_precision_8: 0.7200 - val_recall_8: 0.7200 - val_cohen_kappa: -0.4533 - val_f1_score: 0.5512 - lr: 1.0000e-05\n",
      "Epoch 20: early stopping\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Evaluation --------------------\n",
      "10/10 [==============================] - 3s 246ms/step - loss: 2.7318 - accuracy: 0.7600 - auc_8: 0.8508 - precision_8: 0.7600 - recall_8: 0.7600 - cohen_kappa: -0.4706 - f1_score: 0.6250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85        54\n",
      "           1       0.67      0.29      0.40        21\n",
      "\n",
      "    accuracy                           0.76        75\n",
      "   macro avg       0.72      0.62      0.62        75\n",
      "weighted avg       0.74      0.76      0.72        75\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "InceptionV3 = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_tensor=None, input_shape=None)\n",
    "\n",
    "InceptionV3 = model_training(InceptionV3,'InceptionV3.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d2005d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T13:29:29.898671Z",
     "iopub.status.busy": "2023-06-21T13:29:29.898080Z",
     "iopub.status.idle": "2023-06-21T13:46:26.844676Z",
     "shell.execute_reply": "2023-06-21T13:46:26.843763Z",
     "shell.execute_reply.started": "2023-06-21T13:29:29.898636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "-------------------- Model Initialized --------------------\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5552 - accuracy: 0.7500 - auc_9: 0.7982 - precision_9: 0.7500 - recall_9: 0.7500 - cohen_kappa: -0.4305 - f1_score: 0.5846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric CohenKappa implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.14713, saving model to DenseNet121.h5\n",
      "21/21 [==============================] - 33s 767ms/step - loss: 2.5552 - accuracy: 0.7500 - auc_9: 0.7982 - precision_9: 0.7500 - recall_9: 0.7500 - cohen_kappa: -0.4305 - f1_score: 0.5846 - val_loss: 2.1471 - val_accuracy: 0.7867 - val_auc_9: 0.8361 - val_precision_9: 0.7867 - val_recall_9: 0.7867 - val_cohen_kappa: -0.5052 - val_f1_score: 0.6822 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2626 - accuracy: 0.8333 - auc_9: 0.8860 - precision_9: 0.8333 - recall_9: 0.8333 - cohen_kappa: -0.5386 - f1_score: 0.7619\n",
      "Epoch 2: val_loss improved from 2.14713 to 2.12212, saving model to DenseNet121.h5\n",
      "21/21 [==============================] - 15s 702ms/step - loss: 2.2626 - accuracy: 0.8333 - auc_9: 0.8860 - precision_9: 0.8333 - recall_9: 0.8333 - cohen_kappa: -0.5386 - f1_score: 0.7619 - val_loss: 2.1221 - val_accuracy: 0.8000 - val_auc_9: 0.8484 - val_precision_9: 0.8000 - val_recall_9: 0.8000 - val_cohen_kappa: -0.4533 - val_f1_score: 0.6794 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1666 - accuracy: 0.8148 - auc_9: 0.9081 - precision_9: 0.8148 - recall_9: 0.8148 - cohen_kappa: -0.6547 - f1_score: 0.7660\n",
      "Epoch 3: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 14s 675ms/step - loss: 2.1666 - accuracy: 0.8148 - auc_9: 0.9081 - precision_9: 0.8148 - recall_9: 0.8148 - cohen_kappa: -0.6547 - f1_score: 0.7660 - val_loss: 2.1465 - val_accuracy: 0.7600 - val_auc_9: 0.8417 - val_precision_9: 0.7600 - val_recall_9: 0.7600 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5813 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9780 - accuracy: 0.8690 - auc_9: 0.9446 - precision_9: 0.8690 - recall_9: 0.8690 - cohen_kappa: -0.7326 - f1_score: 0.8451\n",
      "Epoch 4: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 13s 603ms/step - loss: 1.9780 - accuracy: 0.8690 - auc_9: 0.9446 - precision_9: 0.8690 - recall_9: 0.8690 - cohen_kappa: -0.7326 - f1_score: 0.8451 - val_loss: 2.1546 - val_accuracy: 0.7467 - val_auc_9: 0.8420 - val_precision_9: 0.7467 - val_recall_9: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8972 - accuracy: 0.8631 - auc_9: 0.9502 - precision_9: 0.8631 - recall_9: 0.8631 - cohen_kappa: -0.8190 - f1_score: 0.8480\n",
      "Epoch 5: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 12s 583ms/step - loss: 1.8972 - accuracy: 0.8631 - auc_9: 0.9502 - precision_9: 0.8631 - recall_9: 0.8631 - cohen_kappa: -0.8190 - f1_score: 0.8480 - val_loss: 2.1802 - val_accuracy: 0.7467 - val_auc_9: 0.8364 - val_precision_9: 0.7467 - val_recall_9: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8964 - accuracy: 0.8690 - auc_9: 0.9410 - precision_9: 0.8690 - recall_9: 0.8690 - cohen_kappa: -0.7603 - f1_score: 0.8484\n",
      "Epoch 6: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 13s 608ms/step - loss: 1.8964 - accuracy: 0.8690 - auc_9: 0.9410 - precision_9: 0.8690 - recall_9: 0.8690 - cohen_kappa: -0.7603 - f1_score: 0.8484 - val_loss: 2.1702 - val_accuracy: 0.7467 - val_auc_9: 0.8404 - val_precision_9: 0.7467 - val_recall_9: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8434 - accuracy: 0.9012 - auc_9: 0.9693 - precision_9: 0.9012 - recall_9: 0.9012 - cohen_kappa: -0.6853 - f1_score: 0.8786\n",
      "Epoch 7: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 14s 638ms/step - loss: 1.8434 - accuracy: 0.9012 - auc_9: 0.9693 - precision_9: 0.9012 - recall_9: 0.9012 - cohen_kappa: -0.6853 - f1_score: 0.8786 - val_loss: 2.1625 - val_accuracy: 0.7467 - val_auc_9: 0.8414 - val_precision_9: 0.7467 - val_recall_9: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8659 - accuracy: 0.9167 - auc_9: 0.9546 - precision_9: 0.9167 - recall_9: 0.9167 - cohen_kappa: -0.7326 - f1_score: 0.9015\n",
      "Epoch 8: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 16s 784ms/step - loss: 1.8659 - accuracy: 0.9167 - auc_9: 0.9546 - precision_9: 0.9167 - recall_9: 0.9167 - cohen_kappa: -0.7326 - f1_score: 0.9015 - val_loss: 2.1775 - val_accuracy: 0.7467 - val_auc_9: 0.8411 - val_precision_9: 0.7467 - val_recall_9: 0.7467 - val_cohen_kappa: -0.3846 - val_f1_score: 0.5440 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7695 - accuracy: 0.9405 - auc_9: 0.9866 - precision_9: 0.9405 - recall_9: 0.9405 - cohen_kappa: -0.7870 - f1_score: 0.9324\n",
      "Epoch 9: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 13s 614ms/step - loss: 1.7695 - accuracy: 0.9405 - auc_9: 0.9866 - precision_9: 0.9405 - recall_9: 0.9405 - cohen_kappa: -0.7870 - f1_score: 0.9324 - val_loss: 2.1840 - val_accuracy: 0.7333 - val_auc_9: 0.8409 - val_precision_9: 0.7333 - val_recall_9: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7829 - accuracy: 0.9198 - auc_9: 0.9785 - precision_9: 0.9198 - recall_9: 0.9198 - cohen_kappa: -0.7797 - f1_score: 0.9084\n",
      "Epoch 10: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 13s 593ms/step - loss: 1.7829 - accuracy: 0.9198 - auc_9: 0.9785 - precision_9: 0.9198 - recall_9: 0.9198 - cohen_kappa: -0.7797 - f1_score: 0.9084 - val_loss: 2.1884 - val_accuracy: 0.7333 - val_auc_9: 0.8389 - val_precision_9: 0.7333 - val_recall_9: 0.7333 - val_cohen_kappa: -0.3676 - val_f1_score: 0.5040 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7574 - accuracy: 0.9259 - auc_9: 0.9811 - precision_9: 0.9259 - recall_9: 0.9259 - cohen_kappa: -0.7153 - f1_score: 0.9112\n",
      "Epoch 11: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 13s 596ms/step - loss: 1.7574 - accuracy: 0.9259 - auc_9: 0.9811 - precision_9: 0.9259 - recall_9: 0.9259 - cohen_kappa: -0.7153 - f1_score: 0.9112 - val_loss: 2.1718 - val_accuracy: 0.7200 - val_auc_9: 0.8393 - val_precision_9: 0.7200 - val_recall_9: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7651 - accuracy: 0.9345 - auc_9: 0.9853 - precision_9: 0.9345 - recall_9: 0.9345 - cohen_kappa: -0.6824 - f1_score: 0.9193Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 12: val_loss did not improve from 2.12212\n",
      "21/21 [==============================] - 13s 625ms/step - loss: 1.7651 - accuracy: 0.9345 - auc_9: 0.9853 - precision_9: 0.9345 - recall_9: 0.9345 - cohen_kappa: -0.6824 - f1_score: 0.9193 - val_loss: 2.1684 - val_accuracy: 0.7200 - val_auc_9: 0.8348 - val_precision_9: 0.7200 - val_recall_9: 0.7200 - val_cohen_kappa: -0.3846 - val_f1_score: 0.4960 - lr: 1.0000e-05\n",
      "Epoch 12: early stopping\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Evaluation --------------------\n",
      "10/10 [==============================] - 3s 243ms/step - loss: 2.1221 - accuracy: 0.8000 - auc_9: 0.8484 - precision_9: 0.8000 - recall_9: 0.8000 - cohen_kappa: -0.4533 - f1_score: 0.6794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88        54\n",
      "           1       0.88      0.33      0.48        21\n",
      "\n",
      "    accuracy                           0.80        75\n",
      "   macro avg       0.83      0.66      0.68        75\n",
      "weighted avg       0.81      0.80      0.77        75\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DenseNet121 = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False, input_tensor=None, input_shape=None)\n",
    "\n",
    "DenseNet121 = model_training(DenseNet121,'DenseNet121.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff60e0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:30:16.461176Z",
     "iopub.status.busy": "2023-06-21T17:30:16.460272Z",
     "iopub.status.idle": "2023-06-21T17:46:28.836038Z",
     "shell.execute_reply": "2023-06-21T17:46:28.835102Z",
     "shell.execute_reply.started": "2023-06-21T17:30:16.461122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "-------------------- Model Initialized --------------------\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3289 - accuracy: 0.6481 - auc_10: 0.6821 - precision_10: 0.6481 - recall_10: 0.6481 - cohen_kappa: -0.8447 - f1_score: 0.6158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric CohenKappa implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n",
      "C:\\Users\\HSSL77\\anaconda3\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\engine\\training.py:2034: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.79396, saving model to Vgg16.h5\n",
      "21/21 [==============================] - 24s 841ms/step - loss: 2.3289 - accuracy: 0.6481 - auc_10: 0.6821 - precision_10: 0.6481 - recall_10: 0.6481 - cohen_kappa: -0.8447 - f1_score: 0.6158 - val_loss: 1.7940 - val_accuracy: 0.6933 - val_auc_10: 0.7893 - val_precision_10: 0.6933 - val_recall_10: 0.6933 - val_cohen_kappa: -0.7854 - val_f1_score: 0.6514 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5495 - accuracy: 0.8393 - auc_10: 0.9105 - precision_10: 0.8393 - recall_10: 0.8393 - cohen_kappa: -0.7670 - f1_score: 0.8149\n",
      "Epoch 2: val_loss improved from 1.79396 to 1.77667, saving model to Vgg16.h5\n",
      "21/21 [==============================] - 14s 683ms/step - loss: 1.5495 - accuracy: 0.8393 - auc_10: 0.9105 - precision_10: 0.8393 - recall_10: 0.8393 - cohen_kappa: -0.7670 - f1_score: 0.8149 - val_loss: 1.7767 - val_accuracy: 0.7733 - val_auc_10: 0.8437 - val_precision_10: 0.7733 - val_recall_10: 0.7733 - val_cohen_kappa: -0.4879 - val_f1_score: 0.6544 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4294 - accuracy: 0.9167 - auc_10: 0.9641 - precision_10: 0.9167 - recall_10: 0.9167 - cohen_kappa: -0.7738 - f1_score: 0.9045\n",
      "Epoch 3: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 14s 656ms/step - loss: 1.4294 - accuracy: 0.9167 - auc_10: 0.9641 - precision_10: 0.9167 - recall_10: 0.9167 - cohen_kappa: -0.7738 - f1_score: 0.9045 - val_loss: 1.9244 - val_accuracy: 0.7867 - val_auc_10: 0.8480 - val_precision_10: 0.7867 - val_recall_10: 0.7867 - val_cohen_kappa: -0.4706 - val_f1_score: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4194 - accuracy: 0.9074 - auc_10: 0.9659 - precision_10: 0.9074 - recall_10: 0.9074 - cohen_kappa: -0.8066 - f1_score: 0.8963\n",
      "Epoch 4: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 15s 720ms/step - loss: 1.4194 - accuracy: 0.9074 - auc_10: 0.9659 - precision_10: 0.9074 - recall_10: 0.9074 - cohen_kappa: -0.8066 - f1_score: 0.8963 - val_loss: 1.9161 - val_accuracy: 0.7867 - val_auc_10: 0.8521 - val_precision_10: 0.7867 - val_recall_10: 0.7867 - val_cohen_kappa: -0.4360 - val_f1_score: 0.6487 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3766 - accuracy: 0.9643 - auc_10: 0.9822 - precision_10: 0.9643 - recall_10: 0.9643 - cohen_kappa: -0.6750 - f1_score: 0.9557\n",
      "Epoch 5: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 14s 682ms/step - loss: 1.3766 - accuracy: 0.9643 - auc_10: 0.9822 - precision_10: 0.9643 - recall_10: 0.9643 - cohen_kappa: -0.6750 - f1_score: 0.9557 - val_loss: 1.8343 - val_accuracy: 0.7733 - val_auc_10: 0.8624 - val_precision_10: 0.7733 - val_recall_10: 0.7733 - val_cohen_kappa: -0.4879 - val_f1_score: 0.6544 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2817 - accuracy: 0.9762 - auc_10: 0.9970 - precision_10: 0.9762 - recall_10: 0.9762 - cohen_kappa: -0.6303 - f1_score: 0.9692\n",
      "Epoch 6: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 15s 710ms/step - loss: 1.2817 - accuracy: 0.9762 - auc_10: 0.9970 - precision_10: 0.9762 - recall_10: 0.9762 - cohen_kappa: -0.6303 - f1_score: 0.9692 - val_loss: 2.0891 - val_accuracy: 0.7733 - val_auc_10: 0.8320 - val_precision_10: 0.7733 - val_recall_10: 0.7733 - val_cohen_kappa: -0.4188 - val_f1_score: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2539 - accuracy: 0.9821 - auc_10: 0.9991 - precision_10: 0.9821 - recall_10: 0.9821 - cohen_kappa: -0.6228 - f1_score: 0.9767\n",
      "Epoch 7: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 15s 723ms/step - loss: 1.2539 - accuracy: 0.9821 - auc_10: 0.9991 - precision_10: 0.9821 - recall_10: 0.9821 - cohen_kappa: -0.6228 - f1_score: 0.9767 - val_loss: 2.1065 - val_accuracy: 0.7733 - val_auc_10: 0.8409 - val_precision_10: 0.7733 - val_recall_10: 0.7733 - val_cohen_kappa: -0.4533 - val_f1_score: 0.6366 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3170 - accuracy: 0.9444 - auc_10: 0.9878 - precision_10: 0.9444 - recall_10: 0.9444 - cohen_kappa: -0.5842 - f1_score: 0.9247\n",
      "Epoch 8: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 15s 728ms/step - loss: 1.3170 - accuracy: 0.9444 - auc_10: 0.9878 - precision_10: 0.9444 - recall_10: 0.9444 - cohen_kappa: -0.5842 - f1_score: 0.9247 - val_loss: 1.8020 - val_accuracy: 0.7600 - val_auc_10: 0.8734 - val_precision_10: 0.7600 - val_recall_10: 0.7600 - val_cohen_kappa: -0.6423 - val_f1_score: 0.6932 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2970 - accuracy: 0.9524 - auc_10: 0.9918 - precision_10: 0.9524 - recall_10: 0.9524 - cohen_kappa: -0.6897 - f1_score: 0.9417\n",
      "Epoch 9: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 16s 750ms/step - loss: 1.2970 - accuracy: 0.9524 - auc_10: 0.9918 - precision_10: 0.9524 - recall_10: 0.9524 - cohen_kappa: -0.6897 - f1_score: 0.9417 - val_loss: 2.5615 - val_accuracy: 0.7200 - val_auc_10: 0.8039 - val_precision_10: 0.7200 - val_recall_10: 0.7200 - val_cohen_kappa: -0.3507 - val_f1_score: 0.4608 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2490 - accuracy: 0.9753 - auc_10: 0.9970 - precision_10: 0.9753 - recall_10: 0.9753 - cohen_kappa: -0.7587 - f1_score: 0.9714\n",
      "Epoch 10: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 17s 817ms/step - loss: 1.2490 - accuracy: 0.9753 - auc_10: 0.9970 - precision_10: 0.9753 - recall_10: 0.9753 - cohen_kappa: -0.7587 - f1_score: 0.9714 - val_loss: 2.2727 - val_accuracy: 0.7600 - val_auc_10: 0.8295 - val_precision_10: 0.7600 - val_recall_10: 0.7600 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5813 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2181 - accuracy: 0.9938 - auc_10: 0.9995 - precision_10: 0.9938 - recall_10: 0.9938 - cohen_kappa: -0.5842 - f1_score: 0.9916\n",
      "Epoch 11: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 1.2181 - accuracy: 0.9938 - auc_10: 0.9995 - precision_10: 0.9938 - recall_10: 0.9938 - cohen_kappa: -0.5842 - f1_score: 0.9916 - val_loss: 2.2580 - val_accuracy: 0.7733 - val_auc_10: 0.8249 - val_precision_10: 0.7733 - val_recall_10: 0.7733 - val_cohen_kappa: -0.4188 - val_f1_score: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2673 - accuracy: 0.9691 - auc_10: 0.9967 - precision_10: 0.9691 - recall_10: 0.9691 - cohen_kappa: -0.6624 - f1_score: 0.9613Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.77667\n",
      "21/21 [==============================] - 16s 757ms/step - loss: 1.2673 - accuracy: 0.9691 - auc_10: 0.9967 - precision_10: 0.9691 - recall_10: 0.9691 - cohen_kappa: -0.6624 - f1_score: 0.9613 - val_loss: 2.4150 - val_accuracy: 0.7600 - val_auc_10: 0.8121 - val_precision_10: 0.7600 - val_recall_10: 0.7600 - val_cohen_kappa: -0.4017 - val_f1_score: 0.5813 - lr: 1.0000e-05\n",
      "Epoch 12: early stopping\n",
      "\n",
      "\n",
      "\n",
      "-------------------- Evaluation --------------------\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 1.7767 - accuracy: 0.7733 - auc_10: 0.8437 - precision_10: 0.7733 - recall_10: 0.7733 - cohen_kappa: -0.4879 - f1_score: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.86        54\n",
      "           1       0.70      0.33      0.45        21\n",
      "\n",
      "    accuracy                           0.77        75\n",
      "   macro avg       0.74      0.64      0.65        75\n",
      "weighted avg       0.76      0.77      0.74        75\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vgg16 = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_tensor=None, input_shape=None)\n",
    "\n",
    "Vgg16 = model_training(Vgg16,'Vgg16.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6509ec4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cohen_kappa</th>\n",
       "      <th>cm</th>\n",
       "      <th>cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MobileNet.h5</td>\n",
       "      <td>2.196022</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.819378</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>-0.557093</td>\n",
       "      <td>[0.83478266, 0.45714286]</td>\n",
       "      <td>[[48, 6], [13, 8]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vgg19.h5</td>\n",
       "      <td>2.135838</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.852622</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>-0.522534</td>\n",
       "      <td>[0.83760685, 0.42424244]</td>\n",
       "      <td>[[49, 5], [14, 7]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xception.h5</td>\n",
       "      <td>1.826214</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.853689</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.401694</td>\n",
       "      <td>[0.8387097, 0.23076925]</td>\n",
       "      <td>[[52, 2], [18, 3]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InceptionV3.h5</td>\n",
       "      <td>2.731813</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.850756</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>[0.85, 0.4]</td>\n",
       "      <td>[[51, 3], [15, 6]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DenseNet121.h5</td>\n",
       "      <td>2.122121</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.848356</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.453301</td>\n",
       "      <td>[0.87603307, 0.48275864]</td>\n",
       "      <td>[[53, 1], [14, 7]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vgg16.h5</td>\n",
       "      <td>1.776670</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.843733</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>-0.487898</td>\n",
       "      <td>[0.85714287, 0.45161292]</td>\n",
       "      <td>[[51, 3], [14, 7]]</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model      loss  accuracy       auc  precision    recall  \\\n",
       "0    MobileNet.h5  2.196022  0.746667  0.819378   0.746667  0.746667   \n",
       "1        Vgg19.h5  2.135838  0.746667  0.852622   0.746667  0.746667   \n",
       "2     Xception.h5  1.826214  0.733333  0.853689   0.733333  0.733333   \n",
       "3  InceptionV3.h5  2.731813  0.760000  0.850756   0.760000  0.760000   \n",
       "4  DenseNet121.h5  2.122121  0.800000  0.848356   0.800000  0.800000   \n",
       "5        Vgg16.h5  1.776670  0.773333  0.843733   0.773333  0.773333   \n",
       "\n",
       "   f1_score               cohen_kappa                  cm  \\\n",
       "0 -0.557093  [0.83478266, 0.45714286]  [[48, 6], [13, 8]]   \n",
       "1 -0.522534  [0.83760685, 0.42424244]  [[49, 5], [14, 7]]   \n",
       "2 -0.401694   [0.8387097, 0.23076925]  [[52, 2], [18, 3]]   \n",
       "3 -0.470588               [0.85, 0.4]  [[51, 3], [15, 6]]   \n",
       "4 -0.453301  [0.87603307, 0.48275864]  [[53, 1], [14, 7]]   \n",
       "5 -0.487898  [0.85714287, 0.45161292]  [[51, 3], [14, 7]]   \n",
       "\n",
       "                                                  cr  \n",
       "0                precision    recall  f1-score   ...  \n",
       "1                precision    recall  f1-score   ...  \n",
       "2                precision    recall  f1-score   ...  \n",
       "3                precision    recall  f1-score   ...  \n",
       "4                precision    recall  f1-score   ...  \n",
       "5                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(l)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d5927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
