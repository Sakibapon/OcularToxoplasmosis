{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c0b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95f0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865f0638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2070 SUPER, compute capability 7.5\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\mixed_precision\\loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca79c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:/Ocular toxoplasmosis binzarized/Oculur Toxoplasmosis/train\"\n",
    "test_dir = \"D:/Ocular toxoplasmosis binzarized/Oculur Toxoplasmosis/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2d3b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 366 images belonging to 2 classes.\n",
      "Found 83 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (112, 112)\n",
    "\n",
    "datagen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False)\n",
    "\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)\n",
    "steps_per_epoch = generator_train.n / batch_size\n",
    "steps_test = generator_test.n / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f9cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(model):\n",
    "    transfer_layer = model.get_layer(model.get_layer(index = -1).name)\n",
    "    conv_model = Model(inputs=model.input, outputs=transfer_layer.output)\n",
    "    new_model = Sequential()\n",
    "    new_model.add(conv_model)\n",
    "    new_model.add(Flatten())\n",
    "    new_model.add(Dense(2, activation='softmax'))\n",
    "    optimizer = Adam(lr=1e-5)\n",
    "    loss = 'categorical_crossentropy'\n",
    "    metrics = ['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "    new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dd9867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9428\\183852360.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_vgg19 = vgg19.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 26s 849ms/step - loss: 0.5365 - categorical_accuracy: 0.7158 - precision: 0.7158 - recall: 0.7158 - auc: 0.8043 - val_loss: 0.5607 - val_categorical_accuracy: 0.7108 - val_precision: 0.7108 - val_recall: 0.7108 - val_auc: 0.7836\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 17s 738ms/step - loss: 0.3073 - categorical_accuracy: 0.8989 - precision: 0.8989 - recall: 0.8989 - auc: 0.9552 - val_loss: 0.4739 - val_categorical_accuracy: 0.8072 - val_precision: 0.8072 - val_recall: 0.8072 - val_auc: 0.8588\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 16s 716ms/step - loss: 0.2120 - categorical_accuracy: 0.9208 - precision: 0.9208 - recall: 0.9208 - auc: 0.9743 - val_loss: 0.6588 - val_categorical_accuracy: 0.7229 - val_precision: 0.7229 - val_recall: 0.7229 - val_auc: 0.8138\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 17s 732ms/step - loss: 0.1725 - categorical_accuracy: 0.9317 - precision: 0.9317 - recall: 0.9317 - auc: 0.9823 - val_loss: 0.3291 - val_categorical_accuracy: 0.8554 - val_precision: 0.8554 - val_recall: 0.8554 - val_auc: 0.9374\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 16s 717ms/step - loss: 0.2714 - categorical_accuracy: 0.8989 - precision: 0.8989 - recall: 0.8989 - auc: 0.9558 - val_loss: 0.4377 - val_categorical_accuracy: 0.7831 - val_precision: 0.7831 - val_recall: 0.7831 - val_auc: 0.8878\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 16s 698ms/step - loss: 0.1417 - categorical_accuracy: 0.9372 - precision: 0.9372 - recall: 0.9372 - auc: 0.9890 - val_loss: 0.4156 - val_categorical_accuracy: 0.8554 - val_precision: 0.8554 - val_recall: 0.8554 - val_auc: 0.9181\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 16s 719ms/step - loss: 0.1214 - categorical_accuracy: 0.9508 - precision: 0.9508 - recall: 0.9508 - auc: 0.9915 - val_loss: 0.5086 - val_categorical_accuracy: 0.7952 - val_precision: 0.7952 - val_recall: 0.7952 - val_auc: 0.8970\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 16s 724ms/step - loss: 0.1268 - categorical_accuracy: 0.9481 - precision: 0.9481 - recall: 0.9481 - auc: 0.9898 - val_loss: 0.5959 - val_categorical_accuracy: 0.7590 - val_precision: 0.7590 - val_recall: 0.7590 - val_auc: 0.8646\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 17s 744ms/step - loss: 0.0835 - categorical_accuracy: 0.9754 - precision: 0.9754 - recall: 0.9754 - auc: 0.9967 - val_loss: 0.4930 - val_categorical_accuracy: 0.8313 - val_precision: 0.8313 - val_recall: 0.8313 - val_auc: 0.9150\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 16s 710ms/step - loss: 0.1573 - categorical_accuracy: 0.9426 - precision: 0.9426 - recall: 0.9426 - auc: 0.9844 - val_loss: 0.4012 - val_categorical_accuracy: 0.8193 - val_precision: 0.8193 - val_recall: 0.8193 - val_auc: 0.9237\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.VGG19(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "vgg19 = model_creator(model)\n",
    "history_vgg19 = vgg19.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9045cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9428\\576356427.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_inception = inception.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 29s 806ms/step - loss: 0.7903 - categorical_accuracy: 0.5301 - precision_1: 0.5301 - recall_1: 0.5301 - auc_1: 0.5320 - val_loss: 1.0482 - val_categorical_accuracy: 0.6024 - val_precision_1: 0.6024 - val_recall_1: 0.6024 - val_auc_1: 0.5795\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 16s 718ms/step - loss: 0.6328 - categorical_accuracy: 0.6366 - precision_1: 0.6366 - recall_1: 0.6366 - auc_1: 0.7040 - val_loss: 0.9488 - val_categorical_accuracy: 0.6024 - val_precision_1: 0.6024 - val_recall_1: 0.6024 - val_auc_1: 0.6193\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 17s 728ms/step - loss: 0.5594 - categorical_accuracy: 0.7268 - precision_1: 0.7268 - recall_1: 0.7268 - auc_1: 0.7832 - val_loss: 0.9136 - val_categorical_accuracy: 0.5663 - val_precision_1: 0.5663 - val_recall_1: 0.5663 - val_auc_1: 0.5712\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 17s 742ms/step - loss: 0.5634 - categorical_accuracy: 0.7404 - precision_1: 0.7404 - recall_1: 0.7404 - auc_1: 0.7905 - val_loss: 0.7342 - val_categorical_accuracy: 0.6747 - val_precision_1: 0.6747 - val_recall_1: 0.6747 - val_auc_1: 0.6666\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 16s 713ms/step - loss: 0.5219 - categorical_accuracy: 0.7650 - precision_1: 0.7650 - recall_1: 0.7650 - auc_1: 0.8258 - val_loss: 0.6629 - val_categorical_accuracy: 0.6988 - val_precision_1: 0.6988 - val_recall_1: 0.6988 - val_auc_1: 0.7211\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 17s 745ms/step - loss: 0.5119 - categorical_accuracy: 0.7623 - precision_1: 0.7623 - recall_1: 0.7623 - auc_1: 0.8279 - val_loss: 0.5791 - val_categorical_accuracy: 0.7470 - val_precision_1: 0.7561 - val_recall_1: 0.7470 - val_auc_1: 0.7937\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 17s 727ms/step - loss: 0.4352 - categorical_accuracy: 0.8005 - precision_1: 0.8005 - recall_1: 0.8005 - auc_1: 0.8802 - val_loss: 0.5366 - val_categorical_accuracy: 0.6867 - val_precision_1: 0.6867 - val_recall_1: 0.6867 - val_auc_1: 0.8021\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 16s 691ms/step - loss: 0.4051 - categorical_accuracy: 0.8306 - precision_1: 0.8306 - recall_1: 0.8306 - auc_1: 0.9010 - val_loss: 0.5074 - val_categorical_accuracy: 0.7108 - val_precision_1: 0.7108 - val_recall_1: 0.7108 - val_auc_1: 0.8199\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 16s 693ms/step - loss: 0.4451 - categorical_accuracy: 0.7814 - precision_1: 0.7808 - recall_1: 0.7787 - auc_1: 0.8753 - val_loss: 0.6134 - val_categorical_accuracy: 0.7108 - val_precision_1: 0.7108 - val_recall_1: 0.7108 - val_auc_1: 0.8056\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 17s 723ms/step - loss: 0.3675 - categorical_accuracy: 0.8388 - precision_1: 0.8388 - recall_1: 0.8388 - auc_1: 0.9212 - val_loss: 0.9162 - val_categorical_accuracy: 0.6506 - val_precision_1: 0.6506 - val_recall_1: 0.6506 - val_auc_1: 0.7586\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.InceptionV3(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "inception = model_creator(model)\n",
    "history_inception = inception.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d80df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9428\\789522733.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_mobile = mobile.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 21s 750ms/step - loss: 1.3098 - categorical_accuracy: 0.5273 - precision_2: 0.5273 - recall_2: 0.5273 - auc_2: 0.5483 - val_loss: 1.2947 - val_categorical_accuracy: 0.4217 - val_precision_2: 0.4217 - val_recall_2: 0.4217 - val_auc_2: 0.4307\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 17s 754ms/step - loss: 1.0583 - categorical_accuracy: 0.6311 - precision_2: 0.6311 - recall_2: 0.6311 - auc_2: 0.6505 - val_loss: 0.9955 - val_categorical_accuracy: 0.5542 - val_precision_2: 0.5542 - val_recall_2: 0.5542 - val_auc_2: 0.5814\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 17s 734ms/step - loss: 0.7253 - categorical_accuracy: 0.7213 - precision_2: 0.7213 - recall_2: 0.7213 - auc_2: 0.7856 - val_loss: 0.9245 - val_categorical_accuracy: 0.5904 - val_precision_2: 0.5904 - val_recall_2: 0.5904 - val_auc_2: 0.6190\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 17s 737ms/step - loss: 0.6813 - categorical_accuracy: 0.7295 - precision_2: 0.7315 - recall_2: 0.7295 - auc_2: 0.7992 - val_loss: 0.8447 - val_categorical_accuracy: 0.6145 - val_precision_2: 0.6145 - val_recall_2: 0.6145 - val_auc_2: 0.6904\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 17s 747ms/step - loss: 0.6228 - categorical_accuracy: 0.7377 - precision_2: 0.7377 - recall_2: 0.7377 - auc_2: 0.8288 - val_loss: 0.7324 - val_categorical_accuracy: 0.6506 - val_precision_2: 0.6506 - val_recall_2: 0.6506 - val_auc_2: 0.7525\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 16s 717ms/step - loss: 0.5519 - categorical_accuracy: 0.7869 - precision_2: 0.7869 - recall_2: 0.7869 - auc_2: 0.8647 - val_loss: 0.6415 - val_categorical_accuracy: 0.6988 - val_precision_2: 0.6988 - val_recall_2: 0.6988 - val_auc_2: 0.8051\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 17s 720ms/step - loss: 0.5565 - categorical_accuracy: 0.8033 - precision_2: 0.8033 - recall_2: 0.8033 - auc_2: 0.8684 - val_loss: 0.5895 - val_categorical_accuracy: 0.7831 - val_precision_2: 0.7831 - val_recall_2: 0.7831 - val_auc_2: 0.8442\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 17s 763ms/step - loss: 0.4856 - categorical_accuracy: 0.7978 - precision_2: 0.7978 - recall_2: 0.7978 - auc_2: 0.8844 - val_loss: 0.5760 - val_categorical_accuracy: 0.8313 - val_precision_2: 0.8313 - val_recall_2: 0.8313 - val_auc_2: 0.8562\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 17s 739ms/step - loss: 0.4586 - categorical_accuracy: 0.8388 - precision_2: 0.8388 - recall_2: 0.8388 - auc_2: 0.9041 - val_loss: 0.5770 - val_categorical_accuracy: 0.8313 - val_precision_2: 0.8313 - val_recall_2: 0.8313 - val_auc_2: 0.8564\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 17s 726ms/step - loss: 0.3743 - categorical_accuracy: 0.8579 - precision_2: 0.8579 - recall_2: 0.8579 - auc_2: 0.9278 - val_loss: 0.5717 - val_categorical_accuracy: 0.8313 - val_precision_2: 0.8313 - val_recall_2: 0.8313 - val_auc_2: 0.8681\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.MobileNet(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "mobile = model_creator(model)\n",
    "history_mobile = mobile.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf476612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9428\\3413688818.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_dense = dense.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 37s 898ms/step - loss: 0.8953 - categorical_accuracy: 0.6175 - precision_3: 0.6175 - recall_3: 0.6175 - auc_3: 0.6392 - val_loss: 1.5069 - val_categorical_accuracy: 0.5663 - val_precision_3: 0.5663 - val_recall_3: 0.5663 - val_auc_3: 0.5750\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 17s 756ms/step - loss: 0.5201 - categorical_accuracy: 0.7213 - precision_3: 0.7213 - recall_3: 0.7213 - auc_3: 0.8313 - val_loss: 1.1605 - val_categorical_accuracy: 0.5422 - val_precision_3: 0.5422 - val_recall_3: 0.5422 - val_auc_3: 0.6115\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 17s 754ms/step - loss: 0.4625 - categorical_accuracy: 0.7869 - precision_3: 0.7869 - recall_3: 0.7869 - auc_3: 0.8692 - val_loss: 0.9434 - val_categorical_accuracy: 0.5783 - val_precision_3: 0.5783 - val_recall_3: 0.5783 - val_auc_3: 0.6317\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 17s 746ms/step - loss: 0.3908 - categorical_accuracy: 0.8060 - precision_3: 0.8060 - recall_3: 0.8060 - auc_3: 0.9062 - val_loss: 0.7851 - val_categorical_accuracy: 0.6145 - val_precision_3: 0.6145 - val_recall_3: 0.6145 - val_auc_3: 0.6823\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 17s 736ms/step - loss: 0.3796 - categorical_accuracy: 0.8251 - precision_3: 0.8251 - recall_3: 0.8251 - auc_3: 0.9130 - val_loss: 0.6945 - val_categorical_accuracy: 0.6386 - val_precision_3: 0.6463 - val_recall_3: 0.6386 - val_auc_3: 0.7143\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 18s 773ms/step - loss: 0.2748 - categorical_accuracy: 0.8743 - precision_3: 0.8743 - recall_3: 0.8743 - auc_3: 0.9539 - val_loss: 0.6110 - val_categorical_accuracy: 0.6988 - val_precision_3: 0.6988 - val_recall_3: 0.6988 - val_auc_3: 0.7765\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 17s 748ms/step - loss: 0.2323 - categorical_accuracy: 0.9016 - precision_3: 0.9016 - recall_3: 0.9016 - auc_3: 0.9678 - val_loss: 0.5295 - val_categorical_accuracy: 0.7590 - val_precision_3: 0.7590 - val_recall_3: 0.7590 - val_auc_3: 0.8341\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 17s 736ms/step - loss: 0.2394 - categorical_accuracy: 0.8989 - precision_3: 0.8989 - recall_3: 0.8989 - auc_3: 0.9662 - val_loss: 0.4811 - val_categorical_accuracy: 0.7831 - val_precision_3: 0.7831 - val_recall_3: 0.7831 - val_auc_3: 0.8522\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 17s 744ms/step - loss: 0.2258 - categorical_accuracy: 0.9071 - precision_3: 0.9071 - recall_3: 0.9071 - auc_3: 0.9687 - val_loss: 0.4589 - val_categorical_accuracy: 0.7711 - val_precision_3: 0.7711 - val_recall_3: 0.7711 - val_auc_3: 0.8649\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 17s 739ms/step - loss: 0.2413 - categorical_accuracy: 0.9126 - precision_3: 0.9126 - recall_3: 0.9126 - auc_3: 0.9639 - val_loss: 0.4395 - val_categorical_accuracy: 0.7470 - val_precision_3: 0.7470 - val_recall_3: 0.7470 - val_auc_3: 0.8776\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.DenseNet121(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "dense = model_creator(model)\n",
    "history_dense = dense.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5772e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9428\\28214634.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_xcep = xcep.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 26s 803ms/step - loss: 0.6917 - categorical_accuracy: 0.5574 - precision_4: 0.5549 - recall_4: 0.5519 - auc_4: 0.5852 - val_loss: 0.6209 - val_categorical_accuracy: 0.6386 - val_precision_4: 0.6341 - val_recall_4: 0.6265 - val_auc_4: 0.7034\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 18s 772ms/step - loss: 0.5975 - categorical_accuracy: 0.7049 - precision_4: 0.7068 - recall_4: 0.7049 - auc_4: 0.7477 - val_loss: 0.5865 - val_categorical_accuracy: 0.6627 - val_precision_4: 0.6627 - val_recall_4: 0.6627 - val_auc_4: 0.7503\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 17s 747ms/step - loss: 0.5331 - categorical_accuracy: 0.7568 - precision_4: 0.7589 - recall_4: 0.7568 - auc_4: 0.8333 - val_loss: 0.5573 - val_categorical_accuracy: 0.6988 - val_precision_4: 0.6988 - val_recall_4: 0.6988 - val_auc_4: 0.7841\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 17s 747ms/step - loss: 0.4709 - categorical_accuracy: 0.7842 - precision_4: 0.7842 - recall_4: 0.7842 - auc_4: 0.8856 - val_loss: 0.5269 - val_categorical_accuracy: 0.7349 - val_precision_4: 0.7349 - val_recall_4: 0.7349 - val_auc_4: 0.8156\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 17s 747ms/step - loss: 0.4451 - categorical_accuracy: 0.8306 - precision_4: 0.8301 - recall_4: 0.8279 - auc_4: 0.9008 - val_loss: 0.5045 - val_categorical_accuracy: 0.7108 - val_precision_4: 0.7108 - val_recall_4: 0.7108 - val_auc_4: 0.8273\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 17s 735ms/step - loss: 0.4109 - categorical_accuracy: 0.8415 - precision_4: 0.8415 - recall_4: 0.8415 - auc_4: 0.9196 - val_loss: 0.4852 - val_categorical_accuracy: 0.7349 - val_precision_4: 0.7349 - val_recall_4: 0.7349 - val_auc_4: 0.8492\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 17s 721ms/step - loss: 0.3664 - categorical_accuracy: 0.8661 - precision_4: 0.8661 - recall_4: 0.8661 - auc_4: 0.9417 - val_loss: 0.4587 - val_categorical_accuracy: 0.8193 - val_precision_4: 0.8193 - val_recall_4: 0.8193 - val_auc_4: 0.8850\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 17s 752ms/step - loss: 0.3426 - categorical_accuracy: 0.8634 - precision_4: 0.8634 - recall_4: 0.8634 - auc_4: 0.9451 - val_loss: 0.4397 - val_categorical_accuracy: 0.8313 - val_precision_4: 0.8313 - val_recall_4: 0.8313 - val_auc_4: 0.8930\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 17s 742ms/step - loss: 0.3105 - categorical_accuracy: 0.8989 - precision_4: 0.9014 - recall_4: 0.8989 - auc_4: 0.9605 - val_loss: 0.4207 - val_categorical_accuracy: 0.8072 - val_precision_4: 0.8072 - val_recall_4: 0.8072 - val_auc_4: 0.9061\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 18s 767ms/step - loss: 0.3185 - categorical_accuracy: 0.8907 - precision_4: 0.8907 - recall_4: 0.8907 - auc_4: 0.9549 - val_loss: 0.3969 - val_categorical_accuracy: 0.8193 - val_precision_4: 0.8193 - val_recall_4: 0.8193 - val_auc_4: 0.9138\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.Xception(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "xcep = model_creator(model)\n",
    "history_xcep = xcep.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71a9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9428\\388627917.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_vgg16 = vgg16.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 21s 791ms/step - loss: 0.6013 - categorical_accuracy: 0.6858 - precision_5: 0.6858 - recall_5: 0.6858 - auc_5: 0.7399 - val_loss: 0.5420 - val_categorical_accuracy: 0.7590 - val_precision_5: 0.7590 - val_recall_5: 0.7590 - val_auc_5: 0.8358\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 17s 741ms/step - loss: 0.4014 - categorical_accuracy: 0.8279 - precision_5: 0.8279 - recall_5: 0.8279 - auc_5: 0.9143 - val_loss: 0.5569 - val_categorical_accuracy: 0.6867 - val_precision_5: 0.6867 - val_recall_5: 0.6867 - val_auc_5: 0.7778\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 17s 739ms/step - loss: 0.2752 - categorical_accuracy: 0.8934 - precision_5: 0.8934 - recall_5: 0.8934 - auc_5: 0.9618 - val_loss: 0.3548 - val_categorical_accuracy: 0.8072 - val_precision_5: 0.8072 - val_recall_5: 0.8072 - val_auc_5: 0.9162\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 17s 737ms/step - loss: 0.2073 - categorical_accuracy: 0.9071 - precision_5: 0.9071 - recall_5: 0.9071 - auc_5: 0.9761 - val_loss: 0.5610 - val_categorical_accuracy: 0.7349 - val_precision_5: 0.7349 - val_recall_5: 0.7349 - val_auc_5: 0.8441\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 17s 715ms/step - loss: 0.2144 - categorical_accuracy: 0.9126 - precision_5: 0.9126 - recall_5: 0.9126 - auc_5: 0.9717 - val_loss: 0.3183 - val_categorical_accuracy: 0.8554 - val_precision_5: 0.8554 - val_recall_5: 0.8554 - val_auc_5: 0.9380\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 17s 733ms/step - loss: 0.2216 - categorical_accuracy: 0.9016 - precision_5: 0.9016 - recall_5: 0.9016 - auc_5: 0.9705 - val_loss: 0.3328 - val_categorical_accuracy: 0.8675 - val_precision_5: 0.8675 - val_recall_5: 0.8675 - val_auc_5: 0.9310\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 17s 734ms/step - loss: 0.1501 - categorical_accuracy: 0.9481 - precision_5: 0.9481 - recall_5: 0.9481 - auc_5: 0.9873 - val_loss: 0.3227 - val_categorical_accuracy: 0.8916 - val_precision_5: 0.8916 - val_recall_5: 0.8916 - val_auc_5: 0.9405\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 18s 766ms/step - loss: 0.1569 - categorical_accuracy: 0.9399 - precision_5: 0.9399 - recall_5: 0.9399 - auc_5: 0.9850 - val_loss: 0.3992 - val_categorical_accuracy: 0.8313 - val_precision_5: 0.8313 - val_recall_5: 0.8313 - val_auc_5: 0.9170\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 17s 757ms/step - loss: 0.1258 - categorical_accuracy: 0.9508 - precision_5: 0.9508 - recall_5: 0.9508 - auc_5: 0.9909 - val_loss: 0.6792 - val_categorical_accuracy: 0.7349 - val_precision_5: 0.7349 - val_recall_5: 0.7349 - val_auc_5: 0.8536\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 17s 730ms/step - loss: 0.0979 - categorical_accuracy: 0.9590 - precision_5: 0.9590 - recall_5: 0.9590 - auc_5: 0.9953 - val_loss: 0.3020 - val_categorical_accuracy: 0.9157 - val_precision_5: 0.9157 - val_recall_5: 0.9157 - val_auc_5: 0.9529\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.VGG16(include_top=False,input_shape=(112, 112, 3), weights='imagenet')\n",
    "vgg16 = model_creator(model)\n",
    "history_vgg16 = vgg16.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0cf83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
