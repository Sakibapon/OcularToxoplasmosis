{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287e87c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:10.939917Z",
     "iopub.status.busy": "2023-07-04T18:21:10.939537Z",
     "iopub.status.idle": "2023-07-04T18:21:24.794396Z",
     "shell.execute_reply": "2023-07-04T18:21:24.793620Z",
     "shell.execute_reply.started": "2023-07-04T18:21:10.939887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Reshape, Conv2DTranspose, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "np.random.seed(72)\n",
    "tf.random.set_seed(72)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1d3868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:24.799974Z",
     "iopub.status.busy": "2023-07-04T18:21:24.796720Z",
     "iopub.status.idle": "2023-07-04T18:21:24.816658Z",
     "shell.execute_reply": "2023-07-04T18:21:24.815574Z",
     "shell.execute_reply.started": "2023-07-04T18:21:24.799937Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_(model, generator_test):\n",
    "    model.evaluate(generator_test)\n",
    "    \n",
    "    y_pred = model.predict(generator_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = generator_test.classes\n",
    "    class_labels = list(generator_test.class_indices.keys())\n",
    "\n",
    "    print(classification_report(y_true, y_pred_classes))\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    \n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_graphs(history, generator_test):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.plot(history.history['accuracy'], 'r', linewidth=2.5)\n",
    "    plt.plot(history.history['val_accuracy'], linewidth=2.5)\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Training Accuracy', 'Testing Accuracy'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.plot(history.history['loss'], 'r', linewidth=2.5)\n",
    "    plt.plot(history.history['val_loss'], linewidth=2.5)\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train Loss', 'Test Loss'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = model.predict_generator(generator_test)\n",
    "\n",
    "    # Get true labels\n",
    "    true_labels = generator_test.classes\n",
    "\n",
    "    # Binarize the true labels\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    true_labels = encoder.fit_transform(true_labels.reshape(-1, 1))\n",
    "\n",
    "    # Calculate ROC curve and ROC AUC for each class\n",
    "    n_classes = true_labels.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for class_idx in range(n_classes):\n",
    "        fpr[class_idx], tpr[class_idx], _ = roc_curve(true_labels[:, class_idx], predictions[:, class_idx])\n",
    "        roc_auc[class_idx] = auc(fpr[class_idx], tpr[class_idx])\n",
    "\n",
    "    # Plot ROC curves for each class\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for class_idx in range(n_classes):\n",
    "\n",
    "        plt.plot(fpr[class_idx], tpr[class_idx], label='ROC curve (area = %0.2f) for class %d' % (roc_auc[class_idx], class_idx),\n",
    "                linewidth=2.5)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic per Class')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2958dc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:24.818677Z",
     "iopub.status.busy": "2023-07-04T18:21:24.818024Z",
     "iopub.status.idle": "2023-07-04T18:21:24.895036Z",
     "shell.execute_reply": "2023-07-04T18:21:24.894028Z",
     "shell.execute_reply.started": "2023-07-04T18:21:24.818644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 366 images belonging to 2 classes.\n",
      "Found 83 images belonging to 2 classes.\n",
      "{0: 1.3863636363636365, 1: 0.782051282051282}\n"
     ]
    }
   ],
   "source": [
    "train_dir = r\"/kaggle/input/ocular-toxoplasmosis/BinaryClassification/train\"\n",
    "test_dir = r\"/kaggle/input/ocular-toxoplasmosis/BinaryClassification/val\"\n",
    "image_size = 128\n",
    "datagen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False)\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 8\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=(image_size, image_size),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=(image_size, image_size),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)\n",
    "num_classes = generator_train.num_classes\n",
    "# Calculate class weights\n",
    "labels = generator_train.classes\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = dict(zip(np.unique(labels), class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d99f927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:24.898643Z",
     "iopub.status.busy": "2023-07-04T18:21:24.897988Z",
     "iopub.status.idle": "2023-07-04T18:21:38.402052Z",
     "shell.execute_reply": "2023-07-04T18:21:38.400916Z",
     "shell.execute_reply.started": "2023-07-04T18:21:24.898609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_cv_attention_models\n",
      "  Downloading keras_cv_attention_models-1.3.18-py3-none-any.whl (703 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.1/703.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from keras_cv_attention_models) (9.5.0)\n",
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.10/site-packages (from keras_cv_attention_models) (0.20.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from keras_cv_attention_models) (4.9.2)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from keras_cv_attention_models) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (1.51.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (0.4.8)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (59.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras_cv_attention_models) (0.31.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons->keras_cv_attention_models) (2.13.3)\n",
      "Requirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (0.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (8.1.3)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (1.2.0)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (2.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (5.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (2.28.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (0.14.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv_attention_models) (4.64.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->keras_cv_attention_models) (0.40.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv_attention_models) (5.12.0)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv_attention_models) (3.15.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->keras_cv_attention_models) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->keras_cv_attention_models) (1.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv_attention_models) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv_attention_models) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv_attention_models) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv_attention_models) (2023.5.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (2.3.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow->keras_cv_attention_models) (3.0.9)\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv_attention_models) (1.57.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras_cv_attention_models) (3.2.2)\n",
      "Installing collected packages: keras_cv_attention_models\n",
      "Successfully installed keras_cv_attention_models-1.3.18\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47934073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:38.405891Z",
     "iopub.status.busy": "2023-07-04T18:21:38.405560Z",
     "iopub.status.idle": "2023-07-04T18:21:46.689398Z",
     "shell.execute_reply": "2023-07-04T18:21:46.688244Z",
     "shell.execute_reply.started": "2023-07-04T18:21:38.405862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_tiny_224_imagenet.h5\n",
      "126113280/126113280 [==============================] - 1s 0us/step\n",
      ">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n",
      ">>>> Reload mismatched weights: 224 -> (128, 128)\n",
      ">>>> Reload layer: stack_1_block_1/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_1_block_1/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_1_block_2/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_1_block_2/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_2_block_1/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_2_block_1/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_2_block_2/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_2_block_2/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_1/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_1/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_2/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_2/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_3/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_3/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_4/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_4/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_5/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_3_block_5/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_4_block_1/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_4_block_1/grid_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_4_block_2/block_window_mhsa/pos_emb\n",
      ">>>> Reload layer: stack_4_block_2/grid_window_mhsa/pos_emb\n"
     ]
    }
   ],
   "source": [
    "from keras_cv_attention_models import maxvit\n",
    "mm = maxvit.MaxViT_Tiny(input_shape=(image_size, image_size, 3), pretrained=\"imagenet\") #31M Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f13f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:46.691529Z",
     "iopub.status.busy": "2023-07-04T18:21:46.691036Z",
     "iopub.status.idle": "2023-07-04T18:21:49.813595Z",
     "shell.execute_reply": "2023-07-04T18:21:49.812812Z",
     "shell.execute_reply.started": "2023-07-04T18:21:46.691493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"maxvit_tiny\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " stem_1_conv (Conv2D)           (None, 64, 64, 64)   1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " stem_1_bn (BatchNormalization)  (None, 64, 64, 64)  256         ['stem_1_conv[0][0]']            \n",
      "                                                                                                  \n",
      " tf.nn.gelu (TFOpLambda)        (None, 64, 64, 64)   0           ['stem_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " stem_2_conv (Conv2D)           (None, 64, 64, 64)   36928       ['tf.nn.gelu[0][0]']             \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/preact_  (None, 64, 64, 64)  256         ['stem_2_conv[0][0]']            \n",
      " bn (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/expand_  (None, 64, 64, 256)  16384      ['stack_1_block_1/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/expand_  (None, 64, 64, 256)  1024       ['stack_1_block_1/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_1 (TFOpLambda)      (None, 64, 64, 256)  0           ['stack_1_block_1/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/MB_dw_c  (None, 32, 32, 256)  2304       ['tf.nn.gelu_1[0][0]']           \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/MB_dw_b  (None, 32, 32, 256)  1024       ['stack_1_block_1/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_2 (TFOpLambda)      (None, 32, 32, 256)  0           ['stack_1_block_1/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 1, 1, 256)   0           ['tf.nn.gelu_2[0][0]']           \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/se/1_co  (None, 1, 1, 16)    4112        ['tf.math.reduce_mean[0][0]']    \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/se/swis  (None, 1, 1, 16)    0           ['stack_1_block_1/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/se/2_co  (None, 1, 1, 256)   4352        ['stack_1_block_1/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/se/sigm  (None, 1, 1, 256)   0           ['stack_1_block_1/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/se/out   (None, 32, 32, 256)  0          ['tf.nn.gelu_2[0][0]',           \n",
      " (Multiply)                                                       'stack_1_block_1/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/shortcu  (None, 32, 32, 64)  0           ['stem_2_conv[0][0]']            \n",
      " t_pool (AveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/MB_pw_c  (None, 32, 32, 64)  16448       ['stack_1_block_1/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_1_block_1/mbconv/output   (None, 32, 32, 64)  0           ['stack_1_block_1/mbconv/shortcut\n",
      " (Add)                                                           _pool[0][0]',                    \n",
      "                                                                  'stack_1_block_1/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_attn_pre  (None, 32, 32, 64)  128         ['stack_1_block_1/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 4, 8, 256)    0           ['stack_1_block_1/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, 8, 4, 256)   0           ['tf.reshape[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 4, 4, 64)     0           ['tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_window_m  (None, 4, 4, 192)   12480       ['tf.reshape_1[0][0]']           \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)          [(None, 4, 4, 64),   0           ['stack_1_block_1/block_window_mh\n",
      "                                 (None, 4, 4, 64),               sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 64)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 16, 2, 32)    0           ['tf.split[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)      (None, 16, 2, 32)    0           ['tf.split[0][1]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, 2, 16, 32)   0           ['tf.reshape_2[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (TFOp  (None, 2, 32, 16)   0           ['tf.reshape_3[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul (TFOpLambda)  (None, 2, 16, 16)    0           ['tf.compat.v1.transpose_1[0][0]'\n",
      "                                                                 , 'tf.compat.v1.transpose_2[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 2, 16, 16)    0           ['tf.linalg.matmul[0][0]']       \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_window_m  (None, 2, 16, 16)   98          ['tf.math.multiply[0][0]']       \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_4 (TFOpLambda)      (None, 16, 2, 32)    0           ['tf.split[0][2]']               \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_window_m  (None, 2, 16, 16)   0           ['stack_1_block_1/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (TFOp  (None, 2, 16, 32)   0           ['tf.reshape_4[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_1 (TFOpLambda  (None, 2, 16, 32)   0           ['stack_1_block_1/block_window_mh\n",
      " )                                                               sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_4 (TFOp  (None, 16, 2, 32)   0           ['tf.linalg.matmul_1[0][0]']     \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_5 (TFOpLambda)      (None, 4, 4, 64)     0           ['tf.compat.v1.transpose_4[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_window_m  (None, 4, 4, 64)    4160        ['tf.reshape_5[0][0]']           \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_6 (TFOpLambda)      (None, 8, 4, 256)    0           ['stack_1_block_1/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_5 (TFOp  (None, 4, 8, 256)   0           ['tf.reshape_6[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_7 (TFOpLambda)      (None, 32, 32, 64)   0           ['tf.compat.v1.transpose_5[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_attn_out  (None, 32, 32, 64)  0           ['stack_1_block_1/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_7[0][0]']           \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_ffn_prea  (None, 32, 32, 64)  128         ['stack_1_block_1/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_ffn/1_de  (None, 32, 32, 256)  16640      ['stack_1_block_1/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_3 (TFOpLambda)      (None, 32, 32, 256)  0           ['stack_1_block_1/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_ffn/2_de  (None, 32, 32, 64)  16448       ['tf.nn.gelu_3[0][0]']           \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_1_block_1/block_ffn_outp  (None, 32, 32, 64)  0           ['stack_1_block_1/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_1_block_1/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_attn_prea  (None, 32, 32, 64)  128         ['stack_1_block_1/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_8 (TFOpLambda)      (None, 4, 8, 2048)   0           ['stack_1_block_1/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_6 (TFOp  (None, 8, 4, 2048)  0           ['tf.reshape_8[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_9 (TFOpLambda)      (None, 16, 8, 64)    0           ['tf.compat.v1.transpose_6[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_7 (TFOp  (None, 8, 16, 64)   0           ['tf.reshape_9[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.reshape_10 (TFOpLambda)     (None, 4, 4, 64)     0           ['tf.compat.v1.transpose_7[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_window_mh  (None, 4, 4, 192)   12480       ['tf.reshape_10[0][0]']          \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)        [(None, 4, 4, 64),   0           ['stack_1_block_1/grid_window_mhs\n",
      "                                 (None, 4, 4, 64),               a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 64)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_11 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_12 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_1[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_8 (TFOp  (None, 2, 16, 32)   0           ['tf.reshape_11[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_9 (TFOp  (None, 2, 32, 16)   0           ['tf.reshape_12[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_2 (TFOpLambda  (None, 2, 16, 16)   0           ['tf.compat.v1.transpose_8[0][0]'\n",
      " )                                                               , 'tf.compat.v1.transpose_9[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 2, 16, 16)   0           ['tf.linalg.matmul_2[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_window_mh  (None, 2, 16, 16)   98          ['tf.math.multiply_1[0][0]']     \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_13 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_1[0][2]']             \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_window_mh  (None, 2, 16, 16)   0           ['stack_1_block_1/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_10 (TFO  (None, 2, 16, 32)   0           ['tf.reshape_13[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_3 (TFOpLambda  (None, 2, 16, 32)   0           ['stack_1_block_1/grid_window_mhs\n",
      " )                                                               a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_10[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_11 (TFO  (None, 16, 2, 32)   0           ['tf.linalg.matmul_3[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_14 (TFOpLambda)     (None, 4, 4, 64)     0           ['tf.compat.v1.transpose_11[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_window_mh  (None, 4, 4, 64)    4160        ['tf.reshape_14[0][0]']          \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_15 (TFOpLambda)     (None, 8, 16, 64)    0           ['stack_1_block_1/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_12 (TFO  (None, 16, 8, 64)   0           ['tf.reshape_15[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_16 (TFOpLambda)     (None, 8, 4, 2048)   0           ['tf.compat.v1.transpose_12[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_13 (TFO  (None, 4, 8, 2048)  0           ['tf.reshape_16[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_17 (TFOpLambda)     (None, 32, 32, 64)   0           ['tf.compat.v1.transpose_13[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_attn_outp  (None, 32, 32, 64)  0           ['stack_1_block_1/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_17[0][0]']          \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_ffn_preac  (None, 32, 32, 64)  128         ['stack_1_block_1/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_ffn/1_den  (None, 32, 32, 256)  16640      ['stack_1_block_1/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_4 (TFOpLambda)      (None, 32, 32, 256)  0           ['stack_1_block_1/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_ffn/2_den  (None, 32, 32, 64)  16448       ['tf.nn.gelu_4[0][0]']           \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_1_block_1/grid_ffn_outpu  (None, 32, 32, 64)  0           ['stack_1_block_1/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_1_block_1/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/preact_  (None, 32, 32, 64)  256         ['stack_1_block_1/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/expand_  (None, 32, 32, 256)  16384      ['stack_1_block_2/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/expand_  (None, 32, 32, 256)  1024       ['stack_1_block_2/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_5 (TFOpLambda)      (None, 32, 32, 256)  0           ['stack_1_block_2/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/MB_dw_c  (None, 32, 32, 256)  2304       ['tf.nn.gelu_5[0][0]']           \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/MB_dw_b  (None, 32, 32, 256)  1024       ['stack_1_block_2/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_6 (TFOpLambda)      (None, 32, 32, 256)  0           ['stack_1_block_2/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 1, 1, 256)   0           ['tf.nn.gelu_6[0][0]']           \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/se/1_co  (None, 1, 1, 16)    4112        ['tf.math.reduce_mean_1[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/se/swis  (None, 1, 1, 16)    0           ['stack_1_block_2/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/se/2_co  (None, 1, 1, 256)   4352        ['stack_1_block_2/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/se/sigm  (None, 1, 1, 256)   0           ['stack_1_block_2/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/se/out   (None, 32, 32, 256)  0          ['tf.nn.gelu_6[0][0]',           \n",
      " (Multiply)                                                       'stack_1_block_2/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/MB_pw_c  (None, 32, 32, 64)  16448       ['stack_1_block_2/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_1_block_2/mbconv/output   (None, 32, 32, 64)  0           ['stack_1_block_1/grid_ffn_output\n",
      " (Add)                                                           [0][0]',                         \n",
      "                                                                  'stack_1_block_2/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_attn_pre  (None, 32, 32, 64)  128         ['stack_1_block_2/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_18 (TFOpLambda)     (None, 4, 8, 256)    0           ['stack_1_block_2/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_14 (TFO  (None, 8, 4, 256)   0           ['tf.reshape_18[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_19 (TFOpLambda)     (None, 4, 4, 64)     0           ['tf.compat.v1.transpose_14[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_window_m  (None, 4, 4, 192)   12480       ['tf.reshape_19[0][0]']          \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)        [(None, 4, 4, 64),   0           ['stack_1_block_2/block_window_mh\n",
      "                                 (None, 4, 4, 64),               sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 64)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_20 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_21 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_2[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_15 (TFO  (None, 2, 16, 32)   0           ['tf.reshape_20[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_16 (TFO  (None, 2, 32, 16)   0           ['tf.reshape_21[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_4 (TFOpLambda  (None, 2, 16, 16)   0           ['tf.compat.v1.transpose_15[0][0]\n",
      " )                                                               ',                               \n",
      "                                                                  'tf.compat.v1.transpose_16[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 2, 16, 16)   0           ['tf.linalg.matmul_4[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_window_m  (None, 2, 16, 16)   98          ['tf.math.multiply_2[0][0]']     \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_22 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_2[0][2]']             \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_window_m  (None, 2, 16, 16)   0           ['stack_1_block_2/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_17 (TFO  (None, 2, 16, 32)   0           ['tf.reshape_22[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_5 (TFOpLambda  (None, 2, 16, 32)   0           ['stack_1_block_2/block_window_mh\n",
      " )                                                               sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_17[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_18 (TFO  (None, 16, 2, 32)   0           ['tf.linalg.matmul_5[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_23 (TFOpLambda)     (None, 4, 4, 64)     0           ['tf.compat.v1.transpose_18[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_window_m  (None, 4, 4, 64)    4160        ['tf.reshape_23[0][0]']          \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_24 (TFOpLambda)     (None, 8, 4, 256)    0           ['stack_1_block_2/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_19 (TFO  (None, 4, 8, 256)   0           ['tf.reshape_24[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_25 (TFOpLambda)     (None, 32, 32, 64)   0           ['tf.compat.v1.transpose_19[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_attn_out  (None, 32, 32, 64)  0           ['stack_1_block_2/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_25[0][0]']          \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_ffn_prea  (None, 32, 32, 64)  128         ['stack_1_block_2/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_ffn/1_de  (None, 32, 32, 256)  16640      ['stack_1_block_2/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_7 (TFOpLambda)      (None, 32, 32, 256)  0           ['stack_1_block_2/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_ffn/2_de  (None, 32, 32, 64)  16448       ['tf.nn.gelu_7[0][0]']           \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_1_block_2/block_ffn_outp  (None, 32, 32, 64)  0           ['stack_1_block_2/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_1_block_2/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_attn_prea  (None, 32, 32, 64)  128         ['stack_1_block_2/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_26 (TFOpLambda)     (None, 4, 8, 2048)   0           ['stack_1_block_2/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_20 (TFO  (None, 8, 4, 2048)  0           ['tf.reshape_26[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_27 (TFOpLambda)     (None, 16, 8, 64)    0           ['tf.compat.v1.transpose_20[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_21 (TFO  (None, 8, 16, 64)   0           ['tf.reshape_27[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_28 (TFOpLambda)     (None, 4, 4, 64)     0           ['tf.compat.v1.transpose_21[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_window_mh  (None, 4, 4, 192)   12480       ['tf.reshape_28[0][0]']          \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_3 (TFOpLambda)        [(None, 4, 4, 64),   0           ['stack_1_block_2/grid_window_mhs\n",
      "                                 (None, 4, 4, 64),               a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 64)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_29 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_30 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_3[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_22 (TFO  (None, 2, 16, 32)   0           ['tf.reshape_29[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_23 (TFO  (None, 2, 32, 16)   0           ['tf.reshape_30[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_6 (TFOpLambda  (None, 2, 16, 16)   0           ['tf.compat.v1.transpose_22[0][0]\n",
      " )                                                               ',                               \n",
      "                                                                  'tf.compat.v1.transpose_23[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 2, 16, 16)   0           ['tf.linalg.matmul_6[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_window_mh  (None, 2, 16, 16)   98          ['tf.math.multiply_3[0][0]']     \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_31 (TFOpLambda)     (None, 16, 2, 32)    0           ['tf.split_3[0][2]']             \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_window_mh  (None, 2, 16, 16)   0           ['stack_1_block_2/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_24 (TFO  (None, 2, 16, 32)   0           ['tf.reshape_31[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_7 (TFOpLambda  (None, 2, 16, 32)   0           ['stack_1_block_2/grid_window_mhs\n",
      " )                                                               a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_24[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_25 (TFO  (None, 16, 2, 32)   0           ['tf.linalg.matmul_7[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_32 (TFOpLambda)     (None, 4, 4, 64)     0           ['tf.compat.v1.transpose_25[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_window_mh  (None, 4, 4, 64)    4160        ['tf.reshape_32[0][0]']          \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_33 (TFOpLambda)     (None, 8, 16, 64)    0           ['stack_1_block_2/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_26 (TFO  (None, 16, 8, 64)   0           ['tf.reshape_33[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_34 (TFOpLambda)     (None, 8, 4, 2048)   0           ['tf.compat.v1.transpose_26[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_27 (TFO  (None, 4, 8, 2048)  0           ['tf.reshape_34[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_35 (TFOpLambda)     (None, 32, 32, 64)   0           ['tf.compat.v1.transpose_27[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_attn_outp  (None, 32, 32, 64)  0           ['stack_1_block_2/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_35[0][0]']          \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_ffn_preac  (None, 32, 32, 64)  128         ['stack_1_block_2/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_ffn/1_den  (None, 32, 32, 256)  16640      ['stack_1_block_2/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_8 (TFOpLambda)      (None, 32, 32, 256)  0           ['stack_1_block_2/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_ffn/2_den  (None, 32, 32, 64)  16448       ['tf.nn.gelu_8[0][0]']           \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_1_block_2/grid_ffn_outpu  (None, 32, 32, 64)  0           ['stack_1_block_2/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_1_block_2/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/preact_  (None, 32, 32, 64)  256         ['stack_1_block_2/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/expand_  (None, 32, 32, 512)  32768      ['stack_2_block_1/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/expand_  (None, 32, 32, 512)  2048       ['stack_2_block_1/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_9 (TFOpLambda)      (None, 32, 32, 512)  0           ['stack_2_block_1/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/MB_dw_c  (None, 16, 16, 512)  4608       ['tf.nn.gelu_9[0][0]']           \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/MB_dw_b  (None, 16, 16, 512)  2048       ['stack_2_block_1/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_10 (TFOpLambda)     (None, 16, 16, 512)  0           ['stack_2_block_1/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 1, 1, 512)   0           ['tf.nn.gelu_10[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/se/1_co  (None, 1, 1, 32)    16416       ['tf.math.reduce_mean_2[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/se/swis  (None, 1, 1, 32)    0           ['stack_2_block_1/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/se/2_co  (None, 1, 1, 512)   16896       ['stack_2_block_1/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/se/sigm  (None, 1, 1, 512)   0           ['stack_2_block_1/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/shortcu  (None, 16, 16, 64)  0           ['stack_1_block_2/grid_ffn_output\n",
      " t_pool (AveragePooling2D)                                       [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/se/out   (None, 16, 16, 512)  0          ['tf.nn.gelu_10[0][0]',          \n",
      " (Multiply)                                                       'stack_2_block_1/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/shortcu  (None, 16, 16, 128)  8320       ['stack_2_block_1/mbconv/shortcut\n",
      " t_conv (Conv2D)                                                 _pool[0][0]']                    \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/MB_pw_c  (None, 16, 16, 128)  65664      ['stack_2_block_1/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_2_block_1/mbconv/output   (None, 16, 16, 128)  0          ['stack_2_block_1/mbconv/shortcut\n",
      " (Add)                                                           _conv[0][0]',                    \n",
      "                                                                  'stack_2_block_1/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_attn_pre  (None, 16, 16, 128)  256        ['stack_2_block_1/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_36 (TFOpLambda)     (None, 4, 4, 512)    0           ['stack_2_block_1/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_28 (TFO  (None, 4, 4, 512)   0           ['tf.reshape_36[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_37 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_28[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_window_m  (None, 4, 4, 384)   49536       ['tf.reshape_37[0][0]']          \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_4 (TFOpLambda)        [(None, 4, 4, 128),  0           ['stack_2_block_1/block_window_mh\n",
      "                                 (None, 4, 4, 128),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 128)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_38 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_39 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_4[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_29 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_38[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_30 (TFO  (None, 4, 32, 16)   0           ['tf.reshape_39[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_8 (TFOpLambda  (None, 4, 16, 16)   0           ['tf.compat.v1.transpose_29[0][0]\n",
      " )                                                               ',                               \n",
      "                                                                  'tf.compat.v1.transpose_30[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 4, 16, 16)   0           ['tf.linalg.matmul_8[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_window_m  (None, 4, 16, 16)   196         ['tf.math.multiply_4[0][0]']     \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_40 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_4[0][2]']             \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_window_m  (None, 4, 16, 16)   0           ['stack_2_block_1/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_31 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_40[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_9 (TFOpLambda  (None, 4, 16, 32)   0           ['stack_2_block_1/block_window_mh\n",
      " )                                                               sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_31[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_32 (TFO  (None, 16, 4, 32)   0           ['tf.linalg.matmul_9[0][0]']     \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_41 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_32[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_window_m  (None, 4, 4, 128)   16512       ['tf.reshape_41[0][0]']          \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_42 (TFOpLambda)     (None, 4, 4, 512)    0           ['stack_2_block_1/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_33 (TFO  (None, 4, 4, 512)   0           ['tf.reshape_42[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_43 (TFOpLambda)     (None, 16, 16, 128)  0           ['tf.compat.v1.transpose_33[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_attn_out  (None, 16, 16, 128)  0          ['stack_2_block_1/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_43[0][0]']          \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_ffn_prea  (None, 16, 16, 128)  256        ['stack_2_block_1/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_ffn/1_de  (None, 16, 16, 512)  66048      ['stack_2_block_1/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_11 (TFOpLambda)     (None, 16, 16, 512)  0           ['stack_2_block_1/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_ffn/2_de  (None, 16, 16, 128)  65664      ['tf.nn.gelu_11[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_2_block_1/block_ffn_outp  (None, 16, 16, 128)  0          ['stack_2_block_1/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_2_block_1/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_attn_prea  (None, 16, 16, 128)  256        ['stack_2_block_1/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_44 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_2_block_1/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_34 (TFO  (None, 4, 4, 2048)  0           ['tf.reshape_44[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_45 (TFOpLambda)     (None, 16, 4, 128)   0           ['tf.compat.v1.transpose_34[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_35 (TFO  (None, 4, 16, 128)  0           ['tf.reshape_45[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_46 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_35[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_window_mh  (None, 4, 4, 384)   49536       ['tf.reshape_46[0][0]']          \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_5 (TFOpLambda)        [(None, 4, 4, 128),  0           ['stack_2_block_1/grid_window_mhs\n",
      "                                 (None, 4, 4, 128),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 128)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_47 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_48 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_5[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_36 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_47[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_37 (TFO  (None, 4, 32, 16)   0           ['tf.reshape_48[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_10 (TFOpLambd  (None, 4, 16, 16)   0           ['tf.compat.v1.transpose_36[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_37[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 4, 16, 16)   0           ['tf.linalg.matmul_10[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_window_mh  (None, 4, 16, 16)   196         ['tf.math.multiply_5[0][0]']     \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_49 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_5[0][2]']             \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_window_mh  (None, 4, 16, 16)   0           ['stack_2_block_1/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_38 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_49[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_11 (TFOpLambd  (None, 4, 16, 32)   0           ['stack_2_block_1/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_38[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_39 (TFO  (None, 16, 4, 32)   0           ['tf.linalg.matmul_11[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_50 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_39[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_window_mh  (None, 4, 4, 128)   16512       ['tf.reshape_50[0][0]']          \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_51 (TFOpLambda)     (None, 4, 16, 128)   0           ['stack_2_block_1/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_40 (TFO  (None, 16, 4, 128)  0           ['tf.reshape_51[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_52 (TFOpLambda)     (None, 4, 4, 2048)   0           ['tf.compat.v1.transpose_40[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_41 (TFO  (None, 4, 4, 2048)  0           ['tf.reshape_52[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_53 (TFOpLambda)     (None, 16, 16, 128)  0           ['tf.compat.v1.transpose_41[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_attn_outp  (None, 16, 16, 128)  0          ['stack_2_block_1/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_53[0][0]']          \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_ffn_preac  (None, 16, 16, 128)  256        ['stack_2_block_1/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_ffn/1_den  (None, 16, 16, 512)  66048      ['stack_2_block_1/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_12 (TFOpLambda)     (None, 16, 16, 512)  0           ['stack_2_block_1/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_ffn/2_den  (None, 16, 16, 128)  65664      ['tf.nn.gelu_12[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_2_block_1/grid_ffn_outpu  (None, 16, 16, 128)  0          ['stack_2_block_1/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_2_block_1/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/preact_  (None, 16, 16, 128)  512        ['stack_2_block_1/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/expand_  (None, 16, 16, 512)  65536      ['stack_2_block_2/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/expand_  (None, 16, 16, 512)  2048       ['stack_2_block_2/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_13 (TFOpLambda)     (None, 16, 16, 512)  0           ['stack_2_block_2/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/MB_dw_c  (None, 16, 16, 512)  4608       ['tf.nn.gelu_13[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/MB_dw_b  (None, 16, 16, 512)  2048       ['stack_2_block_2/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_14 (TFOpLambda)     (None, 16, 16, 512)  0           ['stack_2_block_2/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 1, 1, 512)   0           ['tf.nn.gelu_14[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/se/1_co  (None, 1, 1, 32)    16416       ['tf.math.reduce_mean_3[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/se/swis  (None, 1, 1, 32)    0           ['stack_2_block_2/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/se/2_co  (None, 1, 1, 512)   16896       ['stack_2_block_2/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/se/sigm  (None, 1, 1, 512)   0           ['stack_2_block_2/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/se/out   (None, 16, 16, 512)  0          ['tf.nn.gelu_14[0][0]',          \n",
      " (Multiply)                                                       'stack_2_block_2/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/MB_pw_c  (None, 16, 16, 128)  65664      ['stack_2_block_2/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_2_block_2/mbconv/output   (None, 16, 16, 128)  0          ['stack_2_block_1/grid_ffn_output\n",
      " (Add)                                                           [0][0]',                         \n",
      "                                                                  'stack_2_block_2/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_attn_pre  (None, 16, 16, 128)  256        ['stack_2_block_2/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_54 (TFOpLambda)     (None, 4, 4, 512)    0           ['stack_2_block_2/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_42 (TFO  (None, 4, 4, 512)   0           ['tf.reshape_54[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_55 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_42[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_window_m  (None, 4, 4, 384)   49536       ['tf.reshape_55[0][0]']          \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_6 (TFOpLambda)        [(None, 4, 4, 128),  0           ['stack_2_block_2/block_window_mh\n",
      "                                 (None, 4, 4, 128),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 128)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_56 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_6[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_57 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_6[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_43 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_56[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_44 (TFO  (None, 4, 32, 16)   0           ['tf.reshape_57[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_12 (TFOpLambd  (None, 4, 16, 16)   0           ['tf.compat.v1.transpose_43[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_44[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 4, 16, 16)   0           ['tf.linalg.matmul_12[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_window_m  (None, 4, 16, 16)   196         ['tf.math.multiply_6[0][0]']     \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_58 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_6[0][2]']             \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_window_m  (None, 4, 16, 16)   0           ['stack_2_block_2/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_45 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_58[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_13 (TFOpLambd  (None, 4, 16, 32)   0           ['stack_2_block_2/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_45[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_46 (TFO  (None, 16, 4, 32)   0           ['tf.linalg.matmul_13[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_59 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_46[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_window_m  (None, 4, 4, 128)   16512       ['tf.reshape_59[0][0]']          \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_60 (TFOpLambda)     (None, 4, 4, 512)    0           ['stack_2_block_2/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_47 (TFO  (None, 4, 4, 512)   0           ['tf.reshape_60[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_61 (TFOpLambda)     (None, 16, 16, 128)  0           ['tf.compat.v1.transpose_47[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_attn_out  (None, 16, 16, 128)  0          ['stack_2_block_2/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_61[0][0]']          \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_ffn_prea  (None, 16, 16, 128)  256        ['stack_2_block_2/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_ffn/1_de  (None, 16, 16, 512)  66048      ['stack_2_block_2/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_15 (TFOpLambda)     (None, 16, 16, 512)  0           ['stack_2_block_2/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_ffn/2_de  (None, 16, 16, 128)  65664      ['tf.nn.gelu_15[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_2_block_2/block_ffn_outp  (None, 16, 16, 128)  0          ['stack_2_block_2/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_2_block_2/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_attn_prea  (None, 16, 16, 128)  256        ['stack_2_block_2/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_62 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_2_block_2/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_48 (TFO  (None, 4, 4, 2048)  0           ['tf.reshape_62[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_63 (TFOpLambda)     (None, 16, 4, 128)   0           ['tf.compat.v1.transpose_48[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_49 (TFO  (None, 4, 16, 128)  0           ['tf.reshape_63[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_64 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_49[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_window_mh  (None, 4, 4, 384)   49536       ['tf.reshape_64[0][0]']          \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_7 (TFOpLambda)        [(None, 4, 4, 128),  0           ['stack_2_block_2/grid_window_mhs\n",
      "                                 (None, 4, 4, 128),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 128)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_65 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_7[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_66 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_7[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_50 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_65[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_51 (TFO  (None, 4, 32, 16)   0           ['tf.reshape_66[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_14 (TFOpLambd  (None, 4, 16, 16)   0           ['tf.compat.v1.transpose_50[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_51[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 4, 16, 16)   0           ['tf.linalg.matmul_14[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_window_mh  (None, 4, 16, 16)   196         ['tf.math.multiply_7[0][0]']     \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_67 (TFOpLambda)     (None, 16, 4, 32)    0           ['tf.split_7[0][2]']             \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_window_mh  (None, 4, 16, 16)   0           ['stack_2_block_2/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_52 (TFO  (None, 4, 16, 32)   0           ['tf.reshape_67[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_15 (TFOpLambd  (None, 4, 16, 32)   0           ['stack_2_block_2/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_52[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_53 (TFO  (None, 16, 4, 32)   0           ['tf.linalg.matmul_15[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_68 (TFOpLambda)     (None, 4, 4, 128)    0           ['tf.compat.v1.transpose_53[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_window_mh  (None, 4, 4, 128)   16512       ['tf.reshape_68[0][0]']          \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_69 (TFOpLambda)     (None, 4, 16, 128)   0           ['stack_2_block_2/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_54 (TFO  (None, 16, 4, 128)  0           ['tf.reshape_69[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_70 (TFOpLambda)     (None, 4, 4, 2048)   0           ['tf.compat.v1.transpose_54[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_55 (TFO  (None, 4, 4, 2048)  0           ['tf.reshape_70[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_71 (TFOpLambda)     (None, 16, 16, 128)  0           ['tf.compat.v1.transpose_55[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_attn_outp  (None, 16, 16, 128)  0          ['stack_2_block_2/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_71[0][0]']          \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_ffn_preac  (None, 16, 16, 128)  256        ['stack_2_block_2/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_ffn/1_den  (None, 16, 16, 512)  66048      ['stack_2_block_2/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_16 (TFOpLambda)     (None, 16, 16, 512)  0           ['stack_2_block_2/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_ffn/2_den  (None, 16, 16, 128)  65664      ['tf.nn.gelu_16[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_2_block_2/grid_ffn_outpu  (None, 16, 16, 128)  0          ['stack_2_block_2/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_2_block_2/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/preact_  (None, 16, 16, 128)  512        ['stack_2_block_2/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/expand_  (None, 16, 16, 1024  131072     ['stack_3_block_1/mbconv/preact_b\n",
      " conv (Conv2D)                  )                                n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/expand_  (None, 16, 16, 1024  4096       ['stack_3_block_1/mbconv/expand_c\n",
      " bn (BatchNormalization)        )                                onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_17 (TFOpLambda)     (None, 16, 16, 1024  0           ['stack_3_block_1/mbconv/expand_b\n",
      "                                )                                n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/MB_dw_c  (None, 8, 8, 1024)  9216        ['tf.nn.gelu_17[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/MB_dw_b  (None, 8, 8, 1024)  4096        ['stack_3_block_1/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_18 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_1/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_4 (TFOpLam  (None, 1, 1, 1024)  0           ['tf.nn.gelu_18[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/se/1_co  (None, 1, 1, 64)    65600       ['tf.math.reduce_mean_4[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/se/swis  (None, 1, 1, 64)    0           ['stack_3_block_1/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/se/2_co  (None, 1, 1, 1024)  66560       ['stack_3_block_1/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/se/sigm  (None, 1, 1, 1024)  0           ['stack_3_block_1/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/shortcu  (None, 8, 8, 128)   0           ['stack_2_block_2/grid_ffn_output\n",
      " t_pool (AveragePooling2D)                                       [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/se/out   (None, 8, 8, 1024)  0           ['tf.nn.gelu_18[0][0]',          \n",
      " (Multiply)                                                       'stack_3_block_1/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/shortcu  (None, 8, 8, 256)   33024       ['stack_3_block_1/mbconv/shortcut\n",
      " t_conv (Conv2D)                                                 _pool[0][0]']                    \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/MB_pw_c  (None, 8, 8, 256)   262400      ['stack_3_block_1/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_1/mbconv/output   (None, 8, 8, 256)   0           ['stack_3_block_1/mbconv/shortcut\n",
      " (Add)                                                           _conv[0][0]',                    \n",
      "                                                                  'stack_3_block_1/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_attn_pre  (None, 8, 8, 256)   512         ['stack_3_block_1/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_72 (TFOpLambda)     (None, 4, 2, 1024)   0           ['stack_3_block_1/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_56 (TFO  (None, 2, 4, 1024)  0           ['tf.reshape_72[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_73 (TFOpLambda)     (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_56[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_window_m  (None, 4, 4, 768)   197376      ['tf.reshape_73[0][0]']          \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_8 (TFOpLambda)        [(None, 4, 4, 256),  0           ['stack_3_block_1/block_window_mh\n",
      "                                 (None, 4, 4, 256),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_74 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_8[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_75 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_8[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_57 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_74[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_58 (TFO  (None, 8, 32, 16)   0           ['tf.reshape_75[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_16 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_57[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_58[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 8, 16, 16)   0           ['tf.linalg.matmul_16[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_window_m  (None, 8, 16, 16)   392         ['tf.math.multiply_8[0][0]']     \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_76 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_8[0][2]']             \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_window_m  (None, 8, 16, 16)   0           ['stack_3_block_1/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_59 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_76[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_17 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_1/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_59[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_60 (TFO  (None, 16, 8, 32)   0           ['tf.linalg.matmul_17[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_77 (TFOpLambda)     (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_60[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_window_m  (None, 4, 4, 256)   65792       ['tf.reshape_77[0][0]']          \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_78 (TFOpLambda)     (None, 2, 4, 1024)   0           ['stack_3_block_1/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_61 (TFO  (None, 4, 2, 1024)  0           ['tf.reshape_78[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_79 (TFOpLambda)     (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_61[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_attn_out  (None, 8, 8, 256)   0           ['stack_3_block_1/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_79[0][0]']          \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_ffn_prea  (None, 8, 8, 256)   512         ['stack_3_block_1/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_ffn/1_de  (None, 8, 8, 1024)  263168      ['stack_3_block_1/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_19 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_1/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_ffn/2_de  (None, 8, 8, 256)   262400      ['tf.nn.gelu_19[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_1/block_ffn_outp  (None, 8, 8, 256)   0           ['stack_3_block_1/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_3_block_1/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_attn_prea  (None, 8, 8, 256)   512         ['stack_3_block_1/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_80 (TFOpLambda)     (None, 4, 2, 2048)   0           ['stack_3_block_1/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_62 (TFO  (None, 2, 4, 2048)  0           ['tf.reshape_80[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_81 (TFOpLambda)     (None, 16, 2, 256)   0           ['tf.compat.v1.transpose_62[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_63 (TFO  (None, 2, 16, 256)  0           ['tf.reshape_81[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_82 (TFOpLambda)     (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_63[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_window_mh  (None, 4, 4, 768)   197376      ['tf.reshape_82[0][0]']          \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_9 (TFOpLambda)        [(None, 4, 4, 256),  0           ['stack_3_block_1/grid_window_mhs\n",
      "                                 (None, 4, 4, 256),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_83 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_9[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_84 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_9[0][1]']             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_64 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_83[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_65 (TFO  (None, 8, 32, 16)   0           ['tf.reshape_84[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_18 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_64[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_65[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, 8, 16, 16)   0           ['tf.linalg.matmul_18[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_window_mh  (None, 8, 16, 16)   392         ['tf.math.multiply_9[0][0]']     \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_85 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_9[0][2]']             \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_window_mh  (None, 8, 16, 16)   0           ['stack_3_block_1/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_66 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_85[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_19 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_1/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_66[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_67 (TFO  (None, 16, 8, 32)   0           ['tf.linalg.matmul_19[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_86 (TFOpLambda)     (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_67[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_window_mh  (None, 4, 4, 256)   65792       ['tf.reshape_86[0][0]']          \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_87 (TFOpLambda)     (None, 2, 16, 256)   0           ['stack_3_block_1/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_68 (TFO  (None, 16, 2, 256)  0           ['tf.reshape_87[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_88 (TFOpLambda)     (None, 2, 4, 2048)   0           ['tf.compat.v1.transpose_68[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_69 (TFO  (None, 4, 2, 2048)  0           ['tf.reshape_88[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_89 (TFOpLambda)     (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_69[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_attn_outp  (None, 8, 8, 256)   0           ['stack_3_block_1/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_89[0][0]']          \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_ffn_preac  (None, 8, 8, 256)   512         ['stack_3_block_1/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_ffn/1_den  (None, 8, 8, 1024)  263168      ['stack_3_block_1/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_20 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_1/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_ffn/2_den  (None, 8, 8, 256)   262400      ['tf.nn.gelu_20[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_3_block_1/grid_ffn_outpu  (None, 8, 8, 256)   0           ['stack_3_block_1/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_3_block_1/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/preact_  (None, 8, 8, 256)   1024        ['stack_3_block_1/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/expand_  (None, 8, 8, 1024)  262144      ['stack_3_block_2/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/expand_  (None, 8, 8, 1024)  4096        ['stack_3_block_2/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_21 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_2/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/MB_dw_c  (None, 8, 8, 1024)  9216        ['tf.nn.gelu_21[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/MB_dw_b  (None, 8, 8, 1024)  4096        ['stack_3_block_2/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_22 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_2/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_5 (TFOpLam  (None, 1, 1, 1024)  0           ['tf.nn.gelu_22[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/se/1_co  (None, 1, 1, 64)    65600       ['tf.math.reduce_mean_5[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/se/swis  (None, 1, 1, 64)    0           ['stack_3_block_2/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/se/2_co  (None, 1, 1, 1024)  66560       ['stack_3_block_2/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/se/sigm  (None, 1, 1, 1024)  0           ['stack_3_block_2/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/se/out   (None, 8, 8, 1024)  0           ['tf.nn.gelu_22[0][0]',          \n",
      " (Multiply)                                                       'stack_3_block_2/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/MB_pw_c  (None, 8, 8, 256)   262400      ['stack_3_block_2/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_2/mbconv/output   (None, 8, 8, 256)   0           ['stack_3_block_1/grid_ffn_output\n",
      " (Add)                                                           [0][0]',                         \n",
      "                                                                  'stack_3_block_2/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_attn_pre  (None, 8, 8, 256)   512         ['stack_3_block_2/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_90 (TFOpLambda)     (None, 4, 2, 1024)   0           ['stack_3_block_2/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_70 (TFO  (None, 2, 4, 1024)  0           ['tf.reshape_90[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_91 (TFOpLambda)     (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_70[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_window_m  (None, 4, 4, 768)   197376      ['tf.reshape_91[0][0]']          \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_10 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_2/block_window_mh\n",
      "                                 (None, 4, 4, 256),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_92 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_10[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_93 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_10[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_71 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_92[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_72 (TFO  (None, 8, 32, 16)   0           ['tf.reshape_93[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_20 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_71[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_72[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_20[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_window_m  (None, 8, 16, 16)   392         ['tf.math.multiply_10[0][0]']    \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_94 (TFOpLambda)     (None, 16, 8, 32)    0           ['tf.split_10[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_window_m  (None, 8, 16, 16)   0           ['stack_3_block_2/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_73 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_94[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_21 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_2/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_73[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_74 (TFO  (None, 16, 8, 32)   0           ['tf.linalg.matmul_21[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_95 (TFOpLambda)     (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_74[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_window_m  (None, 4, 4, 256)   65792       ['tf.reshape_95[0][0]']          \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_96 (TFOpLambda)     (None, 2, 4, 1024)   0           ['stack_3_block_2/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_75 (TFO  (None, 4, 2, 1024)  0           ['tf.reshape_96[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_97 (TFOpLambda)     (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_75[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_attn_out  (None, 8, 8, 256)   0           ['stack_3_block_2/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_97[0][0]']          \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_ffn_prea  (None, 8, 8, 256)   512         ['stack_3_block_2/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_ffn/1_de  (None, 8, 8, 1024)  263168      ['stack_3_block_2/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_23 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_2/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_ffn/2_de  (None, 8, 8, 256)   262400      ['tf.nn.gelu_23[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_2/block_ffn_outp  (None, 8, 8, 256)   0           ['stack_3_block_2/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_3_block_2/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_attn_prea  (None, 8, 8, 256)   512         ['stack_3_block_2/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_98 (TFOpLambda)     (None, 4, 2, 2048)   0           ['stack_3_block_2/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_76 (TFO  (None, 2, 4, 2048)  0           ['tf.reshape_98[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_99 (TFOpLambda)     (None, 16, 2, 256)   0           ['tf.compat.v1.transpose_76[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_77 (TFO  (None, 2, 16, 256)  0           ['tf.reshape_99[0][0]']          \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_100 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_77[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_window_mh  (None, 4, 4, 768)   197376      ['tf.reshape_100[0][0]']         \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_11 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_2/grid_window_mhs\n",
      "                                 (None, 4, 4, 256),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_101 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_11[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_102 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_11[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_78 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_101[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_79 (TFO  (None, 8, 32, 16)   0           ['tf.reshape_102[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_22 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_78[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_79[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_22[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_window_mh  (None, 8, 16, 16)   392         ['tf.math.multiply_11[0][0]']    \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_103 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_11[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_window_mh  (None, 8, 16, 16)   0           ['stack_3_block_2/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_80 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_103[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_23 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_2/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_80[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_81 (TFO  (None, 16, 8, 32)   0           ['tf.linalg.matmul_23[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_104 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_81[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_window_mh  (None, 4, 4, 256)   65792       ['tf.reshape_104[0][0]']         \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_105 (TFOpLambda)    (None, 2, 16, 256)   0           ['stack_3_block_2/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_82 (TFO  (None, 16, 2, 256)  0           ['tf.reshape_105[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_106 (TFOpLambda)    (None, 2, 4, 2048)   0           ['tf.compat.v1.transpose_82[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_83 (TFO  (None, 4, 2, 2048)  0           ['tf.reshape_106[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_107 (TFOpLambda)    (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_83[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_attn_outp  (None, 8, 8, 256)   0           ['stack_3_block_2/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_107[0][0]']         \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_ffn_preac  (None, 8, 8, 256)   512         ['stack_3_block_2/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_ffn/1_den  (None, 8, 8, 1024)  263168      ['stack_3_block_2/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_24 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_2/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_ffn/2_den  (None, 8, 8, 256)   262400      ['tf.nn.gelu_24[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_3_block_2/grid_ffn_outpu  (None, 8, 8, 256)   0           ['stack_3_block_2/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_3_block_2/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/preact_  (None, 8, 8, 256)   1024        ['stack_3_block_2/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/expand_  (None, 8, 8, 1024)  262144      ['stack_3_block_3/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/expand_  (None, 8, 8, 1024)  4096        ['stack_3_block_3/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_25 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_3/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/MB_dw_c  (None, 8, 8, 1024)  9216        ['tf.nn.gelu_25[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/MB_dw_b  (None, 8, 8, 1024)  4096        ['stack_3_block_3/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_26 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_3/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_6 (TFOpLam  (None, 1, 1, 1024)  0           ['tf.nn.gelu_26[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/se/1_co  (None, 1, 1, 64)    65600       ['tf.math.reduce_mean_6[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/se/swis  (None, 1, 1, 64)    0           ['stack_3_block_3/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/se/2_co  (None, 1, 1, 1024)  66560       ['stack_3_block_3/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/se/sigm  (None, 1, 1, 1024)  0           ['stack_3_block_3/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/se/out   (None, 8, 8, 1024)  0           ['tf.nn.gelu_26[0][0]',          \n",
      " (Multiply)                                                       'stack_3_block_3/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/MB_pw_c  (None, 8, 8, 256)   262400      ['stack_3_block_3/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_3/mbconv/output   (None, 8, 8, 256)   0           ['stack_3_block_2/grid_ffn_output\n",
      " (Add)                                                           [0][0]',                         \n",
      "                                                                  'stack_3_block_3/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_attn_pre  (None, 8, 8, 256)   512         ['stack_3_block_3/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_108 (TFOpLambda)    (None, 4, 2, 1024)   0           ['stack_3_block_3/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_84 (TFO  (None, 2, 4, 1024)  0           ['tf.reshape_108[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_109 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_84[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_window_m  (None, 4, 4, 768)   197376      ['tf.reshape_109[0][0]']         \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_12 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_3/block_window_mh\n",
      "                                 (None, 4, 4, 256),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_110 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_12[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_111 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_12[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_85 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_110[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_86 (TFO  (None, 8, 32, 16)   0           ['tf.reshape_111[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_24 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_85[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_86[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_24[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_window_m  (None, 8, 16, 16)   392         ['tf.math.multiply_12[0][0]']    \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_112 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_12[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_window_m  (None, 8, 16, 16)   0           ['stack_3_block_3/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_87 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_112[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_25 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_3/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_87[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_88 (TFO  (None, 16, 8, 32)   0           ['tf.linalg.matmul_25[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_113 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_88[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_window_m  (None, 4, 4, 256)   65792       ['tf.reshape_113[0][0]']         \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_114 (TFOpLambda)    (None, 2, 4, 1024)   0           ['stack_3_block_3/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_89 (TFO  (None, 4, 2, 1024)  0           ['tf.reshape_114[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_115 (TFOpLambda)    (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_89[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_attn_out  (None, 8, 8, 256)   0           ['stack_3_block_3/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_115[0][0]']         \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_ffn_prea  (None, 8, 8, 256)   512         ['stack_3_block_3/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_ffn/1_de  (None, 8, 8, 1024)  263168      ['stack_3_block_3/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_27 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_3/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_ffn/2_de  (None, 8, 8, 256)   262400      ['tf.nn.gelu_27[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_3/block_ffn_outp  (None, 8, 8, 256)   0           ['stack_3_block_3/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_3_block_3/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_attn_prea  (None, 8, 8, 256)   512         ['stack_3_block_3/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_116 (TFOpLambda)    (None, 4, 2, 2048)   0           ['stack_3_block_3/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_90 (TFO  (None, 2, 4, 2048)  0           ['tf.reshape_116[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_117 (TFOpLambda)    (None, 16, 2, 256)   0           ['tf.compat.v1.transpose_90[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_91 (TFO  (None, 2, 16, 256)  0           ['tf.reshape_117[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_118 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_91[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_window_mh  (None, 4, 4, 768)   197376      ['tf.reshape_118[0][0]']         \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_13 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_3/grid_window_mhs\n",
      "                                 (None, 4, 4, 256),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_119 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_13[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_120 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_13[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_92 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_119[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_93 (TFO  (None, 8, 32, 16)   0           ['tf.reshape_120[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_26 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_92[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_93[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_26[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_window_mh  (None, 8, 16, 16)   392         ['tf.math.multiply_13[0][0]']    \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_121 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_13[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_window_mh  (None, 8, 16, 16)   0           ['stack_3_block_3/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_94 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_121[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_27 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_3/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_94[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_95 (TFO  (None, 16, 8, 32)   0           ['tf.linalg.matmul_27[0][0]']    \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_122 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_95[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_window_mh  (None, 4, 4, 256)   65792       ['tf.reshape_122[0][0]']         \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_123 (TFOpLambda)    (None, 2, 16, 256)   0           ['stack_3_block_3/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_96 (TFO  (None, 16, 2, 256)  0           ['tf.reshape_123[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_124 (TFOpLambda)    (None, 2, 4, 2048)   0           ['tf.compat.v1.transpose_96[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_97 (TFO  (None, 4, 2, 2048)  0           ['tf.reshape_124[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_125 (TFOpLambda)    (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_97[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_attn_outp  (None, 8, 8, 256)   0           ['stack_3_block_3/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_125[0][0]']         \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_ffn_preac  (None, 8, 8, 256)   512         ['stack_3_block_3/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_ffn/1_den  (None, 8, 8, 1024)  263168      ['stack_3_block_3/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_28 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_3/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_ffn/2_den  (None, 8, 8, 256)   262400      ['tf.nn.gelu_28[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_3_block_3/grid_ffn_outpu  (None, 8, 8, 256)   0           ['stack_3_block_3/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_3_block_3/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/preact_  (None, 8, 8, 256)   1024        ['stack_3_block_3/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/expand_  (None, 8, 8, 1024)  262144      ['stack_3_block_4/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/expand_  (None, 8, 8, 1024)  4096        ['stack_3_block_4/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_29 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_4/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/MB_dw_c  (None, 8, 8, 1024)  9216        ['tf.nn.gelu_29[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/MB_dw_b  (None, 8, 8, 1024)  4096        ['stack_3_block_4/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_30 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_4/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_7 (TFOpLam  (None, 1, 1, 1024)  0           ['tf.nn.gelu_30[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/se/1_co  (None, 1, 1, 64)    65600       ['tf.math.reduce_mean_7[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/se/swis  (None, 1, 1, 64)    0           ['stack_3_block_4/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/se/2_co  (None, 1, 1, 1024)  66560       ['stack_3_block_4/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/se/sigm  (None, 1, 1, 1024)  0           ['stack_3_block_4/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/se/out   (None, 8, 8, 1024)  0           ['tf.nn.gelu_30[0][0]',          \n",
      " (Multiply)                                                       'stack_3_block_4/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/MB_pw_c  (None, 8, 8, 256)   262400      ['stack_3_block_4/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_4/mbconv/output   (None, 8, 8, 256)   0           ['stack_3_block_3/grid_ffn_output\n",
      " (Add)                                                           [0][0]',                         \n",
      "                                                                  'stack_3_block_4/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_attn_pre  (None, 8, 8, 256)   512         ['stack_3_block_4/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_126 (TFOpLambda)    (None, 4, 2, 1024)   0           ['stack_3_block_4/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_98 (TFO  (None, 2, 4, 1024)  0           ['tf.reshape_126[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.reshape_127 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_98[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_window_m  (None, 4, 4, 768)   197376      ['tf.reshape_127[0][0]']         \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_14 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_4/block_window_mh\n",
      "                                 (None, 4, 4, 256),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_128 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_14[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_129 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_14[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_99 (TFO  (None, 8, 16, 32)   0           ['tf.reshape_128[0][0]']         \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_100 (TF  (None, 8, 32, 16)   0           ['tf.reshape_129[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_28 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_99[0][0]\n",
      " a)                                                              ',                               \n",
      "                                                                  'tf.compat.v1.transpose_100[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_28[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_window_m  (None, 8, 16, 16)   392         ['tf.math.multiply_14[0][0]']    \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_130 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_14[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_window_m  (None, 8, 16, 16)   0           ['stack_3_block_4/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_101 (TF  (None, 8, 16, 32)   0           ['tf.reshape_130[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_29 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_4/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_101[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_102 (TF  (None, 16, 8, 32)   0           ['tf.linalg.matmul_29[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_131 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_102[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_window_m  (None, 4, 4, 256)   65792       ['tf.reshape_131[0][0]']         \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_132 (TFOpLambda)    (None, 2, 4, 1024)   0           ['stack_3_block_4/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_103 (TF  (None, 4, 2, 1024)  0           ['tf.reshape_132[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_133 (TFOpLambda)    (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_103[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_attn_out  (None, 8, 8, 256)   0           ['stack_3_block_4/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_133[0][0]']         \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_ffn_prea  (None, 8, 8, 256)   512         ['stack_3_block_4/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_ffn/1_de  (None, 8, 8, 1024)  263168      ['stack_3_block_4/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_31 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_4/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_ffn/2_de  (None, 8, 8, 256)   262400      ['tf.nn.gelu_31[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_4/block_ffn_outp  (None, 8, 8, 256)   0           ['stack_3_block_4/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_3_block_4/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_attn_prea  (None, 8, 8, 256)   512         ['stack_3_block_4/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_134 (TFOpLambda)    (None, 4, 2, 2048)   0           ['stack_3_block_4/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_104 (TF  (None, 2, 4, 2048)  0           ['tf.reshape_134[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_135 (TFOpLambda)    (None, 16, 2, 256)   0           ['tf.compat.v1.transpose_104[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_105 (TF  (None, 2, 16, 256)  0           ['tf.reshape_135[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_136 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_105[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_window_mh  (None, 4, 4, 768)   197376      ['tf.reshape_136[0][0]']         \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_15 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_4/grid_window_mhs\n",
      "                                 (None, 4, 4, 256),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_137 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_138 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_15[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_106 (TF  (None, 8, 16, 32)   0           ['tf.reshape_137[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_107 (TF  (None, 8, 32, 16)   0           ['tf.reshape_138[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_30 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_106[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_107[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_30[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_window_mh  (None, 8, 16, 16)   392         ['tf.math.multiply_15[0][0]']    \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_139 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_15[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_window_mh  (None, 8, 16, 16)   0           ['stack_3_block_4/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_108 (TF  (None, 8, 16, 32)   0           ['tf.reshape_139[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_31 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_4/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_108[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_109 (TF  (None, 16, 8, 32)   0           ['tf.linalg.matmul_31[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_140 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_109[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_window_mh  (None, 4, 4, 256)   65792       ['tf.reshape_140[0][0]']         \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_141 (TFOpLambda)    (None, 2, 16, 256)   0           ['stack_3_block_4/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_110 (TF  (None, 16, 2, 256)  0           ['tf.reshape_141[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_142 (TFOpLambda)    (None, 2, 4, 2048)   0           ['tf.compat.v1.transpose_110[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_111 (TF  (None, 4, 2, 2048)  0           ['tf.reshape_142[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_143 (TFOpLambda)    (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_111[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_attn_outp  (None, 8, 8, 256)   0           ['stack_3_block_4/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_143[0][0]']         \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_ffn_preac  (None, 8, 8, 256)   512         ['stack_3_block_4/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_ffn/1_den  (None, 8, 8, 1024)  263168      ['stack_3_block_4/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_32 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_4/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_ffn/2_den  (None, 8, 8, 256)   262400      ['tf.nn.gelu_32[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_3_block_4/grid_ffn_outpu  (None, 8, 8, 256)   0           ['stack_3_block_4/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_3_block_4/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/preact_  (None, 8, 8, 256)   1024        ['stack_3_block_4/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/expand_  (None, 8, 8, 1024)  262144      ['stack_3_block_5/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/expand_  (None, 8, 8, 1024)  4096        ['stack_3_block_5/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_33 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_5/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/MB_dw_c  (None, 8, 8, 1024)  9216        ['tf.nn.gelu_33[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/MB_dw_b  (None, 8, 8, 1024)  4096        ['stack_3_block_5/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_34 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_5/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_8 (TFOpLam  (None, 1, 1, 1024)  0           ['tf.nn.gelu_34[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/se/1_co  (None, 1, 1, 64)    65600       ['tf.math.reduce_mean_8[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/se/swis  (None, 1, 1, 64)    0           ['stack_3_block_5/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/se/2_co  (None, 1, 1, 1024)  66560       ['stack_3_block_5/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/se/sigm  (None, 1, 1, 1024)  0           ['stack_3_block_5/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/se/out   (None, 8, 8, 1024)  0           ['tf.nn.gelu_34[0][0]',          \n",
      " (Multiply)                                                       'stack_3_block_5/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/MB_pw_c  (None, 8, 8, 256)   262400      ['stack_3_block_5/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_3_block_5/mbconv/output   (None, 8, 8, 256)   0           ['stack_3_block_4/grid_ffn_output\n",
      " (Add)                                                           [0][0]',                         \n",
      "                                                                  'stack_3_block_5/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_attn_pre  (None, 8, 8, 256)   512         ['stack_3_block_5/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " tf.reshape_144 (TFOpLambda)    (None, 4, 2, 1024)   0           ['stack_3_block_5/block_attn_prea\n",
      "                                                                 ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_112 (TF  (None, 2, 4, 1024)  0           ['tf.reshape_144[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_145 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_112[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_window_m  (None, 4, 4, 768)   197376      ['tf.reshape_145[0][0]']         \n",
      " hsa/qkv_conv (Conv2D)                                                                            \n",
      "                                                                                                  \n",
      " tf.split_16 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_5/block_window_mh\n",
      "                                 (None, 4, 4, 256),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_146 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_16[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_147 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_16[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_113 (TF  (None, 8, 16, 32)   0           ['tf.reshape_146[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_114 (TF  (None, 8, 32, 16)   0           ['tf.reshape_147[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_32 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_113[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_114[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_32[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_window_m  (None, 8, 16, 16)   392         ['tf.math.multiply_16[0][0]']    \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_148 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_16[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_window_m  (None, 8, 16, 16)   0           ['stack_3_block_5/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_115 (TF  (None, 8, 16, 32)   0           ['tf.reshape_148[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_33 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_5/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_115[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_116 (TF  (None, 16, 8, 32)   0           ['tf.linalg.matmul_33[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_149 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_116[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_window_m  (None, 4, 4, 256)   65792       ['tf.reshape_149[0][0]']         \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_150 (TFOpLambda)    (None, 2, 4, 1024)   0           ['stack_3_block_5/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_117 (TF  (None, 4, 2, 1024)  0           ['tf.reshape_150[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_151 (TFOpLambda)    (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_117[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_attn_out  (None, 8, 8, 256)   0           ['stack_3_block_5/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_151[0][0]']         \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_ffn_prea  (None, 8, 8, 256)   512         ['stack_3_block_5/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_ffn/1_de  (None, 8, 8, 1024)  263168      ['stack_3_block_5/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_35 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_5/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_ffn/2_de  (None, 8, 8, 256)   262400      ['tf.nn.gelu_35[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_3_block_5/block_ffn_outp  (None, 8, 8, 256)   0           ['stack_3_block_5/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_3_block_5/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_attn_prea  (None, 8, 8, 256)   512         ['stack_3_block_5/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_152 (TFOpLambda)    (None, 4, 2, 2048)   0           ['stack_3_block_5/grid_attn_preac\n",
      "                                                                 t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_118 (TF  (None, 2, 4, 2048)  0           ['tf.reshape_152[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_153 (TFOpLambda)    (None, 16, 2, 256)   0           ['tf.compat.v1.transpose_118[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_119 (TF  (None, 2, 16, 256)  0           ['tf.reshape_153[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_154 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_119[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_window_mh  (None, 4, 4, 768)   197376      ['tf.reshape_154[0][0]']         \n",
      " sa/qkv_conv (Conv2D)                                                                             \n",
      "                                                                                                  \n",
      " tf.split_17 (TFOpLambda)       [(None, 4, 4, 256),  0           ['stack_3_block_5/grid_window_mhs\n",
      "                                 (None, 4, 4, 256),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_155 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_17[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_156 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_17[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_120 (TF  (None, 8, 16, 32)   0           ['tf.reshape_155[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_121 (TF  (None, 8, 32, 16)   0           ['tf.reshape_156[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_34 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.compat.v1.transpose_120[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_121[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpLambd  (None, 8, 16, 16)   0           ['tf.linalg.matmul_34[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_window_mh  (None, 8, 16, 16)   392         ['tf.math.multiply_17[0][0]']    \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_157 (TFOpLambda)    (None, 16, 8, 32)    0           ['tf.split_17[0][2]']            \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_window_mh  (None, 8, 16, 16)   0           ['stack_3_block_5/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_122 (TF  (None, 8, 16, 32)   0           ['tf.reshape_157[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_35 (TFOpLambd  (None, 8, 16, 32)   0           ['stack_3_block_5/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_122[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_123 (TF  (None, 16, 8, 32)   0           ['tf.linalg.matmul_35[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_158 (TFOpLambda)    (None, 4, 4, 256)    0           ['tf.compat.v1.transpose_123[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_window_mh  (None, 4, 4, 256)   65792       ['tf.reshape_158[0][0]']         \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_159 (TFOpLambda)    (None, 2, 16, 256)   0           ['stack_3_block_5/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_124 (TF  (None, 16, 2, 256)  0           ['tf.reshape_159[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_160 (TFOpLambda)    (None, 2, 4, 2048)   0           ['tf.compat.v1.transpose_124[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_125 (TF  (None, 4, 2, 2048)  0           ['tf.reshape_160[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_161 (TFOpLambda)    (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_125[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_attn_outp  (None, 8, 8, 256)   0           ['stack_3_block_5/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_161[0][0]']         \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_ffn_preac  (None, 8, 8, 256)   512         ['stack_3_block_5/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_ffn/1_den  (None, 8, 8, 1024)  263168      ['stack_3_block_5/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_36 (TFOpLambda)     (None, 8, 8, 1024)   0           ['stack_3_block_5/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_ffn/2_den  (None, 8, 8, 256)   262400      ['tf.nn.gelu_36[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_3_block_5/grid_ffn_outpu  (None, 8, 8, 256)   0           ['stack_3_block_5/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_3_block_5/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/preact_  (None, 8, 8, 256)   1024        ['stack_3_block_5/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/expand_  (None, 8, 8, 2048)  524288      ['stack_4_block_1/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/expand_  (None, 8, 8, 2048)  8192        ['stack_4_block_1/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_37 (TFOpLambda)     (None, 8, 8, 2048)   0           ['stack_4_block_1/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/MB_dw_c  (None, 4, 4, 2048)  18432       ['tf.nn.gelu_37[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/MB_dw_b  (None, 4, 4, 2048)  8192        ['stack_4_block_1/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_38 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_4_block_1/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_9 (TFOpLam  (None, 1, 1, 2048)  0           ['tf.nn.gelu_38[0][0]']          \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/se/1_co  (None, 1, 1, 128)   262272      ['tf.math.reduce_mean_9[0][0]']  \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/se/swis  (None, 1, 1, 128)   0           ['stack_4_block_1/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/se/2_co  (None, 1, 1, 2048)  264192      ['stack_4_block_1/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/se/sigm  (None, 1, 1, 2048)  0           ['stack_4_block_1/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/shortcu  (None, 4, 4, 256)   0           ['stack_3_block_5/grid_ffn_output\n",
      " t_pool (AveragePooling2D)                                       [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/se/out   (None, 4, 4, 2048)  0           ['tf.nn.gelu_38[0][0]',          \n",
      " (Multiply)                                                       'stack_4_block_1/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/shortcu  (None, 4, 4, 512)   131584      ['stack_4_block_1/mbconv/shortcut\n",
      " t_conv (Conv2D)                                                 _pool[0][0]']                    \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/MB_pw_c  (None, 4, 4, 512)   1049088     ['stack_4_block_1/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_4_block_1/mbconv/output   (None, 4, 4, 512)   0           ['stack_4_block_1/mbconv/shortcut\n",
      " (Add)                                                           _conv[0][0]',                    \n",
      "                                                                  'stack_4_block_1/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_attn_pre  (None, 4, 4, 512)   1024        ['stack_4_block_1/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_window_m  (None, 4, 4, 1536)  787968      ['stack_4_block_1/block_attn_prea\n",
      " hsa/qkv_conv (Conv2D)                                           ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.split_18 (TFOpLambda)       [(None, 4, 4, 512),  0           ['stack_4_block_1/block_window_mh\n",
      "                                 (None, 4, 4, 512),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 512)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_162 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_18[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_163 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_18[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_126 (TF  (None, 16, 16, 32)  0           ['tf.reshape_162[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_127 (TF  (None, 16, 32, 16)  0           ['tf.reshape_163[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_36 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.compat.v1.transpose_126[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_127[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.linalg.matmul_36[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_window_m  (None, 16, 16, 16)  784         ['tf.math.multiply_18[0][0]']    \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_164 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_18[0][2]']            \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_window_m  (None, 16, 16, 16)  0           ['stack_4_block_1/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_128 (TF  (None, 16, 16, 32)  0           ['tf.reshape_164[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_37 (TFOpLambd  (None, 16, 16, 32)  0           ['stack_4_block_1/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_128[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_129 (TF  (None, 16, 16, 32)  0           ['tf.linalg.matmul_37[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_165 (TFOpLambda)    (None, 4, 4, 512)    0           ['tf.compat.v1.transpose_129[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_window_m  (None, 4, 4, 512)   262656      ['tf.reshape_165[0][0]']         \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_166 (TFOpLambda)    (None, 4, 4, 512)    0           ['stack_4_block_1/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_attn_out  (None, 4, 4, 512)   0           ['stack_4_block_1/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_166[0][0]']         \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_ffn_prea  (None, 4, 4, 512)   1024        ['stack_4_block_1/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_ffn/1_de  (None, 4, 4, 2048)  1050624     ['stack_4_block_1/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_39 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_4_block_1/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_ffn/2_de  (None, 4, 4, 512)   1049088     ['tf.nn.gelu_39[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_4_block_1/block_ffn_outp  (None, 4, 4, 512)   0           ['stack_4_block_1/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_4_block_1/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_attn_prea  (None, 4, 4, 512)   1024        ['stack_4_block_1/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_window_mh  (None, 4, 4, 1536)  787968      ['stack_4_block_1/grid_attn_preac\n",
      " sa/qkv_conv (Conv2D)                                            t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.split_19 (TFOpLambda)       [(None, 4, 4, 512),  0           ['stack_4_block_1/grid_window_mhs\n",
      "                                 (None, 4, 4, 512),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 512)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_167 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_19[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_168 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_19[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_130 (TF  (None, 16, 16, 32)  0           ['tf.reshape_167[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_131 (TF  (None, 16, 32, 16)  0           ['tf.reshape_168[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_38 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.compat.v1.transpose_130[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_131[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.linalg.matmul_38[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_window_mh  (None, 16, 16, 16)  784         ['tf.math.multiply_19[0][0]']    \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_169 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_19[0][2]']            \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_window_mh  (None, 16, 16, 16)  0           ['stack_4_block_1/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_132 (TF  (None, 16, 16, 32)  0           ['tf.reshape_169[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_39 (TFOpLambd  (None, 16, 16, 32)  0           ['stack_4_block_1/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_132[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_133 (TF  (None, 16, 16, 32)  0           ['tf.linalg.matmul_39[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_170 (TFOpLambda)    (None, 4, 4, 512)    0           ['tf.compat.v1.transpose_133[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_window_mh  (None, 4, 4, 512)   262656      ['tf.reshape_170[0][0]']         \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_171 (TFOpLambda)    (None, 4, 4, 512)    0           ['stack_4_block_1/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_attn_outp  (None, 4, 4, 512)   0           ['stack_4_block_1/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_171[0][0]']         \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_ffn_preac  (None, 4, 4, 512)   1024        ['stack_4_block_1/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_ffn/1_den  (None, 4, 4, 2048)  1050624     ['stack_4_block_1/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_40 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_4_block_1/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_ffn/2_den  (None, 4, 4, 512)   1049088     ['tf.nn.gelu_40[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_4_block_1/grid_ffn_outpu  (None, 4, 4, 512)   0           ['stack_4_block_1/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_4_block_1/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/preact_  (None, 4, 4, 512)   2048        ['stack_4_block_1/grid_ffn_output\n",
      " bn (BatchNormalization)                                         [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/expand_  (None, 4, 4, 2048)  1048576     ['stack_4_block_2/mbconv/preact_b\n",
      " conv (Conv2D)                                                   n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/expand_  (None, 4, 4, 2048)  8192        ['stack_4_block_2/mbconv/expand_c\n",
      " bn (BatchNormalization)                                         onv[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_41 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_4_block_2/mbconv/expand_b\n",
      "                                                                 n[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/MB_dw_c  (None, 4, 4, 2048)  18432       ['tf.nn.gelu_41[0][0]']          \n",
      " onv (DepthwiseConv2D)                                                                            \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/MB_dw_b  (None, 4, 4, 2048)  8192        ['stack_4_block_2/mbconv/MB_dw_co\n",
      " n (BatchNormalization)                                          nv[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.nn.gelu_42 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_4_block_2/mbconv/MB_dw_bn\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_10 (TFOpLa  (None, 1, 1, 2048)  0           ['tf.nn.gelu_42[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/se/1_co  (None, 1, 1, 128)   262272      ['tf.math.reduce_mean_10[0][0]'] \n",
      " nv (Conv2D)                                                                                      \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/se/swis  (None, 1, 1, 128)   0           ['stack_4_block_2/mbconv/se/1_con\n",
      " h (Activation)                                                  v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/se/2_co  (None, 1, 1, 2048)  264192      ['stack_4_block_2/mbconv/se/swish\n",
      " nv (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/se/sigm  (None, 1, 1, 2048)  0           ['stack_4_block_2/mbconv/se/2_con\n",
      " oid (Activation)                                                v[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/se/out   (None, 4, 4, 2048)  0           ['tf.nn.gelu_42[0][0]',          \n",
      " (Multiply)                                                       'stack_4_block_2/mbconv/se/sigmo\n",
      "                                                                 id[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/MB_pw_c  (None, 4, 4, 512)   1049088     ['stack_4_block_2/mbconv/se/out[0\n",
      " onv (Conv2D)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " stack_4_block_2/mbconv/output   (None, 4, 4, 512)   0           ['stack_4_block_1/grid_ffn_output\n",
      " (Add)                                                           [0][0]',                         \n",
      "                                                                  'stack_4_block_2/mbconv/MB_pw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_attn_pre  (None, 4, 4, 512)   1024        ['stack_4_block_2/mbconv/output[0\n",
      " act_ln (LayerNormalization)                                     ][0]']                           \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_window_m  (None, 4, 4, 1536)  787968      ['stack_4_block_2/block_attn_prea\n",
      " hsa/qkv_conv (Conv2D)                                           ct_ln[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.split_20 (TFOpLambda)       [(None, 4, 4, 512),  0           ['stack_4_block_2/block_window_mh\n",
      "                                 (None, 4, 4, 512),              sa/qkv_conv[0][0]']              \n",
      "                                 (None, 4, 4, 512)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_172 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_20[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_173 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_20[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_134 (TF  (None, 16, 16, 32)  0           ['tf.reshape_172[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_135 (TF  (None, 16, 32, 16)  0           ['tf.reshape_173[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_40 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.compat.v1.transpose_134[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_135[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.linalg.matmul_40[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_window_m  (None, 16, 16, 16)  784         ['tf.math.multiply_20[0][0]']    \n",
      " hsa/pos_emb (MultiHeadRelative                                                                   \n",
      " PositionalEmbedding)                                                                             \n",
      "                                                                                                  \n",
      " tf.reshape_174 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_20[0][2]']            \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_window_m  (None, 16, 16, 16)  0           ['stack_4_block_2/block_window_mh\n",
      " hsa/attention_scores (Softmax)                                  sa/pos_emb[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_136 (TF  (None, 16, 16, 32)  0           ['tf.reshape_174[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_41 (TFOpLambd  (None, 16, 16, 32)  0           ['stack_4_block_2/block_window_mh\n",
      " a)                                                              sa/attention_scores[0][0]',      \n",
      "                                                                  'tf.compat.v1.transpose_136[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_137 (TF  (None, 16, 16, 32)  0           ['tf.linalg.matmul_41[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_175 (TFOpLambda)    (None, 4, 4, 512)    0           ['tf.compat.v1.transpose_137[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_window_m  (None, 4, 4, 512)   262656      ['tf.reshape_175[0][0]']         \n",
      " hsa/output (Dense)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_176 (TFOpLambda)    (None, 4, 4, 512)    0           ['stack_4_block_2/block_window_mh\n",
      "                                                                 sa/output[0][0]']                \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_attn_out  (None, 4, 4, 512)   0           ['stack_4_block_2/mbconv/output[0\n",
      " put (Add)                                                       ][0]',                           \n",
      "                                                                  'tf.reshape_176[0][0]']         \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_ffn_prea  (None, 4, 4, 512)   1024        ['stack_4_block_2/block_attn_outp\n",
      " ct_ln (LayerNormalization)                                      ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_ffn/1_de  (None, 4, 4, 2048)  1050624     ['stack_4_block_2/block_ffn_preac\n",
      " nse (Dense)                                                     t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu_43 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_4_block_2/block_ffn/1_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_ffn/2_de  (None, 4, 4, 512)   1049088     ['tf.nn.gelu_43[0][0]']          \n",
      " nse (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack_4_block_2/block_ffn_outp  (None, 4, 4, 512)   0           ['stack_4_block_2/block_attn_outp\n",
      " ut (Add)                                                        ut[0][0]',                       \n",
      "                                                                  'stack_4_block_2/block_ffn/2_den\n",
      "                                                                 se[0][0]']                       \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_attn_prea  (None, 4, 4, 512)   1024        ['stack_4_block_2/block_ffn_outpu\n",
      " ct_ln (LayerNormalization)                                      t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_window_mh  (None, 4, 4, 1536)  787968      ['stack_4_block_2/grid_attn_preac\n",
      " sa/qkv_conv (Conv2D)                                            t_ln[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.split_21 (TFOpLambda)       [(None, 4, 4, 512),  0           ['stack_4_block_2/grid_window_mhs\n",
      "                                 (None, 4, 4, 512),              a/qkv_conv[0][0]']               \n",
      "                                 (None, 4, 4, 512)]                                               \n",
      "                                                                                                  \n",
      " tf.reshape_177 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_21[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_178 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_21[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_138 (TF  (None, 16, 16, 32)  0           ['tf.reshape_177[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_139 (TF  (None, 16, 32, 16)  0           ['tf.reshape_178[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_42 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.compat.v1.transpose_138[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_139[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpLambd  (None, 16, 16, 16)  0           ['tf.linalg.matmul_42[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_window_mh  (None, 16, 16, 16)  784         ['tf.math.multiply_21[0][0]']    \n",
      " sa/pos_emb (MultiHeadRelativeP                                                                   \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_179 (TFOpLambda)    (None, 16, 16, 32)   0           ['tf.split_21[0][2]']            \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_window_mh  (None, 16, 16, 16)  0           ['stack_4_block_2/grid_window_mhs\n",
      " sa/attention_scores (Softmax)                                   a/pos_emb[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_140 (TF  (None, 16, 16, 32)  0           ['tf.reshape_179[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_43 (TFOpLambd  (None, 16, 16, 32)  0           ['stack_4_block_2/grid_window_mhs\n",
      " a)                                                              a/attention_scores[0][0]',       \n",
      "                                                                  'tf.compat.v1.transpose_140[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_141 (TF  (None, 16, 16, 32)  0           ['tf.linalg.matmul_43[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_180 (TFOpLambda)    (None, 4, 4, 512)    0           ['tf.compat.v1.transpose_141[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_window_mh  (None, 4, 4, 512)   262656      ['tf.reshape_180[0][0]']         \n",
      " sa/output (Dense)                                                                                \n",
      "                                                                                                  \n",
      " tf.reshape_181 (TFOpLambda)    (None, 4, 4, 512)    0           ['stack_4_block_2/grid_window_mhs\n",
      "                                                                 a/output[0][0]']                 \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_attn_outp  (None, 4, 4, 512)   0           ['stack_4_block_2/block_ffn_outpu\n",
      " ut (Add)                                                        t[0][0]',                        \n",
      "                                                                  'tf.reshape_181[0][0]']         \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_ffn_preac  (None, 4, 4, 512)   1024        ['stack_4_block_2/grid_attn_outpu\n",
      " t_ln (LayerNormalization)                                       t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_ffn/1_den  (None, 4, 4, 2048)  1050624     ['stack_4_block_2/grid_ffn_preact\n",
      " se (Dense)                                                      _ln[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.nn.gelu_44 (TFOpLambda)     (None, 4, 4, 2048)   0           ['stack_4_block_2/grid_ffn/1_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_ffn/2_den  (None, 4, 4, 512)   1049088     ['tf.nn.gelu_44[0][0]']          \n",
      " se (Dense)                                                                                       \n",
      "                                                                                                  \n",
      " stack_4_block_2/grid_ffn_outpu  (None, 4, 4, 512)   0           ['stack_4_block_2/grid_attn_outpu\n",
      " t (Add)                                                         t[0][0]',                        \n",
      "                                                                  'stack_4_block_2/grid_ffn/2_dens\n",
      "                                                                 e[0][0]']                        \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 512)         0           ['stack_4_block_2/grid_ffn_output\n",
      " 2D)                                                             [0][0]']                         \n",
      "                                                                                                  \n",
      " post_ln (LayerNormalization)   (None, 512)          1024        ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " features (Dense)               (None, 512)          262656      ['post_ln[0][0]']                \n",
      "                                                                                                  \n",
      " features_tanh (Activation)     (None, 512)          0           ['features[0][0]']               \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         513000      ['features_tanh[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,943,984\n",
      "Trainable params: 30,896,368\n",
      "Non-trainable params: 47,616\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2174667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:49.815080Z",
     "iopub.status.busy": "2023-07-04T18:21:49.814715Z",
     "iopub.status.idle": "2023-07-04T18:21:55.166694Z",
     "shell.execute_reply": "2023-07-04T18:21:55.165721Z",
     "shell.execute_reply.started": "2023-07-04T18:21:49.815046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/leondgarse/keras_cv_attention_models/releases/download/davit/davit_t_imagenet.h5\n",
      "114235032/114235032 [==============================] - 1s 0us/step\n",
      ">>>> Load pretrained from: /root/.keras/models/davit_t_imagenet.h5\n"
     ]
    }
   ],
   "source": [
    "from keras_cv_attention_models import davit\n",
    "mm2 = davit.DaViT_T(input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed806a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:55.169908Z",
     "iopub.status.busy": "2023-07-04T18:21:55.169575Z",
     "iopub.status.idle": "2023-07-04T18:21:56.181672Z",
     "shell.execute_reply": "2023-07-04T18:21:56.180937Z",
     "shell.execute_reply.started": "2023-07-04T18:21:55.169882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"davit_t\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " stem_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 32, 32, 96)   14208       ['stem_pad[0][0]']               \n",
      "                                                                                                  \n",
      " stem_ln (LayerNormalization)   (None, 32, 32, 96)   192         ['stem_conv[0][0]']              \n",
      "                                                                                                  \n",
      " stack1_block1_pre_attn_cpe_pad  (None, 34, 34, 96)  0           ['stem_ln[0][0]']                \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack1_block1_pre_attn_cpe_dw_  (None, 32, 32, 96)  960         ['stack1_block1_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack1_block1_pre_attn_cpe_out  (None, 32, 32, 96)  0           ['stem_ln[0][0]',                \n",
      " put (Add)                                                        'stack1_block1_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack1_block1_attn_ln (LayerNo  (None, 32, 32, 96)  192         ['stack1_block1_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_182 (TFOpLambda)    (None, 4, 8, 384)    0           ['stack1_block1_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_142 (TF  (None, 8, 4, 384)   0           ['tf.reshape_182[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_183 (TFOpLambda)    (None, 4, 4, 96)     0           ['tf.compat.v1.transpose_142[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.reshape_184 (TFOpLambda)    (None, 16, 96)       0           ['tf.reshape_183[0][0]']         \n",
      "                                                                                                  \n",
      " stack1_block1_attn_qkv (Dense)  (None, 16, 288)     27936       ['tf.reshape_184[0][0]']         \n",
      "                                                                                                  \n",
      " tf.split_22 (TFOpLambda)       [(None, 16, 96),     0           ['stack1_block1_attn_qkv[0][0]'] \n",
      "                                 (None, 16, 96),                                                  \n",
      "                                 (None, 16, 96)]                                                  \n",
      "                                                                                                  \n",
      " tf.reshape_185 (TFOpLambda)    (None, 16, 3, 32)    0           ['tf.split_22[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_186 (TFOpLambda)    (None, 16, 3, 32)    0           ['tf.split_22[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_143 (TF  (None, 3, 16, 32)   0           ['tf.reshape_185[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_144 (TF  (None, 3, 32, 16)   0           ['tf.reshape_186[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_44 (TFOpLambd  (None, 3, 16, 16)   0           ['tf.compat.v1.transpose_143[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_144[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpLambd  (None, 3, 16, 16)   0           ['tf.linalg.matmul_44[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_187 (TFOpLambda)    (None, 16, 3, 32)    0           ['tf.split_22[0][2]']            \n",
      "                                                                                                  \n",
      " stack1_block1_attn_attention_s  (None, 3, 16, 16)   0           ['tf.math.multiply_22[0][0]']    \n",
      " cores (Softmax)                                                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_145 (TF  (None, 3, 16, 32)   0           ['tf.reshape_187[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_45 (TFOpLambd  (None, 3, 16, 32)   0           ['stack1_block1_attn_attention_sc\n",
      " a)                                                              ores[0][0]',                     \n",
      "                                                                  'tf.compat.v1.transpose_145[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_146 (TF  (None, 16, 3, 32)   0           ['tf.linalg.matmul_45[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_188 (TFOpLambda)    (None, 4, 4, 96)     0           ['tf.compat.v1.transpose_146[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack1_block1_attn_output (Den  (None, 4, 4, 96)    9312        ['tf.reshape_188[0][0]']         \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_189 (TFOpLambda)    (None, 8, 4, 384)    0           ['stack1_block1_attn_output[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_147 (TF  (None, 4, 8, 384)   0           ['tf.reshape_189[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_190 (TFOpLambda)    (None, 32, 32, 96)   0           ['tf.compat.v1.transpose_147[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack1_block1_1_output (Add)   (None, 32, 32, 96)   0           ['stack1_block1_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'tf.reshape_190[0][0]']         \n",
      "                                                                                                  \n",
      " stack1_block1_pre_ffn_cpe_pad   (None, 34, 34, 96)  0           ['stack1_block1_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack1_block1_pre_ffn_cpe_dw_c  (None, 32, 32, 96)  960         ['stack1_block1_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack1_block1_pre_ffn_cpe_outp  (None, 32, 32, 96)  0           ['stack1_block1_1_output[0][0]', \n",
      " ut (Add)                                                         'stack1_block1_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack1_block1_mlp_ln (LayerNor  (None, 32, 32, 96)  192         ['stack1_block1_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack1_block1_mlp_Dense_0 (Den  (None, 32, 32, 384)  37248      ['stack1_block1_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack1_block1_mlp_gelu (Activa  (None, 32, 32, 384)  0          ['stack1_block1_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack1_block1_mlp_Dense_1 (Den  (None, 32, 32, 96)  36960       ['stack1_block1_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack1_block1_2_output (Add)   (None, 32, 32, 96)   0           ['stack1_block1_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack1_block1_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack1_block2_pre_attn_cpe_pad  (None, 34, 34, 96)  0           ['stack1_block1_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack1_block2_pre_attn_cpe_dw_  (None, 32, 32, 96)  960         ['stack1_block2_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack1_block2_pre_attn_cpe_out  (None, 32, 32, 96)  0           ['stack1_block1_2_output[0][0]', \n",
      " put (Add)                                                        'stack1_block2_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack1_block2_attn_ln (LayerNo  (None, 32, 32, 96)  192         ['stack1_block2_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_191 (TFOpLambda)    (None, 1024, 96)     0           ['stack1_block2_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " stack1_block2_channel_attn_qkv  (None, 1024, 288)   27936       ['tf.reshape_191[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " tf.split_23 (TFOpLambda)       [(None, 1024, 96),   0           ['stack1_block2_channel_attn_qkv[\n",
      "                                 (None, 1024, 96),               0][0]']                          \n",
      "                                 (None, 1024, 96)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_192 (TFOpLambda)    (None, 1024, 3, 32)  0           ['tf.split_23[0][1]']            \n",
      "                                                                                                  \n",
      " tf.reshape_193 (TFOpLambda)    (None, 1024, 3, 32)  0           ['tf.split_23[0][2]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_148 (TF  (None, 3, 32, 1024)  0          ['tf.reshape_192[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_149 (TF  (None, 3, 1024, 32)  0          ['tf.reshape_193[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_46 (TFOpLambd  (None, 3, 32, 32)   0           ['tf.compat.v1.transpose_148[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_149[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpLambd  (None, 3, 32, 32)   0           ['tf.linalg.matmul_46[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_194 (TFOpLambda)    (None, 1024, 3, 32)  0           ['tf.split_23[0][0]']            \n",
      "                                                                                                  \n",
      " stack1_block2_channel_attn_att  (None, 3, 32, 32)   0           ['tf.math.multiply_23[0][0]']    \n",
      " ention_scores (Softmax)                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_150 (TF  (None, 3, 32, 1024)  0          ['tf.reshape_194[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_47 (TFOpLambd  (None, 3, 32, 1024)  0          ['stack1_block2_channel_attn_atte\n",
      " a)                                                              ntion_scores[0][0]',             \n",
      "                                                                  'tf.compat.v1.transpose_150[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_151 (TF  (None, 1024, 3, 32)  0          ['tf.linalg.matmul_47[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_195 (TFOpLambda)    (None, 32, 32, 96)   0           ['tf.compat.v1.transpose_151[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack1_block2_channel_attn_out  (None, 32, 32, 96)  9312        ['tf.reshape_195[0][0]']         \n",
      " put (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack1_block2_1_output (Add)   (None, 32, 32, 96)   0           ['stack1_block2_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'stack1_block2_channel_attn_outp\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack1_block2_pre_ffn_cpe_pad   (None, 34, 34, 96)  0           ['stack1_block2_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack1_block2_pre_ffn_cpe_dw_c  (None, 32, 32, 96)  960         ['stack1_block2_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack1_block2_pre_ffn_cpe_outp  (None, 32, 32, 96)  0           ['stack1_block2_1_output[0][0]', \n",
      " ut (Add)                                                         'stack1_block2_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack1_block2_mlp_ln (LayerNor  (None, 32, 32, 96)  192         ['stack1_block2_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack1_block2_mlp_Dense_0 (Den  (None, 32, 32, 384)  37248      ['stack1_block2_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack1_block2_mlp_gelu (Activa  (None, 32, 32, 384)  0          ['stack1_block2_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack1_block2_mlp_Dense_1 (Den  (None, 32, 32, 96)  36960       ['stack1_block2_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack1_block2_2_output (Add)   (None, 32, 32, 96)   0           ['stack1_block2_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack1_block2_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack2_downsample_ln (LayerNor  (None, 32, 32, 96)  192         ['stack1_block2_2_output[0][0]'] \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " stack2_downsample_conv (Conv2D  (None, 16, 16, 192)  73920      ['stack2_downsample_ln[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack2_block1_pre_attn_cpe_pad  (None, 18, 18, 192)  0          ['stack2_downsample_conv[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack2_block1_pre_attn_cpe_dw_  (None, 16, 16, 192)  1920       ['stack2_block1_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack2_block1_pre_attn_cpe_out  (None, 16, 16, 192)  0          ['stack2_downsample_conv[0][0]', \n",
      " put (Add)                                                        'stack2_block1_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack2_block1_attn_ln (LayerNo  (None, 16, 16, 192)  384        ['stack2_block1_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_196 (TFOpLambda)    (None, 4, 4, 768)    0           ['stack2_block1_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_152 (TF  (None, 4, 4, 768)   0           ['tf.reshape_196[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_197 (TFOpLambda)    (None, 4, 4, 192)    0           ['tf.compat.v1.transpose_152[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.reshape_198 (TFOpLambda)    (None, 16, 192)      0           ['tf.reshape_197[0][0]']         \n",
      "                                                                                                  \n",
      " stack2_block1_attn_qkv (Dense)  (None, 16, 576)     111168      ['tf.reshape_198[0][0]']         \n",
      "                                                                                                  \n",
      " tf.split_24 (TFOpLambda)       [(None, 16, 192),    0           ['stack2_block1_attn_qkv[0][0]'] \n",
      "                                 (None, 16, 192),                                                 \n",
      "                                 (None, 16, 192)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_199 (TFOpLambda)    (None, 16, 6, 32)    0           ['tf.split_24[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_200 (TFOpLambda)    (None, 16, 6, 32)    0           ['tf.split_24[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_153 (TF  (None, 6, 16, 32)   0           ['tf.reshape_199[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_154 (TF  (None, 6, 32, 16)   0           ['tf.reshape_200[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_48 (TFOpLambd  (None, 6, 16, 16)   0           ['tf.compat.v1.transpose_153[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_154[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpLambd  (None, 6, 16, 16)   0           ['tf.linalg.matmul_48[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_201 (TFOpLambda)    (None, 16, 6, 32)    0           ['tf.split_24[0][2]']            \n",
      "                                                                                                  \n",
      " stack2_block1_attn_attention_s  (None, 6, 16, 16)   0           ['tf.math.multiply_24[0][0]']    \n",
      " cores (Softmax)                                                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_155 (TF  (None, 6, 16, 32)   0           ['tf.reshape_201[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_49 (TFOpLambd  (None, 6, 16, 32)   0           ['stack2_block1_attn_attention_sc\n",
      " a)                                                              ores[0][0]',                     \n",
      "                                                                  'tf.compat.v1.transpose_155[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_156 (TF  (None, 16, 6, 32)   0           ['tf.linalg.matmul_49[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_202 (TFOpLambda)    (None, 4, 4, 192)    0           ['tf.compat.v1.transpose_156[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack2_block1_attn_output (Den  (None, 4, 4, 192)   37056       ['tf.reshape_202[0][0]']         \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_203 (TFOpLambda)    (None, 4, 4, 768)    0           ['stack2_block1_attn_output[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_157 (TF  (None, 4, 4, 768)   0           ['tf.reshape_203[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_204 (TFOpLambda)    (None, 16, 16, 192)  0           ['tf.compat.v1.transpose_157[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack2_block1_1_output (Add)   (None, 16, 16, 192)  0           ['stack2_block1_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'tf.reshape_204[0][0]']         \n",
      "                                                                                                  \n",
      " stack2_block1_pre_ffn_cpe_pad   (None, 18, 18, 192)  0          ['stack2_block1_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack2_block1_pre_ffn_cpe_dw_c  (None, 16, 16, 192)  1920       ['stack2_block1_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack2_block1_pre_ffn_cpe_outp  (None, 16, 16, 192)  0          ['stack2_block1_1_output[0][0]', \n",
      " ut (Add)                                                         'stack2_block1_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack2_block1_mlp_ln (LayerNor  (None, 16, 16, 192)  384        ['stack2_block1_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack2_block1_mlp_Dense_0 (Den  (None, 16, 16, 768)  148224     ['stack2_block1_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack2_block1_mlp_gelu (Activa  (None, 16, 16, 768)  0          ['stack2_block1_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack2_block1_mlp_Dense_1 (Den  (None, 16, 16, 192)  147648     ['stack2_block1_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack2_block1_2_output (Add)   (None, 16, 16, 192)  0           ['stack2_block1_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack2_block1_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack2_block2_pre_attn_cpe_pad  (None, 18, 18, 192)  0          ['stack2_block1_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack2_block2_pre_attn_cpe_dw_  (None, 16, 16, 192)  1920       ['stack2_block2_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack2_block2_pre_attn_cpe_out  (None, 16, 16, 192)  0          ['stack2_block1_2_output[0][0]', \n",
      " put (Add)                                                        'stack2_block2_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack2_block2_attn_ln (LayerNo  (None, 16, 16, 192)  384        ['stack2_block2_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_205 (TFOpLambda)    (None, 256, 192)     0           ['stack2_block2_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " stack2_block2_channel_attn_qkv  (None, 256, 576)    111168      ['tf.reshape_205[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " tf.split_25 (TFOpLambda)       [(None, 256, 192),   0           ['stack2_block2_channel_attn_qkv[\n",
      "                                 (None, 256, 192),               0][0]']                          \n",
      "                                 (None, 256, 192)]                                                \n",
      "                                                                                                  \n",
      " tf.reshape_206 (TFOpLambda)    (None, 256, 6, 32)   0           ['tf.split_25[0][1]']            \n",
      "                                                                                                  \n",
      " tf.reshape_207 (TFOpLambda)    (None, 256, 6, 32)   0           ['tf.split_25[0][2]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_158 (TF  (None, 6, 32, 256)  0           ['tf.reshape_206[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_159 (TF  (None, 6, 256, 32)  0           ['tf.reshape_207[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_50 (TFOpLambd  (None, 6, 32, 32)   0           ['tf.compat.v1.transpose_158[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_159[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpLambd  (None, 6, 32, 32)   0           ['tf.linalg.matmul_50[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_208 (TFOpLambda)    (None, 256, 6, 32)   0           ['tf.split_25[0][0]']            \n",
      "                                                                                                  \n",
      " stack2_block2_channel_attn_att  (None, 6, 32, 32)   0           ['tf.math.multiply_25[0][0]']    \n",
      " ention_scores (Softmax)                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_160 (TF  (None, 6, 32, 256)  0           ['tf.reshape_208[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_51 (TFOpLambd  (None, 6, 32, 256)  0           ['stack2_block2_channel_attn_atte\n",
      " a)                                                              ntion_scores[0][0]',             \n",
      "                                                                  'tf.compat.v1.transpose_160[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_161 (TF  (None, 256, 6, 32)  0           ['tf.linalg.matmul_51[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_209 (TFOpLambda)    (None, 16, 16, 192)  0           ['tf.compat.v1.transpose_161[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack2_block2_channel_attn_out  (None, 16, 16, 192)  37056      ['tf.reshape_209[0][0]']         \n",
      " put (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack2_block2_1_output (Add)   (None, 16, 16, 192)  0           ['stack2_block2_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'stack2_block2_channel_attn_outp\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack2_block2_pre_ffn_cpe_pad   (None, 18, 18, 192)  0          ['stack2_block2_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack2_block2_pre_ffn_cpe_dw_c  (None, 16, 16, 192)  1920       ['stack2_block2_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack2_block2_pre_ffn_cpe_outp  (None, 16, 16, 192)  0          ['stack2_block2_1_output[0][0]', \n",
      " ut (Add)                                                         'stack2_block2_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack2_block2_mlp_ln (LayerNor  (None, 16, 16, 192)  384        ['stack2_block2_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack2_block2_mlp_Dense_0 (Den  (None, 16, 16, 768)  148224     ['stack2_block2_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack2_block2_mlp_gelu (Activa  (None, 16, 16, 768)  0          ['stack2_block2_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack2_block2_mlp_Dense_1 (Den  (None, 16, 16, 192)  147648     ['stack2_block2_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack2_block2_2_output (Add)   (None, 16, 16, 192)  0           ['stack2_block2_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack2_block2_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack3_downsample_ln (LayerNor  (None, 16, 16, 192)  384        ['stack2_block2_2_output[0][0]'] \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " stack3_downsample_conv (Conv2D  (None, 8, 8, 384)   295296      ['stack3_downsample_ln[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack3_block1_pre_attn_cpe_pad  (None, 10, 10, 384)  0          ['stack3_downsample_conv[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack3_block1_pre_attn_cpe_dw_  (None, 8, 8, 384)   3840        ['stack3_block1_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack3_block1_pre_attn_cpe_out  (None, 8, 8, 384)   0           ['stack3_downsample_conv[0][0]', \n",
      " put (Add)                                                        'stack3_block1_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack3_block1_attn_ln (LayerNo  (None, 8, 8, 384)   768         ['stack3_block1_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_210 (TFOpLambda)    (None, 4, 2, 1536)   0           ['stack3_block1_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_162 (TF  (None, 2, 4, 1536)  0           ['tf.reshape_210[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_211 (TFOpLambda)    (None, 4, 4, 384)    0           ['tf.compat.v1.transpose_162[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.reshape_212 (TFOpLambda)    (None, 16, 384)      0           ['tf.reshape_211[0][0]']         \n",
      "                                                                                                  \n",
      " stack3_block1_attn_qkv (Dense)  (None, 16, 1152)    443520      ['tf.reshape_212[0][0]']         \n",
      "                                                                                                  \n",
      " tf.split_26 (TFOpLambda)       [(None, 16, 384),    0           ['stack3_block1_attn_qkv[0][0]'] \n",
      "                                 (None, 16, 384),                                                 \n",
      "                                 (None, 16, 384)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_213 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_26[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_214 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_26[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_163 (TF  (None, 12, 16, 32)  0           ['tf.reshape_213[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_164 (TF  (None, 12, 32, 16)  0           ['tf.reshape_214[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_52 (TFOpLambd  (None, 12, 16, 16)  0           ['tf.compat.v1.transpose_163[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_164[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpLambd  (None, 12, 16, 16)  0           ['tf.linalg.matmul_52[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_215 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_26[0][2]']            \n",
      "                                                                                                  \n",
      " stack3_block1_attn_attention_s  (None, 12, 16, 16)  0           ['tf.math.multiply_26[0][0]']    \n",
      " cores (Softmax)                                                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_165 (TF  (None, 12, 16, 32)  0           ['tf.reshape_215[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_53 (TFOpLambd  (None, 12, 16, 32)  0           ['stack3_block1_attn_attention_sc\n",
      " a)                                                              ores[0][0]',                     \n",
      "                                                                  'tf.compat.v1.transpose_165[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_166 (TF  (None, 16, 12, 32)  0           ['tf.linalg.matmul_53[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_216 (TFOpLambda)    (None, 4, 4, 384)    0           ['tf.compat.v1.transpose_166[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block1_attn_output (Den  (None, 4, 4, 384)   147840      ['tf.reshape_216[0][0]']         \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_217 (TFOpLambda)    (None, 2, 4, 1536)   0           ['stack3_block1_attn_output[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_167 (TF  (None, 4, 2, 1536)  0           ['tf.reshape_217[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_218 (TFOpLambda)    (None, 8, 8, 384)    0           ['tf.compat.v1.transpose_167[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block1_1_output (Add)   (None, 8, 8, 384)    0           ['stack3_block1_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'tf.reshape_218[0][0]']         \n",
      "                                                                                                  \n",
      " stack3_block1_pre_ffn_cpe_pad   (None, 10, 10, 384)  0          ['stack3_block1_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack3_block1_pre_ffn_cpe_dw_c  (None, 8, 8, 384)   3840        ['stack3_block1_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack3_block1_pre_ffn_cpe_outp  (None, 8, 8, 384)   0           ['stack3_block1_1_output[0][0]', \n",
      " ut (Add)                                                         'stack3_block1_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block1_mlp_ln (LayerNor  (None, 8, 8, 384)   768         ['stack3_block1_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack3_block1_mlp_Dense_0 (Den  (None, 8, 8, 1536)  591360      ['stack3_block1_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block1_mlp_gelu (Activa  (None, 8, 8, 1536)  0           ['stack3_block1_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack3_block1_mlp_Dense_1 (Den  (None, 8, 8, 384)   590208      ['stack3_block1_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block1_2_output (Add)   (None, 8, 8, 384)    0           ['stack3_block1_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack3_block1_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack3_block2_pre_attn_cpe_pad  (None, 10, 10, 384)  0          ['stack3_block1_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack3_block2_pre_attn_cpe_dw_  (None, 8, 8, 384)   3840        ['stack3_block2_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack3_block2_pre_attn_cpe_out  (None, 8, 8, 384)   0           ['stack3_block1_2_output[0][0]', \n",
      " put (Add)                                                        'stack3_block2_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack3_block2_attn_ln (LayerNo  (None, 8, 8, 384)   768         ['stack3_block2_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_219 (TFOpLambda)    (None, 64, 384)      0           ['stack3_block2_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " stack3_block2_channel_attn_qkv  (None, 64, 1152)    443520      ['tf.reshape_219[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " tf.split_27 (TFOpLambda)       [(None, 64, 384),    0           ['stack3_block2_channel_attn_qkv[\n",
      "                                 (None, 64, 384),                0][0]']                          \n",
      "                                 (None, 64, 384)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_220 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_27[0][1]']            \n",
      "                                                                                                  \n",
      " tf.reshape_221 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_27[0][2]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_168 (TF  (None, 12, 32, 64)  0           ['tf.reshape_220[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_169 (TF  (None, 12, 64, 32)  0           ['tf.reshape_221[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_54 (TFOpLambd  (None, 12, 32, 32)  0           ['tf.compat.v1.transpose_168[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_169[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_27 (TFOpLambd  (None, 12, 32, 32)  0           ['tf.linalg.matmul_54[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_222 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_27[0][0]']            \n",
      "                                                                                                  \n",
      " stack3_block2_channel_attn_att  (None, 12, 32, 32)  0           ['tf.math.multiply_27[0][0]']    \n",
      " ention_scores (Softmax)                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_170 (TF  (None, 12, 32, 64)  0           ['tf.reshape_222[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_55 (TFOpLambd  (None, 12, 32, 64)  0           ['stack3_block2_channel_attn_atte\n",
      " a)                                                              ntion_scores[0][0]',             \n",
      "                                                                  'tf.compat.v1.transpose_170[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_171 (TF  (None, 64, 12, 32)  0           ['tf.linalg.matmul_55[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_223 (TFOpLambda)    (None, 8, 8, 384)    0           ['tf.compat.v1.transpose_171[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block2_channel_attn_out  (None, 8, 8, 384)   147840      ['tf.reshape_223[0][0]']         \n",
      " put (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack3_block2_1_output (Add)   (None, 8, 8, 384)    0           ['stack3_block2_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'stack3_block2_channel_attn_outp\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block2_pre_ffn_cpe_pad   (None, 10, 10, 384)  0          ['stack3_block2_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack3_block2_pre_ffn_cpe_dw_c  (None, 8, 8, 384)   3840        ['stack3_block2_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack3_block2_pre_ffn_cpe_outp  (None, 8, 8, 384)   0           ['stack3_block2_1_output[0][0]', \n",
      " ut (Add)                                                         'stack3_block2_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block2_mlp_ln (LayerNor  (None, 8, 8, 384)   768         ['stack3_block2_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack3_block2_mlp_Dense_0 (Den  (None, 8, 8, 1536)  591360      ['stack3_block2_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block2_mlp_gelu (Activa  (None, 8, 8, 1536)  0           ['stack3_block2_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack3_block2_mlp_Dense_1 (Den  (None, 8, 8, 384)   590208      ['stack3_block2_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block2_2_output (Add)   (None, 8, 8, 384)    0           ['stack3_block2_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack3_block2_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack3_block3_pre_attn_cpe_pad  (None, 10, 10, 384)  0          ['stack3_block2_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack3_block3_pre_attn_cpe_dw_  (None, 8, 8, 384)   3840        ['stack3_block3_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack3_block3_pre_attn_cpe_out  (None, 8, 8, 384)   0           ['stack3_block2_2_output[0][0]', \n",
      " put (Add)                                                        'stack3_block3_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack3_block3_attn_ln (LayerNo  (None, 8, 8, 384)   768         ['stack3_block3_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_224 (TFOpLambda)    (None, 4, 2, 1536)   0           ['stack3_block3_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_172 (TF  (None, 2, 4, 1536)  0           ['tf.reshape_224[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_225 (TFOpLambda)    (None, 4, 4, 384)    0           ['tf.compat.v1.transpose_172[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.reshape_226 (TFOpLambda)    (None, 16, 384)      0           ['tf.reshape_225[0][0]']         \n",
      "                                                                                                  \n",
      " stack3_block3_attn_qkv (Dense)  (None, 16, 1152)    443520      ['tf.reshape_226[0][0]']         \n",
      "                                                                                                  \n",
      " tf.split_28 (TFOpLambda)       [(None, 16, 384),    0           ['stack3_block3_attn_qkv[0][0]'] \n",
      "                                 (None, 16, 384),                                                 \n",
      "                                 (None, 16, 384)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_227 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_28[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_228 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_28[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_173 (TF  (None, 12, 16, 32)  0           ['tf.reshape_227[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_174 (TF  (None, 12, 32, 16)  0           ['tf.reshape_228[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_56 (TFOpLambd  (None, 12, 16, 16)  0           ['tf.compat.v1.transpose_173[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_174[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_28 (TFOpLambd  (None, 12, 16, 16)  0           ['tf.linalg.matmul_56[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_229 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_28[0][2]']            \n",
      "                                                                                                  \n",
      " stack3_block3_attn_attention_s  (None, 12, 16, 16)  0           ['tf.math.multiply_28[0][0]']    \n",
      " cores (Softmax)                                                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_175 (TF  (None, 12, 16, 32)  0           ['tf.reshape_229[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_57 (TFOpLambd  (None, 12, 16, 32)  0           ['stack3_block3_attn_attention_sc\n",
      " a)                                                              ores[0][0]',                     \n",
      "                                                                  'tf.compat.v1.transpose_175[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_176 (TF  (None, 16, 12, 32)  0           ['tf.linalg.matmul_57[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_230 (TFOpLambda)    (None, 4, 4, 384)    0           ['tf.compat.v1.transpose_176[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block3_attn_output (Den  (None, 4, 4, 384)   147840      ['tf.reshape_230[0][0]']         \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_231 (TFOpLambda)    (None, 2, 4, 1536)   0           ['stack3_block3_attn_output[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_177 (TF  (None, 4, 2, 1536)  0           ['tf.reshape_231[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_232 (TFOpLambda)    (None, 8, 8, 384)    0           ['tf.compat.v1.transpose_177[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block3_1_output (Add)   (None, 8, 8, 384)    0           ['stack3_block3_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'tf.reshape_232[0][0]']         \n",
      "                                                                                                  \n",
      " stack3_block3_pre_ffn_cpe_pad   (None, 10, 10, 384)  0          ['stack3_block3_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack3_block3_pre_ffn_cpe_dw_c  (None, 8, 8, 384)   3840        ['stack3_block3_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack3_block3_pre_ffn_cpe_outp  (None, 8, 8, 384)   0           ['stack3_block3_1_output[0][0]', \n",
      " ut (Add)                                                         'stack3_block3_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block3_mlp_ln (LayerNor  (None, 8, 8, 384)   768         ['stack3_block3_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack3_block3_mlp_Dense_0 (Den  (None, 8, 8, 1536)  591360      ['stack3_block3_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block3_mlp_gelu (Activa  (None, 8, 8, 1536)  0           ['stack3_block3_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack3_block3_mlp_Dense_1 (Den  (None, 8, 8, 384)   590208      ['stack3_block3_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block3_2_output (Add)   (None, 8, 8, 384)    0           ['stack3_block3_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack3_block3_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack3_block4_pre_attn_cpe_pad  (None, 10, 10, 384)  0          ['stack3_block3_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack3_block4_pre_attn_cpe_dw_  (None, 8, 8, 384)   3840        ['stack3_block4_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack3_block4_pre_attn_cpe_out  (None, 8, 8, 384)   0           ['stack3_block3_2_output[0][0]', \n",
      " put (Add)                                                        'stack3_block4_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack3_block4_attn_ln (LayerNo  (None, 8, 8, 384)   768         ['stack3_block4_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_233 (TFOpLambda)    (None, 64, 384)      0           ['stack3_block4_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " stack3_block4_channel_attn_qkv  (None, 64, 1152)    443520      ['tf.reshape_233[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " tf.split_29 (TFOpLambda)       [(None, 64, 384),    0           ['stack3_block4_channel_attn_qkv[\n",
      "                                 (None, 64, 384),                0][0]']                          \n",
      "                                 (None, 64, 384)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_234 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_29[0][1]']            \n",
      "                                                                                                  \n",
      " tf.reshape_235 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_29[0][2]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_178 (TF  (None, 12, 32, 64)  0           ['tf.reshape_234[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_179 (TF  (None, 12, 64, 32)  0           ['tf.reshape_235[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_58 (TFOpLambd  (None, 12, 32, 32)  0           ['tf.compat.v1.transpose_178[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_179[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_29 (TFOpLambd  (None, 12, 32, 32)  0           ['tf.linalg.matmul_58[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_236 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_29[0][0]']            \n",
      "                                                                                                  \n",
      " stack3_block4_channel_attn_att  (None, 12, 32, 32)  0           ['tf.math.multiply_29[0][0]']    \n",
      " ention_scores (Softmax)                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_180 (TF  (None, 12, 32, 64)  0           ['tf.reshape_236[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_59 (TFOpLambd  (None, 12, 32, 64)  0           ['stack3_block4_channel_attn_atte\n",
      " a)                                                              ntion_scores[0][0]',             \n",
      "                                                                  'tf.compat.v1.transpose_180[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_181 (TF  (None, 64, 12, 32)  0           ['tf.linalg.matmul_59[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_237 (TFOpLambda)    (None, 8, 8, 384)    0           ['tf.compat.v1.transpose_181[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block4_channel_attn_out  (None, 8, 8, 384)   147840      ['tf.reshape_237[0][0]']         \n",
      " put (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack3_block4_1_output (Add)   (None, 8, 8, 384)    0           ['stack3_block4_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'stack3_block4_channel_attn_outp\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block4_pre_ffn_cpe_pad   (None, 10, 10, 384)  0          ['stack3_block4_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack3_block4_pre_ffn_cpe_dw_c  (None, 8, 8, 384)   3840        ['stack3_block4_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack3_block4_pre_ffn_cpe_outp  (None, 8, 8, 384)   0           ['stack3_block4_1_output[0][0]', \n",
      " ut (Add)                                                         'stack3_block4_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block4_mlp_ln (LayerNor  (None, 8, 8, 384)   768         ['stack3_block4_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack3_block4_mlp_Dense_0 (Den  (None, 8, 8, 1536)  591360      ['stack3_block4_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block4_mlp_gelu (Activa  (None, 8, 8, 1536)  0           ['stack3_block4_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack3_block4_mlp_Dense_1 (Den  (None, 8, 8, 384)   590208      ['stack3_block4_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block4_2_output (Add)   (None, 8, 8, 384)    0           ['stack3_block4_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack3_block4_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack3_block5_pre_attn_cpe_pad  (None, 10, 10, 384)  0          ['stack3_block4_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack3_block5_pre_attn_cpe_dw_  (None, 8, 8, 384)   3840        ['stack3_block5_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack3_block5_pre_attn_cpe_out  (None, 8, 8, 384)   0           ['stack3_block4_2_output[0][0]', \n",
      " put (Add)                                                        'stack3_block5_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack3_block5_attn_ln (LayerNo  (None, 8, 8, 384)   768         ['stack3_block5_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_238 (TFOpLambda)    (None, 4, 2, 1536)   0           ['stack3_block5_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_182 (TF  (None, 2, 4, 1536)  0           ['tf.reshape_238[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_239 (TFOpLambda)    (None, 4, 4, 384)    0           ['tf.compat.v1.transpose_182[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.reshape_240 (TFOpLambda)    (None, 16, 384)      0           ['tf.reshape_239[0][0]']         \n",
      "                                                                                                  \n",
      " stack3_block5_attn_qkv (Dense)  (None, 16, 1152)    443520      ['tf.reshape_240[0][0]']         \n",
      "                                                                                                  \n",
      " tf.split_30 (TFOpLambda)       [(None, 16, 384),    0           ['stack3_block5_attn_qkv[0][0]'] \n",
      "                                 (None, 16, 384),                                                 \n",
      "                                 (None, 16, 384)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_241 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_30[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_242 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_30[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_183 (TF  (None, 12, 16, 32)  0           ['tf.reshape_241[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_184 (TF  (None, 12, 32, 16)  0           ['tf.reshape_242[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_60 (TFOpLambd  (None, 12, 16, 16)  0           ['tf.compat.v1.transpose_183[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_184[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_30 (TFOpLambd  (None, 12, 16, 16)  0           ['tf.linalg.matmul_60[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_243 (TFOpLambda)    (None, 16, 12, 32)   0           ['tf.split_30[0][2]']            \n",
      "                                                                                                  \n",
      " stack3_block5_attn_attention_s  (None, 12, 16, 16)  0           ['tf.math.multiply_30[0][0]']    \n",
      " cores (Softmax)                                                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_185 (TF  (None, 12, 16, 32)  0           ['tf.reshape_243[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_61 (TFOpLambd  (None, 12, 16, 32)  0           ['stack3_block5_attn_attention_sc\n",
      " a)                                                              ores[0][0]',                     \n",
      "                                                                  'tf.compat.v1.transpose_185[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_186 (TF  (None, 16, 12, 32)  0           ['tf.linalg.matmul_61[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_244 (TFOpLambda)    (None, 4, 4, 384)    0           ['tf.compat.v1.transpose_186[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block5_attn_output (Den  (None, 4, 4, 384)   147840      ['tf.reshape_244[0][0]']         \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_245 (TFOpLambda)    (None, 2, 4, 1536)   0           ['stack3_block5_attn_output[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_187 (TF  (None, 4, 2, 1536)  0           ['tf.reshape_245[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_246 (TFOpLambda)    (None, 8, 8, 384)    0           ['tf.compat.v1.transpose_187[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block5_1_output (Add)   (None, 8, 8, 384)    0           ['stack3_block5_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'tf.reshape_246[0][0]']         \n",
      "                                                                                                  \n",
      " stack3_block5_pre_ffn_cpe_pad   (None, 10, 10, 384)  0          ['stack3_block5_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack3_block5_pre_ffn_cpe_dw_c  (None, 8, 8, 384)   3840        ['stack3_block5_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack3_block5_pre_ffn_cpe_outp  (None, 8, 8, 384)   0           ['stack3_block5_1_output[0][0]', \n",
      " ut (Add)                                                         'stack3_block5_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block5_mlp_ln (LayerNor  (None, 8, 8, 384)   768         ['stack3_block5_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack3_block5_mlp_Dense_0 (Den  (None, 8, 8, 1536)  591360      ['stack3_block5_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block5_mlp_gelu (Activa  (None, 8, 8, 1536)  0           ['stack3_block5_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack3_block5_mlp_Dense_1 (Den  (None, 8, 8, 384)   590208      ['stack3_block5_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block5_2_output (Add)   (None, 8, 8, 384)    0           ['stack3_block5_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack3_block5_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack3_block6_pre_attn_cpe_pad  (None, 10, 10, 384)  0          ['stack3_block5_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack3_block6_pre_attn_cpe_dw_  (None, 8, 8, 384)   3840        ['stack3_block6_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack3_block6_pre_attn_cpe_out  (None, 8, 8, 384)   0           ['stack3_block5_2_output[0][0]', \n",
      " put (Add)                                                        'stack3_block6_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack3_block6_attn_ln (LayerNo  (None, 8, 8, 384)   768         ['stack3_block6_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_247 (TFOpLambda)    (None, 64, 384)      0           ['stack3_block6_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " stack3_block6_channel_attn_qkv  (None, 64, 1152)    443520      ['tf.reshape_247[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " tf.split_31 (TFOpLambda)       [(None, 64, 384),    0           ['stack3_block6_channel_attn_qkv[\n",
      "                                 (None, 64, 384),                0][0]']                          \n",
      "                                 (None, 64, 384)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_248 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_31[0][1]']            \n",
      "                                                                                                  \n",
      " tf.reshape_249 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_31[0][2]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_188 (TF  (None, 12, 32, 64)  0           ['tf.reshape_248[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_189 (TF  (None, 12, 64, 32)  0           ['tf.reshape_249[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_62 (TFOpLambd  (None, 12, 32, 32)  0           ['tf.compat.v1.transpose_188[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_189[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_31 (TFOpLambd  (None, 12, 32, 32)  0           ['tf.linalg.matmul_62[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_250 (TFOpLambda)    (None, 64, 12, 32)   0           ['tf.split_31[0][0]']            \n",
      "                                                                                                  \n",
      " stack3_block6_channel_attn_att  (None, 12, 32, 32)  0           ['tf.math.multiply_31[0][0]']    \n",
      " ention_scores (Softmax)                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_190 (TF  (None, 12, 32, 64)  0           ['tf.reshape_250[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_63 (TFOpLambd  (None, 12, 32, 64)  0           ['stack3_block6_channel_attn_atte\n",
      " a)                                                              ntion_scores[0][0]',             \n",
      "                                                                  'tf.compat.v1.transpose_190[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_191 (TF  (None, 64, 12, 32)  0           ['tf.linalg.matmul_63[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_251 (TFOpLambda)    (None, 8, 8, 384)    0           ['tf.compat.v1.transpose_191[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack3_block6_channel_attn_out  (None, 8, 8, 384)   147840      ['tf.reshape_251[0][0]']         \n",
      " put (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack3_block6_1_output (Add)   (None, 8, 8, 384)    0           ['stack3_block6_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'stack3_block6_channel_attn_outp\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block6_pre_ffn_cpe_pad   (None, 10, 10, 384)  0          ['stack3_block6_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack3_block6_pre_ffn_cpe_dw_c  (None, 8, 8, 384)   3840        ['stack3_block6_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack3_block6_pre_ffn_cpe_outp  (None, 8, 8, 384)   0           ['stack3_block6_1_output[0][0]', \n",
      " ut (Add)                                                         'stack3_block6_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack3_block6_mlp_ln (LayerNor  (None, 8, 8, 384)   768         ['stack3_block6_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack3_block6_mlp_Dense_0 (Den  (None, 8, 8, 1536)  591360      ['stack3_block6_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block6_mlp_gelu (Activa  (None, 8, 8, 1536)  0           ['stack3_block6_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack3_block6_mlp_Dense_1 (Den  (None, 8, 8, 384)   590208      ['stack3_block6_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack3_block6_2_output (Add)   (None, 8, 8, 384)    0           ['stack3_block6_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack3_block6_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack4_downsample_ln (LayerNor  (None, 8, 8, 384)   768         ['stack3_block6_2_output[0][0]'] \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " stack4_downsample_conv (Conv2D  (None, 4, 4, 768)   1180416     ['stack4_downsample_ln[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stack4_block1_pre_attn_cpe_pad  (None, 6, 6, 768)   0           ['stack4_downsample_conv[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack4_block1_pre_attn_cpe_dw_  (None, 4, 4, 768)   7680        ['stack4_block1_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack4_block1_pre_attn_cpe_out  (None, 4, 4, 768)   0           ['stack4_downsample_conv[0][0]', \n",
      " put (Add)                                                        'stack4_block1_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack4_block1_attn_ln (LayerNo  (None, 4, 4, 768)   1536        ['stack4_block1_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_252 (TFOpLambda)    (None, 16, 768)      0           ['stack4_block1_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " stack4_block1_attn_qkv (Dense)  (None, 16, 2304)    1771776     ['tf.reshape_252[0][0]']         \n",
      "                                                                                                  \n",
      " tf.split_32 (TFOpLambda)       [(None, 16, 768),    0           ['stack4_block1_attn_qkv[0][0]'] \n",
      "                                 (None, 16, 768),                                                 \n",
      "                                 (None, 16, 768)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_253 (TFOpLambda)    (None, 16, 24, 32)   0           ['tf.split_32[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_254 (TFOpLambda)    (None, 16, 24, 32)   0           ['tf.split_32[0][1]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_192 (TF  (None, 24, 16, 32)  0           ['tf.reshape_253[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_193 (TF  (None, 24, 32, 16)  0           ['tf.reshape_254[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_64 (TFOpLambd  (None, 24, 16, 16)  0           ['tf.compat.v1.transpose_192[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_193[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_32 (TFOpLambd  (None, 24, 16, 16)  0           ['tf.linalg.matmul_64[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_255 (TFOpLambda)    (None, 16, 24, 32)   0           ['tf.split_32[0][2]']            \n",
      "                                                                                                  \n",
      " stack4_block1_attn_attention_s  (None, 24, 16, 16)  0           ['tf.math.multiply_32[0][0]']    \n",
      " cores (Softmax)                                                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_194 (TF  (None, 24, 16, 32)  0           ['tf.reshape_255[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_65 (TFOpLambd  (None, 24, 16, 32)  0           ['stack4_block1_attn_attention_sc\n",
      " a)                                                              ores[0][0]',                     \n",
      "                                                                  'tf.compat.v1.transpose_194[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_195 (TF  (None, 16, 24, 32)  0           ['tf.linalg.matmul_65[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_256 (TFOpLambda)    (None, 4, 4, 768)    0           ['tf.compat.v1.transpose_195[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack4_block1_attn_output (Den  (None, 4, 4, 768)   590592      ['tf.reshape_256[0][0]']         \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " tf.reshape_257 (TFOpLambda)    (None, 4, 4, 768)    0           ['stack4_block1_attn_output[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack4_block1_1_output (Add)   (None, 4, 4, 768)    0           ['stack4_block1_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'tf.reshape_257[0][0]']         \n",
      "                                                                                                  \n",
      " stack4_block1_pre_ffn_cpe_pad   (None, 6, 6, 768)   0           ['stack4_block1_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack4_block1_pre_ffn_cpe_dw_c  (None, 4, 4, 768)   7680        ['stack4_block1_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack4_block1_pre_ffn_cpe_outp  (None, 4, 4, 768)   0           ['stack4_block1_1_output[0][0]', \n",
      " ut (Add)                                                         'stack4_block1_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack4_block1_mlp_ln (LayerNor  (None, 4, 4, 768)   1536        ['stack4_block1_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack4_block1_mlp_Dense_0 (Den  (None, 4, 4, 3072)  2362368     ['stack4_block1_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack4_block1_mlp_gelu (Activa  (None, 4, 4, 3072)  0           ['stack4_block1_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack4_block1_mlp_Dense_1 (Den  (None, 4, 4, 768)   2360064     ['stack4_block1_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack4_block1_2_output (Add)   (None, 4, 4, 768)    0           ['stack4_block1_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack4_block1_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " stack4_block2_pre_attn_cpe_pad  (None, 6, 6, 768)   0           ['stack4_block1_2_output[0][0]'] \n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " stack4_block2_pre_attn_cpe_dw_  (None, 4, 4, 768)   7680        ['stack4_block2_pre_attn_cpe_pad[\n",
      " conv (DepthwiseConv2D)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " stack4_block2_pre_attn_cpe_out  (None, 4, 4, 768)   0           ['stack4_block1_2_output[0][0]', \n",
      " put (Add)                                                        'stack4_block2_pre_attn_cpe_dw_c\n",
      "                                                                 onv[0][0]']                      \n",
      "                                                                                                  \n",
      " stack4_block2_attn_ln (LayerNo  (None, 4, 4, 768)   1536        ['stack4_block2_pre_attn_cpe_outp\n",
      " rmalization)                                                    ut[0][0]']                       \n",
      "                                                                                                  \n",
      " tf.reshape_258 (TFOpLambda)    (None, 16, 768)      0           ['stack4_block2_attn_ln[0][0]']  \n",
      "                                                                                                  \n",
      " stack4_block2_channel_attn_qkv  (None, 16, 2304)    1771776     ['tf.reshape_258[0][0]']         \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " tf.split_33 (TFOpLambda)       [(None, 16, 768),    0           ['stack4_block2_channel_attn_qkv[\n",
      "                                 (None, 16, 768),                0][0]']                          \n",
      "                                 (None, 16, 768)]                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_259 (TFOpLambda)    (None, 16, 24, 32)   0           ['tf.split_33[0][1]']            \n",
      "                                                                                                  \n",
      " tf.reshape_260 (TFOpLambda)    (None, 16, 24, 32)   0           ['tf.split_33[0][2]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_196 (TF  (None, 24, 32, 16)  0           ['tf.reshape_259[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_197 (TF  (None, 24, 16, 32)  0           ['tf.reshape_260[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_66 (TFOpLambd  (None, 24, 32, 32)  0           ['tf.compat.v1.transpose_196[0][0\n",
      " a)                                                              ]',                              \n",
      "                                                                  'tf.compat.v1.transpose_197[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_33 (TFOpLambd  (None, 24, 32, 32)  0           ['tf.linalg.matmul_66[0][0]']    \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_261 (TFOpLambda)    (None, 16, 24, 32)   0           ['tf.split_33[0][0]']            \n",
      "                                                                                                  \n",
      " stack4_block2_channel_attn_att  (None, 24, 32, 32)  0           ['tf.math.multiply_33[0][0]']    \n",
      " ention_scores (Softmax)                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_198 (TF  (None, 24, 32, 16)  0           ['tf.reshape_261[0][0]']         \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_67 (TFOpLambd  (None, 24, 32, 16)  0           ['stack4_block2_channel_attn_atte\n",
      " a)                                                              ntion_scores[0][0]',             \n",
      "                                                                  'tf.compat.v1.transpose_198[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_199 (TF  (None, 16, 24, 32)  0           ['tf.linalg.matmul_67[0][0]']    \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_262 (TFOpLambda)    (None, 4, 4, 768)    0           ['tf.compat.v1.transpose_199[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " stack4_block2_channel_attn_out  (None, 4, 4, 768)   590592      ['tf.reshape_262[0][0]']         \n",
      " put (Dense)                                                                                      \n",
      "                                                                                                  \n",
      " stack4_block2_1_output (Add)   (None, 4, 4, 768)    0           ['stack4_block2_pre_attn_cpe_outp\n",
      "                                                                 ut[0][0]',                       \n",
      "                                                                  'stack4_block2_channel_attn_outp\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " stack4_block2_pre_ffn_cpe_pad   (None, 6, 6, 768)   0           ['stack4_block2_1_output[0][0]'] \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " stack4_block2_pre_ffn_cpe_dw_c  (None, 4, 4, 768)   7680        ['stack4_block2_pre_ffn_cpe_pad[0\n",
      " onv (DepthwiseConv2D)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " stack4_block2_pre_ffn_cpe_outp  (None, 4, 4, 768)   0           ['stack4_block2_1_output[0][0]', \n",
      " ut (Add)                                                         'stack4_block2_pre_ffn_cpe_dw_co\n",
      "                                                                 nv[0][0]']                       \n",
      "                                                                                                  \n",
      " stack4_block2_mlp_ln (LayerNor  (None, 4, 4, 768)   1536        ['stack4_block2_pre_ffn_cpe_outpu\n",
      " malization)                                                     t[0][0]']                        \n",
      "                                                                                                  \n",
      " stack4_block2_mlp_Dense_0 (Den  (None, 4, 4, 3072)  2362368     ['stack4_block2_mlp_ln[0][0]']   \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack4_block2_mlp_gelu (Activa  (None, 4, 4, 3072)  0           ['stack4_block2_mlp_Dense_0[0][0]\n",
      " tion)                                                           ']                               \n",
      "                                                                                                  \n",
      " stack4_block2_mlp_Dense_1 (Den  (None, 4, 4, 768)   2360064     ['stack4_block2_mlp_gelu[0][0]'] \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " stack4_block2_2_output (Add)   (None, 4, 4, 768)    0           ['stack4_block2_pre_ffn_cpe_outpu\n",
      "                                                                 t[0][0]',                        \n",
      "                                                                  'stack4_block2_mlp_Dense_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " pre_output_ln (LayerNormalizat  (None, 4, 4, 768)   1536        ['stack4_block2_2_output[0][0]'] \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 768)         0           ['pre_output_ln[0][0]']          \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         769000      ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,360,168\n",
      "Trainable params: 28,360,168\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050ca45f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:56.183015Z",
     "iopub.status.busy": "2023-07-04T18:21:56.182696Z",
     "iopub.status.idle": "2023-07-04T18:21:56.186995Z",
     "shell.execute_reply": "2023-07-04T18:21:56.186315Z",
     "shell.execute_reply.started": "2023-07-04T18:21:56.182984Z"
    }
   },
   "outputs": [],
   "source": [
    "# from keras_cv_attention_models import swin_transformer_v2\n",
    "# mm2 = swin_transformer_v2.SwinTransformerV2Tiny_ns(input_shape=(image_size, image_size, 3), pretrained=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18aef055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:56.192624Z",
     "iopub.status.busy": "2023-07-04T18:21:56.192263Z",
     "iopub.status.idle": "2023-07-04T18:21:56.287208Z",
     "shell.execute_reply": "2023-07-04T18:21:56.286410Z",
     "shell.execute_reply.started": "2023-07-04T18:21:56.192593Z"
    }
   },
   "outputs": [],
   "source": [
    "mm_last_layer = mm.get_layer('stack_2_block_2/block_ffn_output').output\n",
    "# out = Dense(256, activation='relu', name='dense_1')(mm_last_layer)\n",
    "mm_last_layer = GlobalAveragePooling2D()(mm_last_layer)\n",
    "mm_custom = Model(mm.input, mm_last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4717f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:56.288484Z",
     "iopub.status.busy": "2023-07-04T18:21:56.288174Z",
     "iopub.status.idle": "2023-07-04T18:21:56.372202Z",
     "shell.execute_reply": "2023-07-04T18:21:56.371448Z",
     "shell.execute_reply.started": "2023-07-04T18:21:56.288446Z"
    }
   },
   "outputs": [],
   "source": [
    "mm2_last_layer = mm2.get_layer('stack2_block2_2_output').output\n",
    "# out2 = Dense(256, activation='relu', name='dense_1')(mm2_last_layer)\n",
    "mm2_last_layer = GlobalAveragePooling2D()(mm2_last_layer)\n",
    "mm2_last_layer = Dense(128, activation='softmax', name='prediction1')(mm2_last_layer)\n",
    "mm2_custom = Model(mm2.input, mm2_last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752a3f45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:56.373507Z",
     "iopub.status.busy": "2023-07-04T18:21:56.373174Z",
     "iopub.status.idle": "2023-07-04T18:21:58.308822Z",
     "shell.execute_reply": "2023-07-04T18:21:58.307891Z",
     "shell.execute_reply.started": "2023-07-04T18:21:56.373465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          1249268     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 128)          1238144     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " average (Average)              (None, 128)          0           ['model[0][0]',                  \n",
      "                                                                  'model_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,487,412\n",
      "Trainable params: 2,480,500\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(image_size, image_size, 3))\n",
    "outputs = layers.average([mm_custom(inputs), mm2_custom(inputs)])\n",
    "avg_ensemble_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "avg_ensemble_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "537c189e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:58.310782Z",
     "iopub.status.busy": "2023-07-04T18:21:58.310402Z",
     "iopub.status.idle": "2023-07-04T18:21:58.373901Z",
     "shell.execute_reply": "2023-07-04T18:21:58.372932Z",
     "shell.execute_reply.started": "2023-07-04T18:21:58.310748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          1249268     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 128)          1238144     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " average (Average)              (None, 128)          0           ['model[0][0]',                  \n",
      "                                                                  'model_1[0][0]']                \n",
      "                                                                                                  \n",
      " output_1 (Dense)               (None, 2)            258         ['average[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,487,670\n",
      "Trainable params: 2,480,758\n",
      "Non-trainable params: 6,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "avg_ensemble_model_last_layer = avg_ensemble_model.get_layer('average').output\n",
    "output_layer = Dense(num_classes, activation='softmax', name='output_1')(avg_ensemble_model_last_layer)\n",
    "final_model = Model(avg_ensemble_model.input, output_layer)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a30f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:58.375792Z",
     "iopub.status.busy": "2023-07-04T18:21:58.375354Z",
     "iopub.status.idle": "2023-07-04T18:21:58.383816Z",
     "shell.execute_reply": "2023-07-04T18:21:58.382769Z",
     "shell.execute_reply.started": "2023-07-04T18:21:58.375760Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Optimizer\n",
    "\n",
    "class LionOptimizer(Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, name=\"LionOptimizer\", **kwargs):\n",
    "        super(LionOptimizer, self).__init__(name, **kwargs)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [tf.compat.v1.assign_add(param, -self.learning_rate * grad)\n",
    "                        for param, grad in zip(params, grads)]\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(LionOptimizer, self).get_config()\n",
    "        config.update({\"learning_rate\": self.learning_rate})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f894e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:58.385780Z",
     "iopub.status.busy": "2023-07-04T18:21:58.385181Z",
     "iopub.status.idle": "2023-07-04T18:21:58.446932Z",
     "shell.execute_reply": "2023-07-04T18:21:58.446002Z",
     "shell.execute_reply.started": "2023-07-04T18:21:58.385747Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-5)\n",
    "# optimizer = LionOptimizer(learning_rate=0.001)\n",
    "loss = 'categorical_crossentropy'\n",
    "# metrics = ['categorical_accuracy']\n",
    "metrics = ['accuracy', 'categorical_accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), \n",
    "           tf.keras.metrics.TruePositives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(), \n",
    "           tf.keras.metrics.FalseNegatives(), tfa.metrics.CohenKappa(num_classes = num_classes), \n",
    "           tfa.metrics.F1Score(num_classes = num_classes)]\n",
    "\n",
    "final_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6435fe52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:58.448742Z",
     "iopub.status.busy": "2023-07-04T18:21:58.448398Z",
     "iopub.status.idle": "2023-07-04T18:21:58.455174Z",
     "shell.execute_reply": "2023-07-04T18:21:58.454276Z",
     "shell.execute_reply.started": "2023-07-04T18:21:58.448711Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "weight = 'DaVIT_MaxVIT_half.h5'\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1,\n",
    "    patience=9, mode=\"max\", min_delta=0.0001, min_lr=0.00001, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath=weight, save_best_only=True, monitor = 'val_accuracy', verbose=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks = [lr, checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7470073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:21:58.457063Z",
     "iopub.status.busy": "2023-07-04T18:21:58.456490Z",
     "iopub.status.idle": "2023-07-04T18:30:29.818211Z",
     "shell.execute_reply": "2023-07-04T18:30:29.817108Z",
     "shell.execute_reply.started": "2023-07-04T18:21:58.457030Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/3901355234.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = final_model.fit_generator(generator=generator_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.7514 - categorical_accuracy: 0.7514 - auc: 0.8191 - precision: 0.7514 - recall: 0.7514 - true_positives: 275.0000 - true_negatives: 275.0000 - false_positives: 91.0000 - false_negatives: 91.0000 - cohen_kappa: -0.9066 - f1_score: 0.7386\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49398, saving model to DaVIT_MaxVIT_half.h5\n",
      "45/45 [==============================] - 88s 488ms/step - loss: 0.5325 - accuracy: 0.7514 - categorical_accuracy: 0.7514 - auc: 0.8191 - precision: 0.7514 - recall: 0.7514 - true_positives: 275.0000 - true_negatives: 275.0000 - false_positives: 91.0000 - false_negatives: 91.0000 - cohen_kappa: -0.9066 - f1_score: 0.7386 - val_loss: 0.9575 - val_accuracy: 0.4940 - val_categorical_accuracy: 0.4940 - val_auc: 0.5246 - val_precision: 0.4940 - val_recall: 0.4940 - val_true_positives: 41.0000 - val_true_negatives: 41.0000 - val_false_positives: 42.0000 - val_false_negatives: 42.0000 - val_cohen_kappa: -0.9521 - val_f1_score: 0.4812 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8169 - categorical_accuracy: 0.8169 - auc: 0.9058 - precision: 0.8169 - recall: 0.8169 - true_positives: 299.0000 - true_negatives: 299.0000 - false_positives: 67.0000 - false_negatives: 67.0000 - cohen_kappa: -0.9110 - f1_score: 0.8080\n",
      "Epoch 2: val_accuracy improved from 0.49398 to 0.87952, saving model to DaVIT_MaxVIT_half.h5\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.4173 - accuracy: 0.8169 - categorical_accuracy: 0.8169 - auc: 0.9058 - precision: 0.8169 - recall: 0.8169 - true_positives: 299.0000 - true_negatives: 299.0000 - false_positives: 67.0000 - false_negatives: 67.0000 - cohen_kappa: -0.9110 - f1_score: 0.8080 - val_loss: 0.3230 - val_accuracy: 0.8795 - val_categorical_accuracy: 0.8795 - val_auc: 0.9367 - val_precision: 0.8795 - val_recall: 0.8795 - val_true_positives: 73.0000 - val_true_negatives: 73.0000 - val_false_positives: 10.0000 - val_false_negatives: 10.0000 - val_cohen_kappa: -0.7270 - val_f1_score: 0.8569 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9290 - categorical_accuracy: 0.9290 - auc: 0.9707 - precision: 0.9290 - recall: 0.9290 - true_positives: 340.0000 - true_negatives: 340.0000 - false_positives: 26.0000 - false_negatives: 26.0000 - cohen_kappa: -0.8662 - f1_score: 0.9235\n",
      "Epoch 3: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 13s 293ms/step - loss: 0.2176 - accuracy: 0.9290 - categorical_accuracy: 0.9290 - auc: 0.9707 - precision: 0.9290 - recall: 0.9290 - true_positives: 340.0000 - true_negatives: 340.0000 - false_positives: 26.0000 - false_negatives: 26.0000 - cohen_kappa: -0.8662 - f1_score: 0.9235 - val_loss: 1.7643 - val_accuracy: 0.3373 - val_categorical_accuracy: 0.3373 - val_auc: 0.4885 - val_precision: 0.3373 - val_recall: 0.3373 - val_true_positives: 28.0000 - val_true_negatives: 28.0000 - val_false_positives: 55.0000 - val_false_negatives: 55.0000 - val_cohen_kappa: -0.8213 - val_f1_score: 0.2653 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.9098 - categorical_accuracy: 0.9098 - auc: 0.9578 - precision: 0.9098 - recall: 0.9098 - true_positives: 333.0000 - true_negatives: 333.0000 - false_positives: 33.0000 - false_negatives: 33.0000 - cohen_kappa: -0.9022 - f1_score: 0.9049\n",
      "Epoch 4: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.2470 - accuracy: 0.9098 - categorical_accuracy: 0.9098 - auc: 0.9578 - precision: 0.9098 - recall: 0.9098 - true_positives: 333.0000 - true_negatives: 333.0000 - false_positives: 33.0000 - false_negatives: 33.0000 - cohen_kappa: -0.9022 - f1_score: 0.9049 - val_loss: 0.3208 - val_accuracy: 0.8795 - val_categorical_accuracy: 0.8795 - val_auc: 0.9457 - val_precision: 0.8795 - val_recall: 0.8795 - val_true_positives: 73.0000 - val_true_negatives: 73.0000 - val_false_positives: 10.0000 - val_false_negatives: 10.0000 - val_cohen_kappa: -0.6684 - val_f1_score: 0.8496 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9508 - categorical_accuracy: 0.9508 - auc: 0.9914 - precision: 0.9508 - recall: 0.9508 - true_positives: 348.0000 - true_negatives: 348.0000 - false_positives: 18.0000 - false_negatives: 18.0000 - cohen_kappa: -0.8662 - f1_score: 0.9470\n",
      "Epoch 5: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 293ms/step - loss: 0.1145 - accuracy: 0.9508 - categorical_accuracy: 0.9508 - auc: 0.9914 - precision: 0.9508 - recall: 0.9508 - true_positives: 348.0000 - true_negatives: 348.0000 - false_positives: 18.0000 - false_negatives: 18.0000 - cohen_kappa: -0.8662 - f1_score: 0.9470 - val_loss: 1.0644 - val_accuracy: 0.6145 - val_categorical_accuracy: 0.6145 - val_auc: 0.7393 - val_precision: 0.6145 - val_recall: 0.6145 - val_true_positives: 51.0000 - val_true_negatives: 51.0000 - val_false_positives: 32.0000 - val_false_negatives: 32.0000 - val_cohen_kappa: -0.9974 - val_f1_score: 0.6140 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9317 - categorical_accuracy: 0.9317 - auc: 0.9800 - precision: 0.9317 - recall: 0.9317 - true_positives: 341.0000 - true_negatives: 341.0000 - false_positives: 25.0000 - false_negatives: 25.0000 - cohen_kappa: -0.8787 - f1_score: 0.9270\n",
      "Epoch 6: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.1738 - accuracy: 0.9317 - categorical_accuracy: 0.9317 - auc: 0.9800 - precision: 0.9317 - recall: 0.9317 - true_positives: 341.0000 - true_negatives: 341.0000 - false_positives: 25.0000 - false_negatives: 25.0000 - cohen_kappa: -0.8787 - f1_score: 0.9270 - val_loss: 0.4290 - val_accuracy: 0.8193 - val_categorical_accuracy: 0.8193 - val_auc: 0.9019 - val_precision: 0.8193 - val_recall: 0.8193 - val_true_positives: 68.0000 - val_true_negatives: 68.0000 - val_false_positives: 15.0000 - val_false_negatives: 15.0000 - val_cohen_kappa: -0.9283 - val_f1_score: 0.8123 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9235 - categorical_accuracy: 0.9235 - auc: 0.9773 - precision: 0.9235 - recall: 0.9235 - true_positives: 338.0000 - true_negatives: 338.0000 - false_positives: 28.0000 - false_negatives: 28.0000 - cohen_kappa: -0.8860 - f1_score: 0.9186\n",
      "Epoch 7: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 294ms/step - loss: 0.1827 - accuracy: 0.9235 - categorical_accuracy: 0.9235 - auc: 0.9773 - precision: 0.9235 - recall: 0.9235 - true_positives: 338.0000 - true_negatives: 338.0000 - false_positives: 28.0000 - false_negatives: 28.0000 - cohen_kappa: -0.8860 - f1_score: 0.9186 - val_loss: 0.9308 - val_accuracy: 0.7108 - val_categorical_accuracy: 0.7108 - val_auc: 0.7757 - val_precision: 0.7108 - val_recall: 0.7108 - val_true_positives: 59.0000 - val_true_negatives: 59.0000 - val_false_positives: 24.0000 - val_false_negatives: 24.0000 - val_cohen_kappa: -0.9928 - val_f1_score: 0.7098 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9645 - categorical_accuracy: 0.9645 - auc: 0.9924 - precision: 0.9645 - recall: 0.9645 - true_positives: 353.0000 - true_negatives: 353.0000 - false_positives: 13.0000 - false_negatives: 13.0000 - cohen_kappa: -0.8836 - f1_score: 0.9621\n",
      "Epoch 8: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 295ms/step - loss: 0.1029 - accuracy: 0.9645 - categorical_accuracy: 0.9645 - auc: 0.9924 - precision: 0.9645 - recall: 0.9645 - true_positives: 353.0000 - true_negatives: 353.0000 - false_positives: 13.0000 - false_negatives: 13.0000 - cohen_kappa: -0.8836 - f1_score: 0.9621 - val_loss: 0.5230 - val_accuracy: 0.8795 - val_categorical_accuracy: 0.8795 - val_auc: 0.9366 - val_precision: 0.8795 - val_recall: 0.8795 - val_true_positives: 73.0000 - val_true_negatives: 73.0000 - val_false_positives: 10.0000 - val_false_negatives: 10.0000 - val_cohen_kappa: -0.6684 - val_f1_score: 0.8496 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9563 - categorical_accuracy: 0.9563 - auc: 0.9817 - precision: 0.9563 - recall: 0.9563 - true_positives: 350.0000 - true_negatives: 350.0000 - false_positives: 16.0000 - false_negatives: 16.0000 - cohen_kappa: -0.8762 - f1_score: 0.9532\n",
      "Epoch 9: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.1696 - accuracy: 0.9563 - categorical_accuracy: 0.9563 - auc: 0.9817 - precision: 0.9563 - recall: 0.9563 - true_positives: 350.0000 - true_negatives: 350.0000 - false_positives: 16.0000 - false_negatives: 16.0000 - cohen_kappa: -0.8762 - f1_score: 0.9532 - val_loss: 0.6135 - val_accuracy: 0.8193 - val_categorical_accuracy: 0.8193 - val_auc: 0.8724 - val_precision: 0.8193 - val_recall: 0.8193 - val_true_positives: 68.0000 - val_true_negatives: 68.0000 - val_false_positives: 15.0000 - val_false_negatives: 15.0000 - val_cohen_kappa: -0.9447 - val_f1_score: 0.8140 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9426 - categorical_accuracy: 0.9426 - auc: 0.9838 - precision: 0.9426 - recall: 0.9426 - true_positives: 345.0000 - true_negatives: 345.0000 - false_positives: 21.0000 - false_negatives: 21.0000 - cohen_kappa: -0.8787 - f1_score: 0.9387\n",
      "Epoch 10: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 293ms/step - loss: 0.1462 - accuracy: 0.9426 - categorical_accuracy: 0.9426 - auc: 0.9838 - precision: 0.9426 - recall: 0.9426 - true_positives: 345.0000 - true_negatives: 345.0000 - false_positives: 21.0000 - false_negatives: 21.0000 - cohen_kappa: -0.8787 - f1_score: 0.9387 - val_loss: 0.4854 - val_accuracy: 0.8313 - val_categorical_accuracy: 0.8313 - val_auc: 0.9234 - val_precision: 0.8313 - val_recall: 0.8313 - val_true_positives: 69.0000 - val_true_negatives: 69.0000 - val_false_positives: 14.0000 - val_false_negatives: 14.0000 - val_cohen_kappa: -0.9367 - val_f1_score: 0.8256 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9727 - categorical_accuracy: 0.9727 - auc: 0.9969 - precision: 0.9727 - recall: 0.9727 - true_positives: 356.0000 - true_negatives: 356.0000 - false_positives: 10.0000 - false_negatives: 10.0000 - cohen_kappa: -0.8662 - f1_score: 0.9706\n",
      "Epoch 11: val_accuracy did not improve from 0.87952\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0646 - accuracy: 0.9727 - categorical_accuracy: 0.9727 - auc: 0.9969 - precision: 0.9727 - recall: 0.9727 - true_positives: 356.0000 - true_negatives: 356.0000 - false_positives: 10.0000 - false_negatives: 10.0000 - cohen_kappa: -0.8662 - f1_score: 0.9706 - val_loss: 0.3779 - val_accuracy: 0.8675 - val_categorical_accuracy: 0.8675 - val_auc: 0.9419 - val_precision: 0.8675 - val_recall: 0.8675 - val_true_positives: 72.0000 - val_true_negatives: 72.0000 - val_false_positives: 11.0000 - val_false_negatives: 11.0000 - val_cohen_kappa: -0.8902 - val_f1_score: 0.8593 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9809 - categorical_accuracy: 0.9809 - auc: 0.9975 - precision: 0.9809 - recall: 0.9809 - true_positives: 359.0000 - true_negatives: 359.0000 - false_positives: 7.0000 - false_negatives: 7.0000 - cohen_kappa: -0.8687 - f1_score: 0.9794\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.87952 to 0.89157, saving model to DaVIT_MaxVIT_half.h5\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0567 - accuracy: 0.9809 - categorical_accuracy: 0.9809 - auc: 0.9975 - precision: 0.9809 - recall: 0.9809 - true_positives: 359.0000 - true_negatives: 359.0000 - false_positives: 7.0000 - false_negatives: 7.0000 - cohen_kappa: -0.8687 - f1_score: 0.9794 - val_loss: 0.2332 - val_accuracy: 0.8916 - val_categorical_accuracy: 0.8916 - val_auc: 0.9791 - val_precision: 0.8916 - val_recall: 0.8916 - val_true_positives: 74.0000 - val_true_negatives: 74.0000 - val_false_positives: 9.0000 - val_false_negatives: 9.0000 - val_cohen_kappa: -0.7689 - val_f1_score: 0.8753 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9863 - categorical_accuracy: 0.9863 - auc: 0.9994 - precision: 0.9863 - recall: 0.9863 - true_positives: 361.0000 - true_negatives: 361.0000 - false_positives: 5.0000 - false_negatives: 5.0000 - cohen_kappa: -0.8636 - f1_score: 0.9853\n",
      "Epoch 13: val_accuracy improved from 0.89157 to 0.96386, saving model to DaVIT_MaxVIT_half.h5\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0277 - accuracy: 0.9863 - categorical_accuracy: 0.9863 - auc: 0.9994 - precision: 0.9863 - recall: 0.9863 - true_positives: 361.0000 - true_negatives: 361.0000 - false_positives: 5.0000 - false_negatives: 5.0000 - cohen_kappa: -0.8636 - f1_score: 0.9853 - val_loss: 0.1043 - val_accuracy: 0.9639 - val_categorical_accuracy: 0.9639 - val_auc: 0.9945 - val_precision: 0.9639 - val_recall: 0.9639 - val_true_positives: 80.0000 - val_true_negatives: 80.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000 - val_cohen_kappa: -0.7956 - val_f1_score: 0.9592 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9863 - categorical_accuracy: 0.9863 - auc: 0.9996 - precision: 0.9863 - recall: 0.9863 - true_positives: 361.0000 - true_negatives: 361.0000 - false_positives: 5.0000 - false_negatives: 5.0000 - cohen_kappa: -0.8636 - f1_score: 0.9853\n",
      "Epoch 14: val_accuracy improved from 0.96386 to 0.97590, saving model to DaVIT_MaxVIT_half.h5\n",
      "45/45 [==============================] - 15s 322ms/step - loss: 0.0255 - accuracy: 0.9863 - categorical_accuracy: 0.9863 - auc: 0.9996 - precision: 0.9863 - recall: 0.9863 - true_positives: 361.0000 - true_negatives: 361.0000 - false_positives: 5.0000 - false_negatives: 5.0000 - cohen_kappa: -0.8636 - f1_score: 0.9853 - val_loss: 0.0529 - val_accuracy: 0.9759 - val_categorical_accuracy: 0.9759 - val_auc: 0.9988 - val_precision: 0.9759 - val_recall: 0.9759 - val_true_positives: 81.0000 - val_true_negatives: 81.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000 - val_cohen_kappa: -0.8086 - val_f1_score: 0.9731 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9891 - categorical_accuracy: 0.9891 - auc: 0.9990 - precision: 0.9891 - recall: 0.9891 - true_positives: 362.0000 - true_negatives: 362.0000 - false_positives: 4.0000 - false_negatives: 4.0000 - cohen_kappa: -0.8611 - f1_score: 0.9882\n",
      "Epoch 15: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0405 - accuracy: 0.9891 - categorical_accuracy: 0.9891 - auc: 0.9990 - precision: 0.9891 - recall: 0.9891 - true_positives: 362.0000 - true_negatives: 362.0000 - false_positives: 4.0000 - false_negatives: 4.0000 - cohen_kappa: -0.8611 - f1_score: 0.9882 - val_loss: 0.2450 - val_accuracy: 0.8916 - val_categorical_accuracy: 0.8916 - val_auc: 0.9733 - val_precision: 0.8916 - val_recall: 0.8916 - val_true_positives: 74.0000 - val_true_negatives: 74.0000 - val_false_positives: 9.0000 - val_false_negatives: 9.0000 - val_cohen_kappa: -0.8902 - val_f1_score: 0.8849 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 0.9997 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970\n",
      "Epoch 16: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 14s 297ms/step - loss: 0.0185 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 0.9997 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970 - val_loss: 0.2135 - val_accuracy: 0.9157 - val_categorical_accuracy: 0.9157 - val_auc: 0.9820 - val_precision: 0.9157 - val_recall: 0.9157 - val_true_positives: 76.0000 - val_true_negatives: 76.0000 - val_false_positives: 7.0000 - val_false_negatives: 7.0000 - val_cohen_kappa: -0.8687 - val_f1_score: 0.9093 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0094 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9398 - val_categorical_accuracy: 0.9398 - val_auc: 0.9848 - val_precision: 0.9398 - val_recall: 0.9398 - val_true_positives: 78.0000 - val_true_negatives: 78.0000 - val_false_positives: 5.0000 - val_false_negatives: 5.0000 - val_cohen_kappa: -0.8457 - val_f1_score: 0.9343 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 0.9999 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970\n",
      "Epoch 18: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 13s 293ms/step - loss: 0.0123 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 0.9999 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970 - val_loss: 0.1094 - val_accuracy: 0.9398 - val_categorical_accuracy: 0.9398 - val_auc: 0.9938 - val_precision: 0.9398 - val_recall: 0.9398 - val_true_positives: 78.0000 - val_true_negatives: 78.0000 - val_false_positives: 5.0000 - val_false_negatives: 5.0000 - val_cohen_kappa: -0.8457 - val_f1_score: 0.9343 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9945 - categorical_accuracy: 0.9945 - auc: 0.9999 - precision: 0.9945 - recall: 0.9945 - true_positives: 364.0000 - true_negatives: 364.0000 - false_positives: 2.0000 - false_negatives: 2.0000 - cohen_kappa: -0.8559 - f1_score: 0.9941\n",
      "Epoch 19: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 14s 297ms/step - loss: 0.0150 - accuracy: 0.9945 - categorical_accuracy: 0.9945 - auc: 0.9999 - precision: 0.9945 - recall: 0.9945 - true_positives: 364.0000 - true_negatives: 364.0000 - false_positives: 2.0000 - false_negatives: 2.0000 - cohen_kappa: -0.8559 - f1_score: 0.9941 - val_loss: 0.1622 - val_accuracy: 0.9398 - val_categorical_accuracy: 0.9398 - val_auc: 0.9893 - val_precision: 0.9398 - val_recall: 0.9398 - val_true_positives: 78.0000 - val_true_negatives: 78.0000 - val_false_positives: 5.0000 - val_false_negatives: 5.0000 - val_cohen_kappa: -0.8457 - val_f1_score: 0.9343 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 1.0000 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970\n",
      "Epoch 20: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 0.0097 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 1.0000 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970 - val_loss: 0.2795 - val_accuracy: 0.9157 - val_categorical_accuracy: 0.9157 - val_auc: 0.9679 - val_precision: 0.9157 - val_recall: 0.9157 - val_true_positives: 76.0000 - val_true_negatives: 76.0000 - val_false_positives: 7.0000 - val_false_negatives: 7.0000 - val_cohen_kappa: -0.8687 - val_f1_score: 0.9093 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 0.9999 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 15s 318ms/step - loss: 0.0103 - accuracy: 0.9973 - categorical_accuracy: 0.9973 - auc: 0.9999 - precision: 0.9973 - recall: 0.9973 - true_positives: 365.0000 - true_negatives: 365.0000 - false_positives: 1.0000 - false_negatives: 1.0000 - cohen_kappa: -0.8585 - f1_score: 0.9970 - val_loss: 0.2053 - val_accuracy: 0.9277 - val_categorical_accuracy: 0.9277 - val_auc: 0.9872 - val_precision: 0.9277 - val_recall: 0.9277 - val_true_positives: 77.0000 - val_true_negatives: 77.0000 - val_false_positives: 6.0000 - val_false_negatives: 6.0000 - val_cohen_kappa: -0.8574 - val_f1_score: 0.9217 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0101 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9277 - val_categorical_accuracy: 0.9277 - val_auc: 0.9861 - val_precision: 0.9277 - val_recall: 0.9277 - val_true_positives: 77.0000 - val_true_negatives: 77.0000 - val_false_positives: 6.0000 - val_false_negatives: 6.0000 - val_cohen_kappa: -0.8574 - val_f1_score: 0.9217 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 0.97590\n",
      "45/45 [==============================] - 14s 300ms/step - loss: 0.0054 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9277 - val_categorical_accuracy: 0.9277 - val_auc: 0.9861 - val_precision: 0.9277 - val_recall: 0.9277 - val_true_positives: 77.0000 - val_true_negatives: 77.0000 - val_false_positives: 6.0000 - val_false_negatives: 6.0000 - val_cohen_kappa: -0.8574 - val_f1_score: 0.9217 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "46/45 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 0.97590\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 0.0056 - accuracy: 1.0000 - categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 366.0000 - true_negatives: 366.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - cohen_kappa: -0.8559 - f1_score: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9277 - val_categorical_accuracy: 0.9277 - val_auc: 0.9856 - val_precision: 0.9277 - val_recall: 0.9277 - val_true_positives: 77.0000 - val_true_negatives: 77.0000 - val_false_positives: 6.0000 - val_false_negatives: 6.0000 - val_cohen_kappa: -0.8574 - val_f1_score: 0.9217 - lr: 1.0000e-05\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "steps_per_epoch = generator_train.n / batch_size\n",
    "steps_test = generator_test.n / batch_size\n",
    "\n",
    "history = final_model.fit_generator(generator=generator_train,\n",
    "                                  epochs=epochs,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  validation_data=generator_test,\n",
    "                                  validation_steps=steps_test,\n",
    "                                   callbacks=callbacks, class_weight =class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fcce84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T18:30:29.820109Z",
     "iopub.status.busy": "2023-07-04T18:30:29.819671Z",
     "iopub.status.idle": "2023-07-04T18:30:49.812295Z",
     "shell.execute_reply": "2023-07-04T18:30:49.811417Z",
     "shell.execute_reply.started": "2023-07-04T18:30:29.820075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 167ms/step - loss: 0.0529 - accuracy: 0.9759 - categorical_accuracy: 0.9759 - auc: 0.9988 - precision: 0.9759 - recall: 0.9759 - true_positives: 81.0000 - true_negatives: 81.0000 - false_positives: 2.0000 - false_negatives: 2.0000 - cohen_kappa: -0.8086 - f1_score: 0.9731\n",
      "11/11 [==============================] - 5s 173ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        27\n",
      "           1       1.00      0.96      0.98        56\n",
      "\n",
      "    accuracy                           0.98        83\n",
      "   macro avg       0.97      0.98      0.97        83\n",
      "weighted avg       0.98      0.98      0.98        83\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNEAAAJuCAYAAACe4JTkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADTEUlEQVR4nOzdd3hT5dsH8G+S7g3dC9pSVplCy0ZFEGQjKIiDjeJGxIG+IiIIDhw4QJEh6E9BQZaoDFHZtCzZqxS6F907yXn/ODQ5SZvOrLbfz3X1os/JycmTtEBz9x4yQRAEEBERERERERERkUFyS2+AiIiIiIiIiIjI2jGIRkREREREREREVA0G0YiIiIiIiIiIiKrBIBoREREREREREVE1GEQjIiIiIiIiIiKqBoNoRERERERERERE1WAQjYiIiIiIiIiIqBoMohEREREREREREVWDQTQiIiIiIiIiIqJqMIhGRERETda6desgk8kgk8nw999/V7hdEASEh4dDJpPh3nvvNepjy2QyLFiwoNb3i4uLg0wmw7p162p8n7Nnz0Imk8HW1hbJycm1fkwiIiIiYhCNiIiICK6urli9enWF4//88w+uX78OV1dXC+zKeL799lsAgFKpxPr16y28GyIiIqKGiUE0IiIiavImTJiAzZs3Izc3V+f46tWr0bt3b7Ro0cJCO6u/kpIS/PDDD+jSpQsCAwOxZs0aS2/JoKKiIgiCYOltEBEREVWKQTQiIiJq8iZOnAgA+PHHHzXHcnJysHnzZkybNq3S+9y+fRvPPPMMAgMDYWdnh7CwMLz55psoKSnROS83NxczZ86Ep6cnXFxc8MADD+DKlSuVXvPq1at49NFH4ePjA3t7e7Rv3x5ffvllvZ7b1q1bkZmZiRkzZmDy5Mm4cuUKDh48WOG8kpISLFy4EO3bt4eDgwM8PT0xYMAAHD58WHOOWq3G559/jq5du8LR0REeHh7o1asXtm/frjnHUJlqSEgIpkyZolmXl9Lu3r0b06ZNg7e3N5ycnFBSUoJr165h6tSpaN26NZycnBAYGIiRI0fi7NmzFa6bnZ2Nl19+GWFhYbC3t4ePjw+GDRuGS5cuQRAEtG7dGkOGDKlwv/z8fLi7u+PZZ5+t5StKRERETRWDaERERNTkubm54aGHHtLJ0vrxxx8hl8sxYcKECucXFxdjwIABWL9+PebMmYPffvsNjz/+OD744AOMHTtWc54gCBgzZgw2bNiAl19+Gb/++it69eqFoUOHVrjmhQsXEBUVhXPnzmHZsmXYuXMnhg8fjhdeeAHvvPNOnZ/b6tWrYW9vj8ceewzTpk2DTCarULqqVCoxdOhQvPvuuxgxYgR+/fVXrFu3Dn369MGtW7c0502ZMgUvvvgioqKisHHjRvz0008YNWoU4uLi6ry/adOmwdbWFhs2bMAvv/wCW1tbJCUlwdPTE0uXLsUff/yBL7/8EjY2NujZsycuX76suW9eXh769euHr7/+GlOnTsWOHTuwcuVKtGnTBsnJyZDJZHj++eexZ88eXL16Vedx169fj9zcXAbRiIiIqOYEIiIioiZq7dq1AgAhOjpa2L9/vwBAOHfunCAIghAVFSVMmTJFEARB6NChg3DPPfdo7rdy5UoBgLBp0yad673//vsCAGH37t2CIAjC77//LgAQPvvsM53zFi9eLAAQ3n77bc2xIUOGCEFBQUJOTo7Ouc8995zg4OAg3L59WxAEQbhx44YAQFi7dm21zy8uLk6Qy+XCI488ojl2zz33CM7OzkJubq7m2Pr16wUAwqpVqwxe699//xUACG+++WaVj6n/vMq1bNlSmDx5smZd/tpPmjSp2uehVCqF0tJSoXXr1sJLL72kOb5w4UIBgLBnzx6D983NzRVcXV2FF198Ued4RESEMGDAgGofm4iIiKgcM9GIiIiIANxzzz1o1aoV1qxZg7NnzyI6OtpgKedff/0FZ2dnPPTQQzrHy8sV9+3bBwDYv38/AOCxxx7TOe/RRx/VWRcXF2Pfvn148MEH4eTkBKVSqfkYNmwYiouLcfTo0Vo/p7Vr10KtVus8j2nTpqGgoAAbN27UHPv999/h4OBg8PmWnwPA6Jlb48aNq3BMqVTivffeQ0REBOzs7GBjYwM7OztcvXoVFy9e1NlTmzZtMGjQIIPXd3V1xdSpU7Fu3ToUFBQAEL9+Fy5cwHPPPWfU50JERESNG4NoRERERBB7eU2dOhXff/+9piSwf//+lZ6bmZkJPz8/yGQyneM+Pj6wsbFBZmam5jwbGxt4enrqnOfn51fhekqlEp9//jlsbW11PoYNGwYAyMjIqNXzUavVWLduHQICAtC9e3dkZ2cjOzsbgwYNgrOzs05JZ3p6OgICAiCXG/7RMD09HQqFosLe68vf37/CsTlz5uCtt97CmDFjsGPHDhw7dgzR0dHo0qULioqKdPYUFBRU7WM8//zzyMvLww8//AAA+OKLLxAUFITRo0cb74kQERFRo2dj6Q0QERERWYspU6Zg/vz5WLlyJRYvXmzwPE9PTxw7dgyCIOgE0tLS0qBUKuHl5aU5T6lUIjMzUyeQlpKSonO9Zs2aQaFQ4IknnjCY6RUaGlqr57J3717cvHlTsw99R48exYULFxAREQFvb28cPHgQarXaYCDN29sbKpUKKSkplQa+ytnb21cYrgBAE1jUpx+IBIDvv/8ekyZNwnvvvadzPCMjAx4eHjp7SkhIMLiXcuHh4Rg6dCi+/PJLDB06FNu3b8c777wDhUJR7X2JiIiIyjETjYiIiOiOwMBAvPLKKxg5ciQmT55s8LyBAwciPz8fW7du1Tm+fv16ze0AMGDAAADQZECV+9///qezdnJywoABA3Dq1Cl07twZkZGRFT4qC4RVZfXq1ZDL5di6dSv279+v87FhwwYA0AxSGDp0KIqLi7Fu3TqD1ysfhrBixYoqHzckJAT//fefzrG//voL+fn5Nd67TCaDvb29zrHffvsNiYmJFfZ05coV/PXXX9Ve88UXX8R///2HyZMnQ6FQYObMmTXeDxERERHATDQiIiIiHUuXLq32nEmTJuHLL7/E5MmTERcXh06dOuHgwYN47733MGzYME2PrsGDB+Puu+/Gq6++ioKCAkRGRuLQoUOaIJbUZ599hn79+qF///54+umnERISgry8PFy7dg07duyoUaCoXGZmJrZt24YhQ4YYLFn85JNPsH79eixZsgQTJ07E2rVrMWvWLFy+fBkDBgyAWq3GsWPH0L59ezzyyCPo378/nnjiCSxatAipqakYMWIE7O3tcerUKTg5OeH5558HADzxxBN46623MH/+fNxzzz24cOECvvjiC7i7u9d4/yNGjMC6devQrl07dO7cGSdOnMCHH35YoXRz9uzZ2LhxI0aPHo3XX38dPXr0QFFREf755x+MGDFCE8QEgPvvvx8RERHYv38/Hn/8cfj4+NR4P0REREQAM9GIiIiIas3BwQH79+/HY489hg8//BBDhw7FunXrMHfuXGzZskVznlwux/bt2/HYY4/hgw8+wJgxY3D48GHs2rWrwjUjIiJw8uRJdOzYEf/3f/+HwYMHY/r06fjll180mW019f3336OkpARPPfWUwXOefPJJpKenY8eOHbCxscGuXbswb948/Prrrxg9ejQmTZqEgwcPomXLlpr7rFu3Dh9//DEOHz6Mhx56COPHj8e2bdt0Sk1feeUVvPLKK1i3bh1GjhyJzZs3Y9OmTTplmNX57LPP8Pjjj2PJkiUYOXIktm/fji1btqBVq1Y657m6uuLgwYOYPn06vvnmGwwfPhwzZ87E5cuXERAQUOG648ePBwAOFCAiIqI6kQmCIFh6E0REREREphYZGQmZTIbo6GhLb4WIiIgaIJZzEhEREVGjlZubi3PnzmHnzp04ceIEfv31V0tviYiIiBooBtGIiIiIqNE6efIkBgwYAE9PT7z99tsYM2aMpbdEREREDRTLOYmIiIiIiIiIiKrBwQJERERERERERETVYBCNiIiIiIiIiIioGgyiERERERERERERVaPJDRZQq9VISkqCq6srZDKZpbdDREREREREREQWJAgC8vLyEBAQALnccL5ZkwuiJSUlITg42NLbICIiIiIiIiIiKxIfH4+goCCDtze5IJqrqysA8YVxc3Oz8G6IiIiIiIiIiMiScnNzERwcrIkZGdLkgmjlJZxubm4MohEREREREREREQBU2/aLgwWIiIiIiIiIiIiqwSAaERERERERERFRNRhEIyIiIiIiIiIiqkaT64lWE4IgQKlUQqVSWXorRFWytbWFQqGw9DaIiIiIiIiIGj0G0fSUlpYiOTkZhYWFlt4KUbVkMhmCgoLg4uJi6a0QERERERERNWoMokmo1WrcuHEDCoUCAQEBsLOzq3YyA5GlCIKA9PR0JCQkoHXr1sxIIyIiIiIiIjIhBtEkSktLoVarERwcDCcnJ0tvh6ha3t7eiIuLQ1lZGYNoRERERERERCbEwQKVkMv5slDDwExJIiIiIiIiIvNgtIiIiIiIiIiIiKgaDKIRERERERERERFVg0E0Mujee+/F7Nmza3x+XFwcZDIZTp8+bbI9ERERERERERFZAoNojYBMJqvyY8qUKXW67pYtW/Duu+/W+Pzg4GAkJyejY8eOdXq8uhg8eDAUCgWOHj1qtsckIiIiIiIioqaH0zkbgeTkZM3nGzduxPz583H58mXNMUdHR53zy8rKYGtrW+11mzdvXqt9KBQK+Pn51eo+9XHr1i0cOXIEzz33HFavXo1evXqZ7bErU9PXlYiIiIiIiIgaHmaiVScnBzh40HIfOTnVbtHPz0/z4e7uDplMplkXFxfDw8MDmzZtwr333gsHBwd8//33yMzMxMSJExEUFAQnJyd06tQJP/74o8519cs5Q0JC8N5772HatGlwdXVFixYt8M0332hu1y/n/PvvvyGTybBv3z5ERkbCyckJffr00QnwAcCiRYvg4+MDV1dXzJgxA6+//jq6du1a7fNeu3YtRowYgaeffhobN25EQUGBzu3Z2dl48skn4evrCwcHB3Ts2BE7d+7U3H7o0CHcc889cHJyQrNmzTBkyBBkZWVpnuunn36qc72uXbtiwYIFmrVMJsPKlSsxevRoODs7Y9GiRVCpVJg+fTpCQ0Ph6OiItm3b4rPPPquw9zVr1qBDhw6wt7eHv78/nnvuOQDAtGnTMGLECJ1zlUol/Pz8sGbNmmpfEyIiIiIiIiIyDWaiVefsWaB/f8s9/oEDQL9+9b7Ma6+9hmXLlmHt2rWwt7dHcXExunfvjtdeew1ubm747bff8MQTTyAsLAw9e/Y0eJ1ly5bh3XffxRtvvIFffvkFTz/9NO6++260a9fO4H3efPNNLFu2DN7e3pg1axamTZuGQ4cOAQB++OEHLF68GF999RX69u2Ln376CcuWLUNoaGiVz0cQBKxduxZffvkl2rVrhzZt2mDTpk2YOnUqAECtVmPo0KHIy8vD999/j1atWuHChQtQKBQAgNOnT2PgwIGYNm0ali9fDhsbG+zfvx8qlapWr+vbb7+NJUuW4JNPPoFCoYBarUZQUBA2bdoELy8vHD58GE8++ST8/f0xfvx4AMCKFSswZ84cLF26FEOHDkVOTo7m9ZgxYwbuvvtuJCcnw9/fHwCwa9cu5Ofna+5PRERERERERObHIFoTMXv2bIwdO1bn2Ny5czWfP//88/jjjz/w888/VxlEGzZsGJ555hkAYmDuk08+wd9//11lEG3x4sW45557AACvv/46hg8fjuLiYjg4OODzzz/H9OnTNcGv+fPnY/fu3cjPz6/y+ezduxeFhYUYMmQIAODxxx/H6tWrNdfZu3cvjh8/josXL6JNmzYAgLCwMM39P/jgA0RGRuKrr77SHOvQoUOVj1mZRx99FNOmTdM59s4772g+Dw0NxeHDh7Fp0yZNEGzRokV4+eWX8eKLL2rOi4qKAgD06dMHbdu2xYYNG/Dqq68CEDPuHn74Ybi4uNR6f0RERERERERkHCznbCIiIyN11iqVCosXL0bnzp3h6ekJFxcX7N69G7du3aryOp07d9Z8Xl42mpaWVuP7lGdXld/n8uXL6NGjh875+uvKrF69GhMmTICNjRgHnjhxIo4dO6YpFT19+jSCgoI0ATR95Zlo9aX/ugLAypUrERkZCW9vb7i4uGDVqlWa1zUtLQ1JSUlVPvaMGTOwdu1azfm//fZbhUAdEREREREREZmXRTPR/v33X3z44Yc4ceIEkpOT8euvv2LMmDFV3ueff/7BnDlzcP78eQQEBODVV1/FrFmzTLfJTp3EkkpL6dTJKJdxdnbWWS9btgyffPIJPv30U3Tq1AnOzs6YPXs2SktLq7yOfuN8mUwGtVpd4/vIZDIA0LlP+bFygiBUeb3bt29j69atKCsrw4oVKzTHVSoV1qxZg/fff7/CMAV91d0ul8sr7KOsrKzCefqv66ZNm/DSSy9h2bJl6N27N1xdXfHhhx/i2LFjNXpcAJg0aRJef/11HDlyBEeOHEFISAj6W7KkmIiIiIiIiIgsG0QrKChAly5dMHXqVIwbN67a82/cuIFhw4Zh5syZ+P7773Ho0CE888wz8Pb2rtH968Td3Sg9yazNgQMHMHr0aDz++OMAxKDW1atX0b59e7Puo23btjh+/DieeOIJzbGYmJgq7/PDDz8gKCgIW7du1Tm+b98+LFmyRJNhl5CQgCtXrlSajda5c2fs27dPp/RSytvbW2fqaW5uLm7cuFHt8zlw4AD69OmjKXkFgOvXr2s+d3V1RUhICPbt24cBAwZUeg1PT0+MGTMGa9euxZEjRzQlqkRERERERERkORYNog0dOhRDhw6t8fkrV65EixYtNFMT27dvj5iYGHz00UemC6I1UuHh4di8eTMOHz6MZs2a4eOPP0ZKSorZg2jPP/88Zs6cicjISPTp0wcbN27Ef//9p9O/TN/q1avx0EMPoWPHjjrHW7Zsiddeew2//fYbRo8ejbvvvhvjxo3Dxx9/jPDwcFy6dAkymQwPPPAA5s2bh06dOuGZZ57BrFmzYGdnh/379+Phhx+Gl5cX7rvvPqxbtw4jR45Es2bN8NZbb2mGElQlPDwc69evx59//onQ0FBs2LAB0dHROoMSFixYgFmzZsHHx0cz/ODQoUN4/vnnNefMmDEDI0aMgEqlwuTJk+vwyhIRERFRjQkCUFQEFBSIH/n52s8rWxcXA46OgIsL4Oys/TC0trcH9KoviKgaKhVQWFj938nyz6upqiITCAgAJAkkTUGDGixw5MgRDB48WOfYkCFDsHr1apSVlVUoNQSAkpISlJSUaNa5ubkm32dD8NZbb+HGjRsYMmQInJyc8OSTT2LMmDHIyckx6z4ee+wxxMbGYu7cuSguLsb48eMxZcoUHD9+vNLzT5w4gTNnzmDVqlUVbnN1dcXgwYOxevVqjB49Gps3b8bcuXMxceJEFBQUIDw8HEuXLgUAtGnTBrt378Ybb7yBHj16wNHRET179sTEiRMBAPPmzUNsbCxGjBgBd3d3vPvuuzXKRJs1axZOnz6NCRMmQCaTYeLEiXjmmWfw+++/a86ZPHkyiouL8cknn2Du3Lnw8vLCQw89pHOdQYMGwd/fHx06dEBAQECNX08iIiKiRksQxDfJNQly1XZdUCBe31Tk8qqDbPVZV/IeiMhsahOArs3fy/x8MVhN1q179yYXRJMJ1TWgMhOZTFZtT7Q2bdpgypQpeOONNzTHDh8+jL59+yIpKUnTtF5qwYIFlZbs5eTkwM3NTedYcXExbty4gdDQUDg4ONT9yVC93H///fDz88OGDRssvRWLKSwsREBAANasWVNhqqoUv2eJiIioQVGpgMREIDZW/IiP175xrsmbb5XK0s/A+tjaGjcoJ13XoBKjySktrTwIW9n3rySZo0EpK6tdENo6QgpkCd27A9W0Y2oocnNz4e7uXmmsSKpBZaIBhpvQ6x8vN2/ePMyZM0ezzs3NRXBwsOk2SLVSWFiIlStXYsiQIVAoFPjxxx+xd+9e7Nmzx9Jbswi1Wo2UlBQsW7YM7u7uGDVqlKW3RERERFQ72dnaIFlsLHDjhvbzmzfFN+gNnZ2d9ZSOlZWJr3l2tvGv7eBg/Mw5Z2exFFYuN/5+yymVxs1UlK6VStPtm+pOLmfZtCU0wUSOBhVE8/PzQ0pKis6xtLQ02NjYwNPTs9L72Nvbw97e3hzbozqQyWTYtWsXFi1ahJKSErRt2xabN2/GoEGDLL01i7h16xZCQ0MRFBSEdevWwcamQf0VJSIioqagtBS4dUs3OCYNmGVlWXqHInt705RPlgeAyvs1Gbu0ND/fegKNxcXiR2am8a/t5FTz19/Orma9scrX1hLgpIpq83WvbM2+g2RhDeodeu/evbFjxw6dY7t370ZkZGSl/dDI+jk6OmLv3r2W3obVCAkJgZVUWBMREVFTJQhAenrFIFn5Oj4eUKuN81gKBeDqavxMJycnwNS/jCzfu6ur8a9d23K6mq7z8433tauvwkLxozFTKBpmYEehqF0Aq6bnmjoDkcgMLBpEy8/Px7Vr1zTrGzdu4PTp02jevDlatGiBefPmITExEevXrwcgNm3/4osvMGfOHMycORNHjhzB6tWr8eOPP1rqKRARERERNTxFRUBcXOUll7GxYsDFWHx8gLAwIDRU/FP6ERjIvluVsbUFPDzED2MqH85grObv+uuGyMbGNCWrzs6mD+QSkdlZ9G91TEwMBgwYoFmX9y6bPHky1q1bh+TkZNy6dUtze2hoKHbt2oWXXnoJX375JQICArB8+XKMGzfO7HsnIiIiIrJaajWQnFx5gCw2VrzNWBwcKgbIytehoWJQgayDTCaWvdnbAwba4dRZ+ZRGU5S3lpbWvwywsnV5qWhDzBYjIouwmumc5lLVxAVOOqSGht+zREREjVx5YKK6YEN2tjaz7MYN8cOYkwEDAysGyMo/fH1ZokVERA1ao53OSURERERkVcpL5Iw9BTA/X+wZZY7febu4AK1aVV5y2bJlk5zARkREpI9BNCIiIiKqH0EAcnOBtDQgNVX8MyNDnF7Y0KjV2imAtekXZe3PVaEAWrQwXHbp6cmSNiIiomowiEZEREREFalUYiCsPDBWHhwz9KcxSwepbpo3rzxAFhYGBAeLzeqJiIiozhhEo1pbt24dZs+ejezsbEtvhYiIiGqjqKjqQJj0z4wM85QRNkUODsafBOjiIjZeJyIiIpNhEK0RkFWTel8+7bQuQkJCMHv2bMyePVtzbMKECRg2bFidrlcXRUVFCAgIgEwmQ2JiIhwdHc322ERERFZNEMSG8jUJiqWlAXl5lt5xw2Fra/xJgOWBLoXC0s+OiIiI6oBBtEYgWTKifOPGjZg/fz4uX76sOWbsoJOjo6NZA1mbN29Gx44dIQgCtmzZgscee8xsj61PEASoVCrY2PCvDhERmZBaDaSkaKcspqRUHhRLSwPKysy7N2dnwMdHnMhY1Z/e3oCdnXn3ZixOTix9JCIiogoYCahGbnEZLqdY7re2bf1c4eZQ9Q9xfn5+ms/d3d0hk8l0ju3YsQMLFizA+fPnERAQgMmTJ+PNN9/UBIIWLFiANWvWIDU1FZ6ennjooYewfPly3Hvvvbh58yZeeuklvPTSSwDEIJJ+OeeCBQuwdetWvPzyy3jrrbeQlZWFoUOHYtWqVXB1dQUA5OXlYdasWdi6dSvc3Nzw6quvYtu2bejatSs+/fTTKp/f6tWr8fjjj0MQBKxevbpCEO38+fN49dVXceDAAQiCgK5du2LdunVo1aoVAGDNmjVYtmwZrl27hubNm2PcuHH44osvEBcXh9DQUJw6dQpdu3YFAGRnZ6NZs2bYv38/7r33Xvz9998YMGAA/vjjD7z55pv477//8Oeff6JFixaYM2cOjh49ioKCArRv3x5LlizBoEGDNPsqKSnBW2+9hR9//BFpaWlo0aIFXn/9dUybNg2tW7fGrFmzMHfuXM35586dQ+fOnXH16lXN3omIqBHLzxcDZLGx2o/y9Y0bQHGx+fbi6Wk4IKZ/zNnZfPsiIiIisiIMolXjckoeHl55xGKP//Os3ogKaV7n+//55594/PHHsXz5cvTv3x/Xr1/Hk08+CQB4++238csvv+CTTz7BTz/9hA4dOiAlJQVnzpwBAGzZsgVdunTBk08+iZkzZ1b5ONevX8fWrVuxc+dOZGVlYfz48Vi6dCkWL14MAJgzZw4OHTqE7du3w9fXF/Pnz8fJkyc1wauqrnvkyBFs2bIFgiBg9uzZiI2NRVhYGAAgMTERd999N+6991789ddfcHNzw6FDh6BUKgEAK1aswJw5c7B06VIMHToUOTk5OHToUK1fx1dffRUfffQRwsLC4OHhgYSEBAwbNgyLFi2Cg4MDvvvuO4wcORKXL19GixYtAACTJk3CkSNHsHz5cnTp0gU3btxARkYGZDIZpk2bhrVr1+oE0dasWYP+/fszgEZE1FioVEBCQuVBsthYID3ddI9ta1uzbDFfX8DLi1lXRERERDXAIFojt3jxYrz++uuYPHkyACAsLAzvvvsuXn31Vbz99tu4desW/Pz8MGjQINja2qJFixbo0aMHAKB58+ZQKBRwdXXVyWyrjFqtxrp16zSZZ0888QT27duHxYsXIy8vD9999x3+97//YeDAgQCAtWvXIiAgoNr9r1mzBkOHDkWzZs0AAA888ADWrFmDRYsWAQC+/PJLuLu746effoLtnTcAbdq00dx/0aJFePnll/Hiiy9qjkVFRdXotZNauHAh7r//fs3a09MTXbp00XmcX3/9Fdu3b8dzzz2HK1euYNOmTdizZ48mO6088AcAU6dOxfz583H8+HH06NEDZWVl+P777/Hhhx/Wem9ERGRBWVmGg2Q3bwJ3fqljFK6uNQuK+fgAHh5ANT1TiYiIiKh2GERr5E6cOIHo6GhNRhgAqFQqFBcXo7CwEA8//DA+/fRThIWF4YEHHsCwYcMwcuTIWvf8CgkJ0QTQAMDf3x9paWkAgNjYWJSVlWmCc4BYdtq2bdsqr6lSqfDdd9/hs88+0xx7/PHH8dJLL+Gdd96BQqHA6dOn0b9/f00ATSotLQ1JSUmawF19REZG6qwLCgrwzjvvYOfOnUhKSoJSqURRURFu3boFADh9+jQUCgXuueeeSq/n7++P4cOHY82aNejRowd27tyJ4uJiPPzww/XeKxERGVFpqRgMqyxIFhsL5OQY77GaNQPCwrQfoaHaPwMDAQ7WMQlBEBB/uwjnknJwLjEHyTnFuK+dD0Z2qf6XfURERNS0MIhWjbZ+rvh5Vm+LPn59qNVqvPPOOxg7dmyF2xwcHBAcHIzLly9jz5492Lt3L5555hl8+OGH+OeffyoNTBmif65MJoNarQYg/nBafkyq/Lghf/75JxITEzFhwgSd4yqVCrt378bQoUOrHHBQ3fADuVxeYR9lBpozO+v1f3nllVfw559/4qOPPkJ4eDgcHR3x0EMPobS0tEaPDQAzZszAE088gU8++QRr167FhAkT4MTR9ERE5iUIYnN+Q0GyhATxHGOwtQVCQioGyco/9/AwzuOQQSq1gNj0fJxLysH5xFzxz6Rc5BXrZgz+eioRMhkwojMDaURERKTFIFo13Bxs69WTzNK6deuGy5cvIzw83OA5jo6OGDVqFEaNGoVnn30W7dq1w9mzZ9GtWzfY2dlBpVLVaw+tWrWCra0tjh8/juDgYABAbm4url69ajBTCxAHCjzyyCN48803dY4vXboUq1evxtChQ9G5c2d89913KCsrqxDIc3V1RUhICPbt24cBAwZUuL63tzcAcbrpXXfdBUDMIKuJAwcOYMqUKXjwwQcBAPn5+YiLi9Pc3qlTJ6jVavzzzz86wwakhg0bBmdnZ6xYsQK///47/v333xo9NhER1UFpKbB/P3D5csXyy8JC4z2Or2/FAFn5R0AAoFAY77GoSiVKFa6m5uNcohgoO5eUg4vJuSguU9fo/vM2n0XnQA+08OQvuIiIiEjEIFojN3/+fIwYMQLBwcF4+OGHIZfL8d9//+Hs2bNYtGgR1q1bB5VKhZ49e8LJyQkbNmyAo6MjWrZsCUAs0/z333/xyCOPwN7eHl5eXrXeg6urKyZPnoxXXnkFzZs3h4+PD95++23I5fIK2Wnl0tPTsWPHDmzfvh0dO3bUuW3y5MkYPnw40tPT8dxzz+Hzzz/HI488gnnz5sHd3R1Hjx5Fjx490LZtWyxYsACzZs2Cj48Phg4diry8PBw6dAjPP/88HB0d0atXLyxduhQhISHIyMjA//3f/9XoOYWHh2PLli0YOXIkZDIZ3nrrLU3mXfnrNnnyZEybNk0zWODmzZtIS0vD+PHjAQAKhQJTpkzBvHnzEB4ejt69LZfxSETUaBUVAd9+C3zwgZhVVl+OjpUHyUJDxQ9OrrSIwlIlLibn4lxiLs4n5eBcYi6upuWhTFX3LMK8EiWe/+kUfn6qN+xs5EbcLRERETVUDKI1ckOGDMHOnTuxcOFCfPDBB7C1tUW7du0wY8YMAICHhweWLl2KOXPmQKVSoVOnTtixYwc8PT0BiA31n3rqKbRq1QolJSXVlmAa8vHHH2PWrFkYMWIE3Nzc8OqrryI+Ph4ODg6Vnr9+/Xo4OztX2s9swIABcHV1xYYNGzBnzhz89ddfeOWVV3DPPfdAoVCga9eu6Nu3LwAx4FZcXIxPPvkEc+fOhZeXFx566CHNtdasWYNp06YhMjISbdu2xQcffIDBgwdX+3w++eQTTJs2DX369IGXlxdee+015Obm6pyzYsUKvPHGG3jmmWeQmZmJFi1a4I033tA5Z/r06Xjvvfcwbdq0ah+TiIhqIS8PWLECWLZMLNesKZlM7D9WWW+ysDAx04wN+y0qp7AM55O02WXnEnMQm1FQ66pbOxs52vu5IiLAHR0D3dAhwB2tfVwwdW00jsfdBgCcic/GR7sv441h7U3wTIiIiKihkQl1jYo0ULm5uXB3d0dOTg7c3Nx0bisuLsaNGzcQGhpqMLhDxlFQUIDAwEAsW7YM06dPt/R2LObQoUO49957kZCQAF9f31rfn9+zRER6srKAzz8HPv1U/Lwybm6Gg2QtWwL29mbdMhmWlleM80m5OJ8oZpedT85B/O2iWl/H2U6BiAAxUNYx0B0dAtwQ7uMCW0XFDLPknCIM/ewAsgu1fVLXTo3CgLY+9XouREREZL2qihVJMRONzOLUqVO4dOkSevTogZycHCxcuBAAMHr0aAvvzDJKSkoQHx+Pt956C+PHj69TAI2IiCTS0oBPPgG+/FLMQtPn4wO8/DIwZQrg7c1sMisjCAISsorEgFl5llliDtLySmp9LQ8nW3QMcEeHO9llHQPcEOLpDLm8Zl9zf3dHfPRQF8xYH6M59vKmM/j9xf7wdeMvrIiIiJoyBtHIbD766CNcvnwZdnZ26N69Ow4cOFCnHmuNwY8//ojp06eja9eu2LBhg6W3Q0TUcCUmAh99BHz9tdj/TF9gIPDqq8CMGQAnIFsFtVrAjcwCTcP/8h5mOUWVT8iuiq+b/Z2AmZhd1jHQHQHuDgZ7rtbUoAhfTO0bgrWH4gAAtwtKMfun0/h+Rk8oahiMIyIiosaH5ZwSLI2jhobfs0R3JCeLmUihoWKpHjV+cXHA++8Da9aIkzf1hYYCr78OTJ7M8kwLKlOpxQmZSTm4cCe77EJyLgpLaz/5u0VzJ03vsg53SjO9XU33tS1RqjBuxWGcS9T2PJ1zfxu8MLC1yR6TiIiILIPlnERE1PilpADPPAP8+qv2mKen4X5XwcGADf/ra9AuXwaWLAG+/x5QVRKIadcOeOMNYOJEfq0t6O/Lafhs31WcT8xFqUpd/R0k5DKglbeLJrOsQ4A7IgLc4O5oa6LdVs7eRoHPJ3bDiOUHUHAn6Pfp3ivoGdocPcM8zboXIiIisg786bISTSw5jxowfq9SkyUIYhDlxRcrNo/PzBQ/oqMr3k+hAFq0MBxka96cvbKs1X//Ae+9B2zahErHMHbuDPzf/wFjx4pfZ7KYfRdTMXN9DNQ1+C/KViFDWz9XdPC/MyEz0B3t/dzgaGcdX8NQL2e8N7YTXvzpNABALQAv/nQav7/YH82c7Sy7OSIiIjI7BtEkbG3F33AWFhbC0dHRwrshql7pnRImBd8wUlOSmAg89RTw22+1v69KBdy4IX7s21fxdjc33aCaNNAWEsKyQEuIjgYWLwa2bav89h49xODZiBEMgFqBc4k5eP7HU5UG0BxtyydkuqHjneyyNr6usLOpOCHTmozuGohD1zKwKSYBAJCSW4y5P5/Bt5Mj6917jYiIiBoWBtEkFAoFPDw8kJaWBgBwcnLiD0dktdRqNdLT0+Hk5AQblixRUyAIYv+rOXOA3Fzd2+66S5y8mJICxMaKH+XBssr6ZRmSmwucOSN+6JPJxCb1+tlr5Ws/PwZxjOnAAWDRImD37spvv+ceMXg2cCBfdyuRnFOE6d9F6/Q7Gxzhi+Gd/dEhwA2hXi4Ntin/glEdcPJWNq6l5QMA9l1Kw5pDcZjeL9TCOyMiIiJz4mABPYIgICUlBdnZ2ebfHFEtyeVyhIaGws6OJSXUyN26BcycWTGgYmcHzJ8vTl+0raRfkloNJCXpBtbKP4+NFYNuxuLoqA2uVRZkc3Y23mM1VoIA7N0rBs/+/bfycx54AHjzTaBfP/PujaqUX6LEwyuP4GKyNsB9b1tvfDspEjYK6840q6lLKbkY9cUhlCrFHm+2Chm2PN0XnYLcLbwzIiIiqq+aDhZgEM0AlUqFsrLaj1onMic7OzvI5Y3jzQlRpdRq4JtvgFdeAfLzdW+LigLWrgU6dKj79QsLxSmPhoJshYX12r4OH5/Ke7FFRIi3NWWCAOzYIQbPKutlBwBjxojBs8hIs26NqqdUqTFzfQz2X07XHGvn54pfnu4DF/vGlSn9/dGb+L+t5zTrlp5O2Pl8P7g6mHfoARERERkXg2gG1PSFISIiC4uNBWbMAPbv1z1ubw+8+y7w0kumnb4oCEB6um5QTRpki4+vvMF9XYSGAr17A716iR9duohZdo2dSgVs3iz2PPvvv4q3y2TAhAnitM1Oncy/P6qWIAiYv+08Nhy9qTnm62aPrc/2hb974+svKwgCnv3fSew6q81iHdUlAJ890pUtQIiIiBowBtEMYBCNiMjKqdXAl18Cr79eMROsTx+xL1rbtpbZm1RpqVhmWlmQ7fp1ICen7td2cAC6d9cG1Xr3FvuxNRZlZcCPP4rTNi9frni7jQ3w+OPi94A1fK3JoNUHb+DdnRc0ayc7BTY91RsdAxtviWNOURmGLz+AhKwizbEPxnXG+KhgC+6KiIiI6oNBNAMYRCMismJXrwLTpgEHD+oed3QEliwBnnsOaCjTaLOyKi8RvXFDLCFVKmt3vaAgbUCtVy+gWzcx2NaQlJQA69YBS5eKr4E+Oztg+nSxx11IiJk3R7W1+3wKnvr+hCYhUy4DVk2KxMD2vpbdmBmcupWFh1cegfLOGFIHWzl2PNcPrX1dLbwzIiIiqgsG0QxgEI2ogcnLEzOT3BtvVgNBLOv79FNx2mJxse5t99wDrF4NtGplka2ZhEoFJCSIQcOYGODoUeDIEeDOdOgasbUFunbVLQMNCbHOSZWFhcCqVcCHHwKJiRVvd3QEZs0C5s4FAgLMvz+qtf8SsjHh66MoKtNO4lwwMgJT+jadaZVf/3MdS36/pFm39XXFtuf6wsG2gQT6iYiISINBNAMYRCNqIMrKgA8+EHslFRUBPXsCo0eLH+3bW2eggOrm4kUx++zoUd3jzs7i98CsWUBTGKAhCGJ2VnlA7ehR4NSp2mWs+fpqA2q9eonDFyw5FTQ3F/jqK+Djj8X+cvpcXYHnnwdmzwa8vc2+PaqbxOwijPnyENLzSjTHpvQJwYJR9Rjy0QCp1QKmrovGP1e039uP9myB9x5k/z4iIqKGhkE0AxhEI2oAzpwBpk4VAwiVadVKG1Dr08e0zeXJdJRK4KOPgAULxDI/qUGDxMylpl7SV1QEnDwpBtTKPxISan5/uRzo3Fm3t1rr1qYPQt++DSxfDnz2GZCdXfH25s3FwNlzzwHNmpl2L2RUecVleGjFEVxOzdMcG9TeB18/EQmFvOn9ciMjvwTDPjuANElA8ctHu2F4Z38L7oqIiIhqi0E0AxhEI7JipaVio/HFi2uefePpCQwfLgbUBg8GXFxMu0cyjrNnxUDpiRO6x11dgWXLxKmczDasXEKCblAtJqZiELIqzZuLmZ3lZaA9ehivXDo1FfjkE3EwRH5+xdt9fMSSzVmzxK81NShlKjWmrYvGgasZmmMdAtyw6anecLZvur/MOHwtA4+tPqbpDedqb4NdL/ZHcHMny26MiIiIaoxBNAMYRCOyUidOiEGVs2d1jzdrBowfD+zbB1y7VvU17O3FDKbRo4GRIwE/P9Ptl+qmrEwcELBokfi51NChwNdfA8GccFcrpaVi9qa0DPTGjZrfXyYTS6SlvdUiImpXQpuQIPY7++abij3tAHEowmuviUMDHB1rfl2yGoIg4I1fz+HH47c0x/zdHbD12b7wdWtgAy5MYNnuy/j8L+3/UV2CPfDzU71hZ9MEStGJiIgaAQbRDGAQjcjKFBcDCxeKva9UKt3bHnxQ7Kfk5yf2i7p4Edi2Ddi+vWL/rMqwj5p1OXVKDJSeOaN73MNDHCowaRK/RsaSmgocO6YNqh0/Ljb3ryk3NzFDTdpfzdOz4nmxscD77wNr11YMigJAWBgwb574tbWzq/vzIYvTb6LvbKfAz7P6ICKAP0sBgFKlxqOrjuF43G3NsSfvDsMbw9pbcFdERERUUwyiGcAgGpEVOXZMDKpcvKh73MsL+OILMQPNUFAlJQXYsUMMqu3dW305W3g4MGoU+6hZQkkJ8O67wNKlFQOlo0YBK1ZwIqOpKZXAuXO6ZaCXL9fuGq1bawNq7doB330H/PBDxa8pIAat33gDeOQR/l1rBHadTcYzP5zUrBVyGVZPjsS9bX0suCvrk5RdhGHLDyC7UBtQXjs1CgP4OhEREVk9BtEMYBCNyAoUFQFvvSX2TlKrdW8bP14MoNVmUl9BAbB7txhQ27kTyMys+nxPT2DECG0fNUtOL2zsoqPFQOn587rHmzcHPv8cmDiR2WeWkpkpZqiVB9WOHQNycup3za5dgf/7PzGLtClMVG0CTt3KwiPfHEWJUvtv9btjOuKJXi0tuCvrtedCKmauj9Gsmzvb4fcX+7PklYiIyMoxiGYAg2hEFnbwIDBtGnD1qu5xX1+xdHPs2PpdX6kEDh8WA2rbtgHXr1d9PvuomUZxMfD22+L0Tf1A6bhxYuN5X1/L7I0qp1YDly7p9lY7fx6oyY8JvXqJwbNhwxgUbUTibxfiwa8OISO/VHNsZv9QvDk8woK7sn7v7DiPtYfiNOveYZ74fkbPJjm9lIiIqKFgEM0ABtGILKSgQCzv+vzzim/KH39c7IlVWc+l+pD2Udu2Tcy0qQ77qNXf4cNioFS/XNDbWwyUPvSQZfZFtZebK2YTlgfVjh7VzfQcMEAMng0YwL8rjUxOURnGrTiMa2naKatDOvhixWPdIWcwqEolShXGrTiMc4m5mmNz7m+DFwa2tuCuyBiKy1T441wKNsXE43R8NpTqJvU2yqKc7BS4t403JkS1QK+w5pDx/xwiMjIG0QxgEI3IAvbvF6fy6U8MDAgQpzGOGGGefdSlj9ro0WLfrr59AYXCPPtsqAoLxYDKp59WDJROnAgsXy72u6OGSxDE7M4LF4CQEKBzZ0vviEygVKnGlLXHcfi6NmDaJcgdPz3ZG452/HewJm5kFGDE8gMoKBV7BsplwI8ze6FnmJF/WURmcS4xB5ti4rH1VCJyi5WW3k6T19LTCeMjg/FQ9yCWShOR0TCIZgCDaERmlJcHvPoqsHJlxdumTgU+/liczGgJ+fm6fdRu3676fPZRq9o//4iBUv3yWT8/8es/erRl9kVEtSIIAl7b/B82xSRojgV6OOLXZ/vAx5VvVmtj2+lEvPjTac3az80Bv7/YH82cOam2IcgpKsP204n4KToe55Nyq78DmZ1cBgxo64PxUcG4r50PbBXsxUlEdccgmgEMohGZye7dwMyZwK1buseDg4FvvgEeeMAy+6oM+6jVXX4+8PrrYo8zfZMni8MjmjUz/76IqE6+3H8NH/6pLcV2tbfBL0/3QVs/VwvuquF65ecz+PmENiA5sJ0Pvp0cyVI0KyUIAo7G3sbG6Fv4/VyKzkANKRd7Gwzr5Ac/d0cz77DpOp+Yg/2X02CogtbLxR7jugdifGQwWnm7mHdzRNQoMIhmAINoRCaWkwO8/DKwenXF2556CvjgA8Ca/+7Vto+aTCb2URs1qun1Udu3D5gxA4iL0z0eGCgGSocNs8i2iKhudpxJwvM/ntKsFXIZ1k2NQv/WtZiWTDoKS5UY+flBXE8v0BybPyIC0/qFWnBXpC81txi/nEjApph43MwsNHheVEgzjI8MxvDO/nCyszHjDgkAUnKKsfkkv05EZBoMohnAIBqRCf32mxgoS0zUPR4SAnz7LTBwoEW2VS/JyWIfte3ba9dHbfRooE+fxtlHLTcXeOUVMVCmb8YMcSKnu7v590VEdXbi5m1MXHUMpZLMmyVjO2FijxYW3FXjcDE5F6O/PKR5bW0VMmx5ui86BfHfSUsqU6nx16U0bIqOrybDyQ7jugXh4chghPsww8kaqNUCjt7IxKbo+GozBkd2CcCEqGB0CXJnBigRVYlBNAMYRCMygdu3gdmzgQ0bKt723HPAkiWASyP4wbO2fdScnICwMO1HaKj285AQ8faG5o8/xDLdhATd4y1aiIHS+++3zL6IqM5uZhbgwa8O43ZBqebYrHta4fWh7Sy4q8bl+6M38X9bz2nWLT2dsPP5fnB1sLXgrpqm6+n52BQdj80nE5GRX/kvxthrq+Eo7123MSZeZyKuvra+rpgQFYwH7wpkX0IiqhSDaAYwiEZkZFu3Ak8/LU6+lGrVClizBrj7botsy+Rq20etMv7+uoE1abAtIACQW9EP7VlZwJw5wLp1FW97+mng/fcBV/ZMImposgtLMXbFYcRKyg2HdfLDFxO7QS5n1oaxCIKAZ/93ErvOav+vHNUlAJ890pXZMWZQWKrEb/8lY1NMPKLjsgyeVz71cVy3IPi5c5BGQ1OTKap2Cjnu7+CLCZHB6BfuxX/niEiDQTQDGESjeklKAiZMAG7eBPr1E0v2hg617h5fppKRATz/PPDTT7rHZTIxK23RooaZaVUXggBcuCCWfNakj1pN2NuL2Wr6GWzla3N+z+3YIZbpJifrHg8LE3vf3Xuv+fZCREZTqlTjidXHcOyGNqu2a7AHfnqyFxxsG2EpuoXlFJVh+PIDSMgq0hz7YFxnjI8KtuCuGi9BEHAmIQcbo+Ox40wS8ksqD6rY28gxtKMfxkcFo1eoJ4MqjUBxmQp/nEvBxuh4HInNNHheoIcjHo4US3UDPTgkopxaLSC/tPK/L0T6FDIZnO0bR+9BBtEMYBCN6mX4cGDXLt1jtrbAgAFiY/lRo8Tpk43dzz8Dzz4LpKfrHm/XTsw+693bMvuyFsnJ4vfJhQvAjRtAbKyYqZafb7zH8PSsPIMtLEz8HrQxwn9mmZnACy8A//uf7nGZTDy+eDHg7Fz/xyEisxMEAS//fAZbTmp7WAY1c8TWZ/vCy8Xegjtr3E7dysLDK49AeacBl4OtHDue64fWvszkNZasglL8eioRG6PjcTk1z+B5HQLc8EhUMEZ1CYS7E8tqG6ubmQX4OSYBP5+IR2pu5eW7MhnQL9wLj0S1wKAIH9jbNJ1fIpSp1LiWlo9ziTk4n5SL80k5uJCUi4JSlaW3Rg1Ep0B37Hi+n6W3YRQMohnAIBrV2d69Nev31K2bmKE2ahTQpUvjmtSYmioGzzZv1j0ul4uN5hcsABxY/lApQRCDUrGx2sBa+ceNG8CtW4DKSD+wKBRAy5aGs9iaN6/++3LzZuCZZ4C0NN3jbdqIgdK+fY2zVyKyiOX7ruLjPVc0a1cHG/z6TB+E+zCYY2pf/3MdS36/pFm39XXFtuf6MvuvHtRqAQevZWBjTDz2nE9FqaryRvNuDjYYc1cgxkcGo2MgBzs0JUqVGv9eTcfG6Hjsu5imCWTra+ZkiwfvCsKEqGC09Wtc/x4Wl6lwKSVPJ2B2KSVPZ6AMUW0xiNYEMIhGdaJSAd27A2fOiGu5HHB0BAoKqr5fy5ZiMG30aLE3mG0D/U2nIIjZSC+8ULGZfocOwNq1QFSUZfbWWJSVAfHxuoE1aaCtuiEGteHmZnjggZOT2Pvs55917yOXi8cXLhS/94mowdp6KhGzN57WrG3kMqyf1gN9wr0st6kmRK0WMGVdNP69os3mfrRnC7z3YCcL7qphSswuws8x8fg5JgGJ2UUGz+sd5okJUcF4oKMfg5WE9LwSbDmZgI0x8Tr9IPV1DfbAhKhgjOwSAJcGVq6WV1yGC0m5OJ+Ui3NJOTifmItr6flQGRpDS1RHDKI1AQyiUZ189x0wZYp2PXMmsHw5sG+f2ANr+3YxS6sq7u7AsGENr49aUhIwa5bYF0tKoQDmzQP+7//E/l1kWjk5lWewxcYCcXFAaWm1l6iziAgx+6xnT9M9BhGZxfEbt/H4t8d0MnU+eKgzxkc2gVYEViQjvwRDPzuA9DxtedmXj3bD8M7+FtxVw1CiVGHvhTT8FH0LB69lwNA7GV83ezzUPQjjI4PR0pOtB6giQRBw4mYWNkbHY+d/ySgqq7wiwNFWgRGd/TEhKhjdWzazumEgmfkldzLLygNmOYjLLKz1dRxs5Wjv74aOAe4I83aGDfsDUg00d7ZvNP93MYhmAINoVGuFhWIJW+KdvjHOzsDVq+JkxXJqNXD8uLax/IULVV+zIfRREwRxEuNLL4kBHKkuXcTss7vussjWSI9KJQY7DZWK6k9OrSmFAnjtNWD+fAZKiRqBGxkFePCrQ8guLNMce25AOOYOaWvBXTVdh65l4PHVxzRBIFd7G+x6sT+CmzeRoTy1dDklDxuj4/HrqQRkSb6HpWzkMgxs74MJUcG4u7U3bBRWNOWarFpecRl2/peMjdHxOB2fbfC8Vt7OmBAVjLHdgszeP1IQBKTkFuN8ohgsO5eYiwtJOUjKKa71tVwdbNAhwA0dAtzRMVAMnIV6OfPvDDVpDKIZwCAa1drixWK2Vbl33hGDClW5dk0Mpm3bBhw6JAbZqmJtfdTi44EnnwT++EP3uK0t8NZbwOuvN9zS1KaooEDMVqssyBYbCxRVUgLTqZMYKO3e3ezbJSLjyyooxYNfHdLJThjZJQCfTejKaYQWtGz3ZXz+1zXNukuwB35+qjfsbPhGFgDyS5TYcSap2sBGmLczJkSKgQ1vV/7Sh+rHGgK2arWAW7cLNdll5xLFhv+ZBbWvPPBysUOHAHd0CHBDx0B3dAxwR3BzR6vLqCOyNAbRDGAQjWolNRUID9dOVfT3F7PQajORMCMD+O03MaD2559iZltVLNlHTRCAVauAuXOBPL2JVt27i0GVTuzZ0qgIgjg8oDygduuW+D0/ejRgZ2fp3RGREZQoVXj822OIjsvSHIts2Qzfz+jJ/lAWplSpMXHVUZ2vzVN3h2HesPYW3JVl1abEbvidErtIKyyxo4avvHR4Y0w8DlxNr7J0+OHuwRgfGYwWnrXPJFWq1LieXoDzd7LLyidk5pUoa32tQA9H3QyzQHf4uNrz7wdRDTCIZgCDaFQrTz8NrFypXa9eDUybVvfrFRWJfdS2b7e+Pmo3boi93vbt0z1uZydm382dC9g0rKaqRERNnSAImL3xNLadTtIca+nphF+f6YvmzgyUW4Ok7CIMW35Ap8x27dQoDGjrY8FdmV9G/p1m79HxuF5Fs/cuwR54JCoYIzr7w9WBWfFkHglZhfjlREKNhlg80iMYQzpUPsSiRKnClZR8TXbZ+aRcXEzORUkdJmSGeTkjQpJd1iHADc347zpRnTGIZgCDaFRjFy4AnTuL/aYAMQPr1CmxT5QxlPdRKy/7vHix6vNN1UdNrQa++kos0dSfNtqrl9hQvn3T/Y04EVFD9vHuy1guKRd0d7TFr8/0QZi3iwV3Rfr2XEjFzPUxmnVzZzv8/mJ/+Lo5WHBXpqdUqfHv1XRsjI7HvotpUBqYHOjhZIuxdwVhQlQw2vq5mnmXRFoqtYBD1zKwMSYee86n6gxpkXJzsMGYuwIxoJ0PbmYU3CnLzMXV1DyD3+eGKOQytPZx0ckua+/v1uAmhhJZOwbRDGAQjWps5Ehg507t+s8/gcGDTfd4V69qBxPUpo/a6NFisK8uadrXrgHTpwP//qt73MEBWLQImD3beEFDIiIyq19OJGDuz2c0a1uFDN9P74meYZ4W3BUZsmD7eaw7HKdZ9w7zxPczekLRCHvW3cosxKaYePx8Ih6puSWVniOTAf3CvTAhKhj3R/jC3oY/j5B1ySooxa+nErExOh6XU/Oqv0MN2NmIEzI7BIjN/jsGuqGNrytL74nMgEE0AxhEoxr56y9g4EDtesiQik32TSk9XdtHbfdu4/dRU6mA5cuBN9+s2FS+f3+xbLV16/o9ByIispjD1zMwec1xlKm0P+Z9MqELHrwryIK7oqqUKFUYt+IwziXmao7Nub8NXhjYOP4/Li5T4c/zKfjpeDyOxGYaPC/QwxEPdQ/Cw5FBCGrGSaVk/QRBwJmEHGyMjseOM0nIr2EvMxd7G0QEaANmHQLd0MrbBbackElkEQyiGcAgGlVLrQYiI8XSTQCQy4HTpy3XUL+8j9q2bcCOHdX3UfPwEPuojRpVeR+1S5fEvm5Hjuged3ICli4Fnn1WfM5ERNQgXUvLx9ivDiG3WPtGbvag1pg9qI0Fd0U1cSOjACOWH0BBqdhKQi4DfnqyN3qENrfwzuruXGIONsXEY+upRJ3vSSlbhQyDI/wwISoYfcO9GmX2HTUNhaVK/PZfMjbFxOsMDGnubKfT8L9DgDtaNnfidGQiK8IgmgEMolG1NmwAJk3SrqdPB7791nL7kVKrgWPHtGWfNe2jNnq0GFjbtAmYPx8o0SudGDBAfI5hYabbOxERmVxmfgnGfHUI8be1WcYP3hWIj8d34XS2BmLrqUTM3nhas/Z3d8CuF/o3qIbhOUVl2H46ERtj4nUy6/S19XXF+KhgPHhXIAddUKNzK7MQCVmFCPFyhr+7A/8NJrJyDKIZwCAaVamoCGjTBkhIENdOTmKvsoAAy+7LkKtXtYMJDh+uvo+aPhcX4MMPgSefZPYZEVEDV1ymwqOrjuLkrWzNsR6hzbFheg/2k2pgXvn5DH4+kaBZD2zng28nR1r1m3BBEHA09jY2xcRj19lkg9MGne0UGNU1AOMjg9E12MOqnxMRETUdNY0VcaQHkdSnn2oDaADwyivWG0ADxL5lc+eKH7XtozZ4MLBqFdCihXn2SkREJqNWC3j55zM6AbQwL2d880R3BtAaoHdGd8DJW1m4ni5Ozd53KQ1rD8VhWr9QC++sotTcYvxyIgGbYuJxM9Pwzx6RLZthfFQwhnfyhzOnChIRUQPFTDSicmlpQHg4kHdnuo6fn5jp5eJi2X3VRVERsHevto9aWpr2Nnd34OOPgalT6zbRk4iIrM4Hf1zCV39f16ybOdni12f6IsTL2YK7ovq4mJyL0V8eQumdjC5bhQxbnu6LTkHuFt4ZUKZS469LadgUHY/9l9OgNvBuwsvFDuO6BeHhyGCE+zTAn6eIiKjJYCYaUW298442gAYA777bMANoAODoCIwcKX6U91HbtQtQKsXBAUGczkZE1FhsjL6lE0CzU8ixalIkA2gNXHt/N8wfEYH/23oOAFCmEvDcjyex8/l+cHWoZgq3iVxPz8emmHhsPpGIjPySSs+Ry4B72/pgfGQwBrb34aRBIiJqVJiJRgSIEys7dgRU4jQsdOwoTuRUsASGiIis18GrGZiy9jiUklSgzx7pitFdAy24KzIWQRDwzA8n8fu5FM2x0V0D8OmErmbrJVZYqsSusynYGH1LZ9qgvhbNnTA+MggPdQ+Gn7uDWfZGRERkLDWNFVn8V0NfffUVQkND4eDggO7du+PAgQNVnv/ll1+iffv2cHR0RNu2bbF+/Xoz7ZQatdde0wbQALHZPgNoRERkxa6k5uHp70/oBNDmDm7DAFojIpPJsHRcZwQ1c9Qc23Y6CT/HJFRxr/oTBAGn47Mxb8tZ9Fi8D3N/PlNpAM3ORo4xXQPwv5k98ffce/Hcfa0ZQCMiokbNouWcGzduxOzZs/HVV1+hb9+++PrrrzF06FBcuHABLSppdr5ixQrMmzcPq1atQlRUFI4fP46ZM2eiWbNmGDlypAWeATUKf/8NbN+uXd9/PzBkiMW2Q0REVJ30vBJMXRuNvBKl5thD3YPw7IBwC+6KTMHd0RbLJ96F8SuPaAKm87efQ7eWHgj3cTXqY2UVlOLXU4nYFBOPSyl5Bs/rEOCGCVHBGN0lEO5OliktJSIisgSLlnP27NkT3bp1w4oVKzTH2rdvjzFjxmDJkiUVzu/Tpw/69u2LDz/8UHNs9uzZiImJwcGDB2v0mCznJB1qNdCjB3DihLiWyYBTp4AuXSy7LyIiIgOKSlV4ZNVRnInP1hzrHeaJ76b1gJ2NxYsMyERW/nMdS3+/pFm39XXFtuf6wsG2fpnzarWAQ9cz8FN0PPacT0WpSl3pea4ONhjTNRATooLRMdDyww2IiIiMyeoHC5SWluLEiRN4/fXXdY4PHjwYhw8frvQ+JSUlcHDQTRF3dHTE8ePHUVZWBlvbir8JKykpQUmJtvFpbm6uEXZPjcaPP2oDaAAwZQoDaEREZLXUagEvbTytE0Br5e2MlY93ZwCtkXuyfxgOX8/Ev1fSAQCXU/OwcOcFvPdgpzpdLzG7CD/HxOPnmAQkZhcZPK9XWHM8EtUCD3T0q3fAjoiIqKGzWBAtIyMDKpUKvr6+Osd9fX2RkpJS6X2GDBmCb7/9FmPGjEG3bt1w4sQJrFmzBmVlZcjIyIC/v3+F+yxZsgTvvPOOSZ4DNXBFRcAbb2jXjo7iRE4iIiIr9f4fl/DHee3PSZ7Odlg7pQdL6poAuVyGj8d3wdDPDiA9T/wF8f+O3ULfVl4Y3rniz8CVKVGqsPdCGjbGxOPA1XQYqkfxdbPHQ92D8HD3YE55JSIikrBoTzQAFSYLCYJgcNrQW2+9hZSUFPTq1QuCIMDX1xdTpkzBBx98AIWBJvDz5s3DnDlzNOvc3FwEBwcb7wlQw7V8OXDrlnY9dy4QyGbMRERknX44dhNf/xurWdvbyLFqciRaeDpZcFdkTl4u9vh0Qlc8vvqYJgD2+ub/0DnIHcHNDX8fXEnNw8boeGw5mYCswrJKz7GRy3BfOx880iMYd7f2ho2CmY1ERET6LBZE8/LygkKhqJB1lpaWViE7rZyjoyPWrFmDr7/+GqmpqfD398c333wDV1dXeHl5VXofe3t72NvbG33/1MClpwPvvadd+/oCr7xiuf0QERFV4Z8r6Zi/7bzOsY/Hd0W3Fs0stCOylL7hXnhuQDg+/+saACCvRInnfjyFX2b1hq0k8JVfosSOM0nYGB2P05LyX31hXs6YEBWMsd2C4O3Kn5mJiIiqYrEgmp2dHbp37449e/bgwQcf1Bzfs2cPRo8eXeV9bW1tERQUBAD46aefMGLECMjl/G0Z1cLChYC0P97ChYCrcSdcERERGcOllFw8+8NJqNTa2rvXh7arcQkfNT4vDmyNo7GZiI7LAgCcic/GR39exutD2+HEzSxsjI7Hb2eTUViqqvT+jrYKDO/sjwlRwYhs2cxgFQgRERHpsuh0zo0bN+KJJ57AypUr0bt3b3zzzTdYtWoVzp8/j5YtW2LevHlITEzE+vXrAQBXrlzB8ePH0bNnT2RlZeHjjz/Gnj17cOLECYSEhNToMTmdk3D5MtCxI6BUiuuICODMGcDG4tXNREREOlJzi/Hgl4eQlFOsOTaxRzDee7ATAx9NXFJ2EYZ+dgA5RdryzBBPJ8RlFhq8T5dgD0yIDMbILv5wdWAfPSIionJWP50TACZMmIDMzEwsXLgQycnJ6NixI3bt2oWWLVsCAJKTk3FL0rNKpVJh2bJluHz5MmxtbTFgwAAcPny4xgE0IgDA669rA2gA8OGHDKAREZHVEARBk020879kFJVps4n6t/bCwtEdGUAjBHg44qOHu2Dm+hjNscoCaB5OtnjwrkBMiApGOz/+ApmIiKg+LJqJZgnMRGvi/v0XuOce7XrgQGDPHoBvRoiIyMIy8kuw5WQCNkbH43p6QYXb2/i64Jen+8CNGUQksWD7eaw7HKdzTCYD+oV7YUJUMO6P8IW9TeUDuIiIiEjUIDLRiMxKrRYncJaTyYCPPmIAjYiILEapUuPfq+nYGB2PfRfToFRX/rvNMC9nrJkSxQAaVTBvWDskZBVh78VUBHo44qHuQXg4MghBzTi1lYiIyNgYRKOmY+NGIDpau540Ceja1WLbISKiputWZiE2xcTjlxMJSMktrvQcZhNRTdjbKLBqUncUlKrgZKuAXM5fDhIREZkKg2jUNBQXA/PmadcODsCiRZbbDxERNTnFZSr8eT4FG6Pjcfh6psHzAj0c8XBkEB7qzmwiqhmZTAYXe/5YT0REZGr835aahs8/B27e1K5ffhkICrLcfoiIqMk4n5SDTdHx+PVUInKLlZWeY6uQYXAHP0yIDEbfcC8omE1EREREZHUYRKPGLyMDWLxYu/bxAV57zXL7ISKiRi+nqAzbTydiY0w8ziXmGjyvra8rxkcF48G7AtHc2c6MOyQiIiKi2mIQjRq/d98FcnK063feAVxdLbcfIiJqlARBwNHY29gUE49dZ5NRolRXep6LvQ1GdgnAhKhgdAlyh4wDboiIiIgaBAbRyGKupOYh/nYh7m7jDVuF3DQPcvUq8NVX2nW7dsCMGaZ5LCt3Oj4becVl6B3mCRtTvd5EFlCmUuPgtQw0c7JD12APS2+HmqDU3GL8ciIBm2LicTOz0OB5USHNMD4yGMM7+8PJjj+CERERETU0/AmOLOLEzSyMW3EYADCxRzCWjO1smgd6/XVAKek/8+GHgE3T+7bfdTYZz/xwEgDwwn3hmDO4rYV3RGQ8S3+/hNUHbwAAnro7DK8PbcfMHjK5MpUaf11Kw6boeOy/nAa1UPl5Xi52GNctCA9HBiPcx8W8myQiIiIio2p60QSyCr+ciNd8vvVUEt57sJPx3/QePAhs2aJdDxgADB9u3MdoILadTtR8/sOxW3jp/jYMMlCjkF1Yig1HtENDvv43FiVKNd4eGcHvcTKJ2PR8bIyJx+YTicjIL6n0HLkMuLetD8ZHBmNgex/TZVsTERERkVkxiEYWcS0tX/N5UZkK2YVlaGbMhsqCIE7glProI6CJvqlOyi7WfJ5ZUIobGQUI82ZGBDV8O/9LRqlKt+/UusNxKFGqsXhMR8g54ZCMoLBUiV1nU7ApOh7H424bPK9FcydMiArGuG5B8HN3MOMOiYiIiMgcGEQjsxMEAVclQTQASMwuMm4QbdMm4Phx7fqJJ4Bu3Yx3/QYmKbtIZx0Tl8UgGjUKW04mVHr8x+O3UKpU44OHOkPBQBrVgSAI+C8hBz9Fx2PHmSTklygrPc/ORo5hHf0wPioYvUI9GbglIiIiasQYRCOzyywoRXZhmc6x5JxidAx0N84DlJSIvdDKOTgAixYZ59oNUHGZCpkFpTrHouNuY3xUsIV2RGQcsen5OHkrW7PuGuyBs4k5UN1pTrX5ZAJKVWp8PL4Ly+moxrIKSvHrqURsionHpZQ8g+d1CHDDhKhgjO4SCHcnWzPukIiIiIgshUE0MrtrelloAJCcU1TJmXX0xRdAXJx2/dJLQIsWxrt+A5OSU1zhWMzNLAvshMi4fj2VqLNeNKYjErIK8fyPp1CmEgNpO84koUypxvKJd8HOhoE0qpxaLeDQ9QxsjI7H7vOpFUqEy7k62GBM10BMiAo23i9+iIiIiKjBYBCNzK6yIFpitpGCaJmZulln3t66WWlNkH4pJwDcyChAWl4xfFzZs4caJrVawJaT2iBaOz9XdAhwQ8dAd6x8XI6nvz+pCYT8cT4Fs74/ga8e6wYHW4WltkxWKCm7CD/HJODnE/FIyDL8/1DvME9MiArGAx39+D1ERERE1IQxiEZmV2kmWnbFbKk6WbQIyM7WrhcsANzcjHPtBiqpkkw0ADgRl4WhnfzNvBsi4zh247ZO8H1st0DNNM6B7X3x7eRIzFwfgxKlGEj761IaZq6PwTdPRMLRjkGQpqxUqcbei6n4KToeB66mQxAqP8/XzR4PdQ/C+MhgtPR0Nu8miYiIiMgqMYhGZmeycs5r14Avv9Su27YFZs6s/3UbuGQDWX7RDKJRAyYdKCCXAWO6Burcfncbb6yb2gPTv4tGYakKAHDgagamrjuO1ZOj4GzP//6amqTsIqw5eANbTiXitl6fyHI2chnua+eDR3oE4+7W3rBhLz0iIiIikuC7CDK7yoJoScbIRJs3DyiTDCz44APAls2ekwwEKGNu3jbzToiMo6hUhV1nkzXr/q294eNWsTS5dytPbJjeA1PWRCPvzmTFo7G3MWnNcaydGgU3B/770BQUl6mw8p/rWPnPdRSXVd7rLMzLGROigjG2WxC8Xe3NvEMiIiIiaigYRCOzyisuQ0puxYBZSm4xVGoBCrmsbhc+fBj45Rft+p57gJEj67jLxsVQgPJ8Ui4KSpTMyKEGZ/eFFBTcyS4DxFJOQ7q3bI7vZ/TEE6uPIbdYDKSduJmFx789hvXTesDDyc7k+yXLEAQBu86m4L1dFyvtu+loq8Dwzv6YEBWMyJbNNOXARERERESG8N0zmVVlWWgAoFILSM8rgZ97HRrdCwLw8su6xz76COAbIgC6pbIu9jbIv5ORo1ILOB2fjb7hXpbaGlGd/HJCW8rpYm+DwRF+VZ7fJdgDPz7ZC49/ewxZhWK26n8JOXh01TFsmN4Dni7MPGpsLibn4p0d53E0tmLGbYcANzzWsyVGdvGHK7MRiYiIiKgW2OyDzMpQEA2ox4TOX34Bjh7Vrh97DIiMrNu1GiFpJtrgCF+d26LjWNJJDUtKTjEOXcvQrId38q/RoIAOAe746cne8JIEzC4k52LiqqNIyzPSYBOyuKyCUvzf1rMYvvxAhQCaj6s9Ph7fBTue64dHe7ZgAI2IiIiIao1BNDKra+mGg2h1Gi5QUgK8/rp2bW8PLF5ch501TrnFZZrMMwDoEOiOVt7aKXMxcVmW2BZRnW07nQi1ZJpiVaWc+tr6uWLjU73g66YNpF1JzccjXx9FioEpttQwKFVqfHc4Dvd+9De+P3pL53vETiHH0/e2wl9z78XYbkGQ17VtABERERE1eQyikVldl2SiBTVz1LktuS7DBb76CoiN1a5nzwZatqzj7hof/dc0wN0BUSHNNeuTt7KgVFXeaJvI2giCgM2SqZxBzRx1vp9ropW3CzY91RuBHtp/f2IzCjD+6yNIyCo02l7JfA5fy8Dw5Qfx9vbzyCkq07ltUHtf7H7pbrz2QDu4sP8jEREREdUTg2hkVlclQbQuQR5wc9C+qal1Oeft28C772rXnp7ihE7SSNJ7TQM8HBEpCToUlqpwMTnP3NsiqpPzSbm4kqr9N2TsXYF1yipq6emMjU/1QovmTppjt24XYsLXR3Ezs8AoeyXTi79diFkbTuDRb4/hcqruv2PhPi5YP60Hvp0ciRAvZwNXICIiIiKqHQbRyGyKy1SIv63N9Gjl44IASTZIrcs5Fy8GsiTliAsWAO7u9dxl45Kk95r6ezggKqSZzjH2RaOGQpqFBgBjuwXV+VpBzZyw6aneCJMEWBKzizD+6yO4XkXZOVleYakSy3ZfxsCP/8Ef51N0bnN1sMFbIyLw+4v9cXcbbwvtkIiIiIgaKwbRyGxuZBTo9KkJrxBEq0U5Z2ws8Pnn2nXr1sBTTxlhl42LtJzTViGDl7M9WjR3grertidUzE0G0cj6lanU2H46SbPu3rJZvTOM/Nwd8NNTvdDG10VzLDW3BBO+PorLKczQtDaCIGDb6UQMXPYPPv/rGkqV2lJ0mQyY2KMF/p57L6b3C4Wtgj/eEBEREZHx8adMMhv9yZytfVzg7+6gWeuXHlZp3jygTNL75oMPAFtOWtMnfU393R0hl8sgk8l0stGi47IgCEJldyeyGv9cTkdmQalmXZuBAlXxcXXAT0/2RoS/m+ZYRn4JHvnmCM4l5hjlMaj+ziXm4OGVR/DiT6cr/MIlKqQZdjzXD0vGdoKnZPoqEREREZGxMYhGZiPthyaXAaFezjqZaBn5pSguU1V/oSNHgE2btOv+/YHRo4251UZDWs4pDVhGttT2RUvPK8Gt22yoTtZtyyltKaedjRwjOgUY7drNne3wv5k90SVIWw6eVViGR1cdxZn4bKM9DtVeRn4JXt/8H0Z+cRAxN3WnCfu7O2D5xLuw6ane6BjIUn4iIiIiMj0G0chspJM5g5s7wcFWgQAPB51zUqor6RQEYO5c3WMffSTW8lAFSZJyTmnAUn+iYXSc7ptTImuSU1iGvRfSNOv72/vC3cm4maceTnbYMKMnurfUZmnmFivx2LfHEMO+gWZXplLj2wOxGPDR3/gpOh7SZFl7GzleuC8c+16+B6O6BEDGf/+JiIiIyEwYRCOzkZZzhnuLPYj83R11ztFvhF/Bli3A4cPa9cSJQI8eRttjY6JWCzpBSWnAsr2/K5zsFJo1gwRkzXb8l4RSlbb/lbFKOfW5Odhi/bQe6BWmDTLnlygxac1xHLmeaZLHpIr+uZKOBz79F4t+u4i8YqXObUM7+mHvnHswZ3BbONnZGLgCEREREZFpMIhGZqFUqXEjo0CzDr/TyDvQQzeIJm2EX0FpKfDaa9q1nR3w3ntG3WdjkllQqhN4kAYsbRRydGsh7YvGIBpZry2SqZxeLnYmnbrobG+DtVN6oH9rL82xwlIVpqw9jn+vpJvscQmIyyjAjO+iMXnNcVxPL9C5ra2vK/43sydWPN4dwc2dLLRDIiIiImrqGEQjs7h1u1AnoFOeiebr5qBTiVnlcIEVK4Dr17XrF18EQkKMvNPGQ/+11C+djZQMF7ieXoDM/BKz7IuoNm5kFODkrWzNelSXQJNPXnS0U2DVpEgMbOejOVaiVGPGdzHYdzHVpI/dFOWXKLHk94u4/5N/sPdims5tHk62eHd0B/z2Qj/0aeVl4ApERERERObBIBqZhf5kznAfMYhmZyOHl2SaWpKhnmhZWcDChdp18+bAG28YfZ+NSXKOfhBNN+tPvy/aiZvsi0bWR5qFBpiulFOfg60CKx7vjgc6+GmOlarUmPX9CfxxLtkse2js1GoBv5xIwICP/sbX/8SiTKVtfCaXAZN6t8Tfc+/FE71DYGPiwCkRERERUU3wp1Iyi2vplQfRAN3gjn7gR+O994DbkpLDt98GPDyMucVGJ0mvNFa//1zXYA8o5No0QP3Jd0SWplYL2HIyUbNu6+uKDgFuZnt8Oxs5vnj0Lozqop0EWqYS8Oz/TmHb6cQq7knVOR2fjbErDmPuz2eQnqebBds7zBO7XuyPhaM7wsPJzkI7JCIiIiKqiF15ySyupWqDaH5uDnB10E7WC3B3wJl48fNKyzlv3ACWL9euw8OBWbNMtdVGQ/paOtsp4Oag+9fd2d4GHQLc8F9CDgD2RSPrczzuNhIl38fjugeafRKjjUKOTyZ0hZ2NHL+cELPiVGoBszeeRqlSjYcjg826n4YuLbcY7/9xGZv1MgwBsUfm/w1vjwc6+nHiJhERERFZJQbRyCykmWjSLDRAN0Oq0sECb7whDhUo9/774lABqlKyzmROx0rflEa2bK4Jop1LzEFRqQqOkqmdRJa0+YQ20CKXAaO7mqeUU59CLsMH4zrDViHHj8dvAQAEAXjll/9QphLwaM8WFtlXQ1KiVGHtoTh8vu8qCkpVOrc52irwzL2tMPPuMDjY8t8fIiIiIrJeDKKRyQmCgOtphoNo0ob3eSVK5BaXwa08U+3YMeCnn7Qn9+0LPPigSffbWCRJSmP99fqhlYsKaYY1h24AEMvUziRko1eYp1n2R1SVolIVdp3V9h7r19obvm4OVdzDtORyGd57sCPsbeRYdzhOc/yNX8+iRKnC1L6hFtubNRMEAX9dSsO7Oy8gLrOwwu2jugTg9aHtKvRsJCIiIiKyRgyikckl5xTrZB5UDKLpvnlKzi6Gm5+tmOoxd67uxZYtA1jmUyPScs4A98qDD90lEzoBICbuNoNoZBV2X0jR+XdjnJkGClRFJpPh7ZERsLeR4+t/YzXH39lxAaVKNZ66p5UFd2d9rqXlY+HOC/j3SnqF2zoEuGHBqA4VBpwQEREREVkzBtHI5K4amMxZTj+IlpRThLZ+rsDWrcDBg9obJkwAevY01TYblTKVGmmSZt2Gsjx8XB0Q4umkyRCJjuNwAbIOv0hKOV3sbTA4wq+Ks81HJpPh9aHtYG8jx/K/rmmOL/n9EkqUarwwsLUFd2cdcovL8Nneq/jucByUakHntubOdnhlSFuMjwzWGWxCRERERNQQMIhGJnetuiCaXpZUcnax2APt1Ve1B+3sgCVLTLbHxiY1txiC5L2rv4FMNACIDGmuCaKdvJkFlVrgm1uyqJScYhy6lqFZD+vkZ1W9+mQyGeYMbgs7Gzk+2n1Fc/zjPVdQqlTj5cFtmmRjfJVawM8x8fjwz8vILCjVuc1GLsOk3iF4cVBruDvaGrgCEREREZF1YxCNTE4aRPNwsoWns+5QAC8Xe9gqZChTiVGfpOwi4OuvgWvaLA88/zwQyp5DNZWkN6Chqn5DUSHNNFk/eSVKXE7JQ0SAm0n3R1SVbacTIU1gGtctyHKbqcJz97WGvY0Ci3dd1Bz7Yv81lChVeGNY+yYVSIuJu40FO87jXGJuhdvubuON+SPaI9zH1QI7IyIiIiIyHgbRyOSkQwVa+7hUeGMpl8vg5+6A+NtiD6+k9BzgnXe0JzRrBrz5pln22lgkS4YKAFUH0SL1ehLF3LzNIBpZjCAI2HxSW8oZ1MzRqvtmzbw7DPa2cszfdl5zbNWBGyhRqrFgZAfIG3lWZ3JOEZb+fgnbTidVuK2lpxPeGh6Bge19mlRAkYiIiIgaLwbRyOSupuVpPtcv5Szn7+6oCaIln70KZGZqb5w/XwykUY3pZ6JVVc4Z5uWM5s52uH2n/Co6LguTeoeYcntEBp1PysWVVG3gfexdgVYfiJrUOwR2Cjnm/XpWU0a9/shNlCrVeO/BTla//7ooLlPh2wOx+HL/dRSVqXRuc7ZT4Ln7WmNavxDY21hPGS4RERERUX0xiEYmlZlfgqzCMs26lXflQTRpX7QkaRZVq1bAM8+YbH+NlXQyZ3NnOzjYGn4jK5PJENmyGXZfSAUARN+4DUEQmDlCFiHNQgOAB620lFPfIz1awM5Gjrk/n9GUov4UHY9SpRofPNQZNgq5ZTdYT6VKNa6m5eF8Ui7OJ+Zg36U0JGQVVThvbLdAvPZAO/i6GQ7cExERERE1VAyikUlVN1SgnLTcMNnFEwIAGQAsXSoOFaBakZZzBnhU/2Y2KqS5JoiWkluMxOwiBDVzMtn+iCpTplJju6QssHvLZgj1crbgjmpnbLcg2NnI8eJPp6G6E0nbcioRpSo1PpnQFbYNJJBWVKrCpZRcnLsTMDuflIvLKXkoVakN3qdLsAfeHhmBbi2YNUxEREREjReDaGRS19J1g2itfStvLO0vCaKV2tgh08kdXl0igHHjTLq/xkpazunvbrgfWrnIEN03vjFxWQyikdn9czldZ6rj2G6BFtxN3YzoHABbhRzP/e+kZljKzv+SUapU4/NH77K68sbc4jJcSMrFuTvBsvNJObiWlq8z2KEq3q72eO2Bdg2i7JaIiIiIqL4YRCOTuirpbeRkp9Ap25QKcLPXWSe5ecNr2TKAJYV1Ii2JNfSaS3UIcIeDrRzFZWKmSXTcbYy5q+EFMKhh23JKW8ppZyPHiE4BFtxN3Q3p4IdvnojEU9+fQKlS/Du1+0IqZm04gRWPd6+yvNqUMvJLcP5OwOxCUi7OJeXgZmZhra/jaKtARIAb+rf2wvR+oXB1sDXBbomIiIiIrA+DaGRS1yWZaK28K07mLBdw+hik345JQ0ajc+/ept5eo1RUqkK2pA9dVZM5y9nZyNE12ANHY28DEDPRiMwpp7AMey+kadb3t/eFu1PDDc4MaOeDNZOjMGN9tCY4vf9yOmZ8F4NVkyLhaGe6QJogCEjOKca5xBycS8rFhaQcnEvMRUpucfV31uPmYIOOge7oEOB25093hHo5Q8GsMyIiIiJqghhEI5OS9kQz1A8NZWUIeO9tYMRizaHkByeYemuNls5gBuiWylYlKqS5Joh2OTUPOYVlDTqIQQ3Ljv+SdHpuNcRSTn39Wnvhu6k9MG1dNApKxQmWB69lYPLa41gzJQou9vX/L1itFnDzduGdgFmOpjRTOtClprxc7NEp0A0dAtzR8c6fQc0cOWSEiIiIiOgOBtHIZPKKy5Cco818MBhE++YbuJ0/A6fBRSi0EwM+STYNp5m4tZFO5gRqVs4JAJEhzXXWJ27dxn3tfI22L6KqbJFM5fR0tsPdbbwtuBvj6RnmifXTe2LKmuPIK1ECAI7fuI1Jq49h3bQecKtFKaRSpca19HycSxR7l51PzMWF5Fzk37lubQQ1cxSzywLcNZlmPpyoSURERERUJQbRyGSupxforCsNouXkAAsWQAYgIDcd17xaAACScmpfdkSi5Gzd164m5ZwA0K2FB+QyaBqKR8dlMYhGZnEjowAnb2Vr1qO7BjaYSZY10b1lM/wwsyeeWH0cOUVihtjJW9l4bNUxbJjeAx5OFScQF5epcDklD+eS7jT8T8zBpZQ8lCgNT8isjEwGhHo53wmWidllHQLcKn1MIiIiIiKqGoNoZDLSUk7AQBBt6VIgIwMA4J+XoQmiJetlU1HNScs55TLAx9W+irO1XB1s0c7PDReScwEAMXG3TbI/In3SLDSgcZRy6usc5IEfZ/bC46uP4fadCaRnE3PwyDdH8c0TkUjJLcb5O73Lzifl4GpaPlQ1HZF5h41chta+ruio6V/mhvb+bnA2QtkoERERERExiEYmJA2i2SpkaNncSfeEW7eATz7RLAMEbQZVUjYz0epKWs7p6+YAm1pk9ESFNNME0c7E56C4TGWxSYINWVxGAf5v6znIZMCSsZ0Q1Myp+js1UWq1gC0nEzXrtr6u6BDgZsEdmU5EgBs2PtkLj357DOl5JQCASyl5uPvD/bW+loOtHO383DTZZR0D3NHGzwX2Nvz7SkRERERkKgyikclIg2ihXs4VgzlvvgmUlGiWAX0jgWTx87S8YihV6loFgEgk7UNX01LOcpEhzfHdkZsAgFKVGucScyr0SqPqvbvzAg5eEzMsn//xFLY83YfN2Q04HncbiZLA77jugY36tWrt64qNT/bCY98e0/m7WhVXextESLLLOga6I6yyf1OJiIiIiMikGEQjk7mWlqf5vEIp54EDwPffa9c9e8K/T3dg81kAYl+u1LwSBNYyCES6mWj+NRwqUC4ypJnOOjoui0G0WsorLsO/V9M161O3srH9TBJGd218JYrGIC3llMvQJF6nMG8XbHqqNyauOoqELN3SdU9nO3QoD5bd6WMW3MwJcnnjDSwSERERETUUDKKRSRSXqXDrdqFmHe4tCaKdPg2MHKl7h2XLEOChW/KWlF3EIFotCYKgUwpb20w0f3dHBDVz1LyxF/uitTLmFhu9A1czUKbS7WW19PdLuD/CF052/CdXqqhUhV1nUzTrfq294dtEJkQGN3fCr8/0xYajNyGXAR0D3NEh0A1+bg6NOhOPiIiIiKgh4zs6Mom4zAJIe2KH+7qKn1y6BAweLE7lLPfYY0DfvghI1x1EkMThArWWU1SGojKVZh1Qy0w0AIgKaY6ELLFHVczNLKjVArNgamHvhdQKx5JzivH1P7F46f42FtiR9dp9IQX5JUrNelwjHChQFW9Xe8zh9wQRERERUYPBhipkEhUmc3q7ADduAIMGAenaUjfcdx/w7bcAxCwoqZr2CyIt/YEM/nXI5JOWdOYUleGaXnCTDFOq1Pjrclqlt33973UGhvVslgwUcLG3weAIPwvuhoiIiIiIqGoMopFJXE3VBl5kMiBMmSsG0BK1b5rRqxewbRvgIGZLOdop0MzJVnMzAw61p/+aBbjXPogWpdcDLTrudr321JScvJWN7MIyzbpfuJfm8+IyNd7/45IltmWVUnOLcVDSO25YJz842nGyJBERERERWS8G0cgkpNlLwW72cHhgMBAbqz2hSxdg1y7ARXfggLSHl35WFVUvOUcviOZR+3LOcG8XuDtqg5kxcVn13ldTsfeibinnsvFd0DXYQ7PedjoJJ27y9QSAracSdUq+x3YLstxmiIiIiIiIaoBBNDKJ65JyztbX/gMuXtTe2LYtsHs30KxZhftJSzr1A0JUvSRJCay9jRzNne1qfQ25XIbIltqvDTPRak7aD61LsAd83Rzw9sgInXMW7jgPtVrQv2uTIggCNkumcgY1c0QPToElIiIiIiIrxyAaGZ1SpUZsRoFmHR57TntjSAiwdy/g41PpfaWZUyznrD3pa+bvXvcpf5GSgEZCVhEDmjVwPT1f5/v+/vbi9/hdLZrhwbu0DfPPJORg6+nECvdvSs4n5eKKpOR77F2BHF5BRERERERWj0E0Mrr4rCKUKtWadavMePETf38xgBZkuGxLWs6ZVViGolKVwXOpomRJCWxAHYYKlIsK0c0SZEln9fbplXIObO+r+fzVB9rC0Vbb7+v9Py6hQDKVsqmRZqEBwIMs5SQiIiIiogaAQTQyumtJ2Trr8Mx4wNNTDKC1alXlff3ddXt4MQOqdpJypJlodQ+idQpyh52N9p+HGJZ0VmvvBe1UzkAPR7Tzc9Ws/d0dMese7fd+am4JVv5z3az7sxZlKjW2n07SrLu3bIZQL2cL7oiIiIiIiKhmLB5E++qrrxAaGgoHBwd0794dBw4cqPL8H374AV26dIGTkxP8/f0xdepUZGZmmmm3VC21Gte+WqtzKLw0G/jzTyAiovL7SOhnT3G4QM2p1AJScqSZaLUfKlDO3kaBLkHumnU0M9GqlFVQipib2kDj/RG+FUppn7w7DAGSIPE3/8YiIavQbHu0Fv9eSUdmQalmPbZbYBVnExERERERWQ+LBtE2btyI2bNn480338SpU6fQv39/DB06FLdu3ar0/IMHD2LSpEmYPn06zp8/j59//hnR0dGYMWOGmXdOlRIE4JlncC1eG9T0zb8Nt19/Abp3r9ElKgTRmIlWYxn5JVBKGtbXp5wT0O2LdiklF7nFZfW6XmO2/3KazqTJge0r9vxztFPgtaHtNOsSpRpLf79kju1ZFWkpp51CjhGdAiy4GyIiIiIiopqzaBDt448/xvTp0zFjxgy0b98en376KYKDg7FixYpKzz969ChCQkLwwgsvIDQ0FP369cNTTz2FmJgYM++cKhAE4JVXgK+/xjXPFprD4cGeQL9+Nb6Mr6s9pP3Fk5mJVmP6gxj0S2NrSzotUS0Ap25l1+t6jdleST80F3sb9Az1rPS8UV0C0F0y+XTnf8lNavppTmGZTtnroAgfuDvZWnBHRERERERENWexIFppaSlOnDiBwYMH6xwfPHgwDh8+XOl9+vTpg4SEBOzatQuCICA1NRW//PILhg8fbvBxSkpKkJubq/NBJvDuu8CyZRAAXPfUNgkPb9fC8H0qYaOQw8eVEzrrQr/0tb6ZaN1aNIO0IpF90SpXolTh3ysZmvU9bb11+slJyWQyzB+hW9a8cMcFqKVpbI3YzrNJKFVph46M40ABIiIiIiJqQCwWRMvIyIBKpYKvr6/OcV9fX6SkpFR6nz59+uCHH37AhAkTYGdnBz8/P3h4eODzzz83+DhLliyBu7u75iM4ONioz4MAfPIJ8PbbAIAUV0/k2ztpbgr3dTV0L4OkvbxYzllz+kMY6puJ5u5ki7aSr19TypiqjWOxt5EvmbQ5qJJSTqkuwR46waOziTkVplU2VptPaJ+np7Md7m7jbcHdEBERERER1Y7FBwvoN98WBKHCsXIXLlzACy+8gPnz5+PEiRP4448/cOPGDcyaNcvg9efNm4ecnBzNR3x8vFH33+StWgXMmaNZXvXUzTwL93ap9SX9JRlUyTks56wpaSaaq4MNXB3qXyYXGaItPTwdn41SpbqKs5umfZJSToVchgFtqw6iAcCrD7SFk51Cs/7gz8s6gbjG6EZGAU5KSoJHdQ2ArcLi/wURERERERHVmMXewXh5eUGhUFTIOktLS6uQnVZuyZIl6Nu3L1555RV07twZQ4YMwVdffYU1a9YgOTm50vvY29vDzc1N54OM5Mcfgaee0jl0bdqzOutwn9oH0aQTDJOyiyAITaPUrb6kpa8B7vUr5SwXJemLVlymxvmkHKNct7EQBAF7L2p7fEW2bAYPJ7tq7+fr5oBn7m2lWafnleCr/ddMskdr8ateth1LOYmIiIiIqKGxWBDNzs4O3bt3x549e3SO79mzB3369Kn0PoWFhZDLdbesUIjZHAy0mNn27cATT4gDBcrNn49rHXtolu6OtvByqT6goE/ay6uwVIXcosadoWMs0nJOaUlsfUgndAJATFyWUa7bWFxMzkOiJHg5qH3lvwCozIz+YQiUfK9/e/AG4m8XGnV/1kKtFrD5ZKJm3dbXFR0C+AsNIiIiIiJqWCxaSzNnzhx8++23WLNmDS5evIiXXnoJt27d0pRnzps3D5MmTdKcP3LkSGzZsgUrVqxAbGwsDh06hBdeeAE9evRAQECApZ5G07N3L/Dww4BKpT02ezawYAGupeVrDrX2cTFYmlsVf70sKvZFq5kkSemrfz2HCpQL9HDUyQxkXzRd0lJOABgUUfMgmoOtAvOGtdOsS5VqLPn9otH2Zk2Ox93WCTaO7RZYp38biIiIiIiILMnGkg8+YcIEZGZmYuHChUhOTkbHjh2xa9cutGzZEgCQnJyMW7duac6fMmUK8vLy8MUXX+Dll1+Gh4cH7rvvPrz//vuWegpNz+HDwOjRQGmp9tiMGcDHHwMymU4QrS6lnEDFLKqk7CK092fWSlVKlCqk55Vo1oFGCqIBYjba9jNJAICYm1lV9i1savZKgmitvJ0R6uVcq/sP7+SP9SE3cfxOcHLX2RQcjc1ErzBPo+7T0rZISjnlMmDMXYEW3A0REREREVHdWLyr8zPPPIO4uDiUlJTgxIkTuPvuuzW3rVu3Dn///bfO+c8//zzOnz+PwsJCJCUl4fvvv0dgIN+QmcWpU8CwYUChpOTskUeAlSsBmQy3C0pxu0AbXKt7EE0/E43DBaqTmlOis67vZE6pKMlwgdsFpYjNKDDatRuy1NxinEnQ9oirTSlnOZlMhvkjIyCNSS7ccQEqdeMpTy8qVWHXWW3vy36tveHrZrzvTyIiIiIiInOxeBCNGoiLF4HBg4EcSWP5kSOB9euBO33ppFloQN2DaJ7OdrCz0X5rJmeznLM6+iWv+iWx9VGxLxpLOgHgr0tpOuvalHJKdQx0x8PdtU32LyTn4pcTjWeK8O4LKTqTR8d14y89iIiIiIioYWIQjap34wYwaBCQkaE9dt99wKZNgK2t5pCxgmgymUwnkyqJQbRq6b9GxiznbOPrClcHbeV3NIcLAAD2XtCWcjZzskW3Fs2qOLtqc4e0hbOdQrP+8M/LyCsuq9f+rIV0oICLvQ0GR/hZcDdERERERER1xyAaVS0xERg4EEhK0h7r3RvYtg1w0C3JupqWp/nc0VaBgHpkQ0nvy3LO6iXrvUa+7vZGu7ZCLkP3ltoAETPRxBLFg9e0QeUB7XygkNe9T5yPqwOevS9cs87IL8UX+6/Va4/WIDW3GAevpmvWwzr5wVESLCQiIiIiImpIGEQjw9LTxQy0Gze0x7p2BXbtAlwqZplJM9Fa+ThDXo+ggr8HM9FqQzr50MvFHvY2xg1URElKOuMyC5GW17QDmwevZaBEqdas769DPzR90/qGIri5Nni89mAcbmY27P5zW08lQtrebWy3IMMnExERERERWTkG0ahy2dnAkCHApUvaY+3aAbt3Ax4eld7luiSI1trHtV4PLy1HTM0throRNVo3BWnfuEAP4zdtj2ypW6p4oomXdEpLOe0UcvRv413vazrYKvDG0PaadalKjfd2Xaz3dS1FEARslkzlDPRwRA+9/npEREREREQNCYNoVFFBATB8uDiNs1xICLBnD+BdebAgv0SpU3ZZ135o5aSN8ctUAjLyS6o4m6TlnMYcKlCuS7AHbBXazMKm3BdNrRawTzJUoFcrT7jY21Rxj5p7oKMfeoZqA01/nk/F4esZVdzDep1PysWVVG1gfVy3wHplpxIREREREVkag2ikq7gYGD0aOHxYe8zfH9i3DwgyXIp1XW+oQCvvegbR9LKpElnSWSXp66P/2hmDg60CnQLdNeuYm023L9qZhGydoO797X2Mdm2ZTIb5IyMgk8SaFu64AFUDzMSUZqEBwIMs5SQiIiIiogaOQTTSKisDJkwQA2blvLyAvXuBsLAq72qsyZzl9KdL6jfOJ638EiXyipWatTEnc0pJ+6KdT8pFQYmyirMbr70XU3XWA43QD02qQ4A7JkQGa9aXUvKwMTreqI9hamUqNbaf1g4j6dbCA6FezhbcERERERERUf0xiEYilQqYPBnYvl17zM0N+PNPICKi2rtfS9cG0WwVMrT0dKrXdvzddbOpOFzAsGS918YU5ZwAECkJoqnUAk7HZ5vkcazd3gvaUs4IfzcEmCBo+fLgtjolost2X0ZucZnRH8dU/r2SjsyCUs16XHdmoRERERERUcPHIBoBggA8/TTw44/aY05O4hTObt1qdAlpJlqIpzNsFfX71nJ1sIWrJIiQlM1MNEP0S11NUc4JAN31hgtExzW9ks7424W4nJqnWQ+KMG4WWjlvV3s8f1+4Zp1ZUIrP9101yWOZgrSU004hx4hOARbcDRERERERkXEwiNbUCQIwdy6wapX2mJ0dsG0b0LdvjS8jDaLVt5SznDTDJzmHmWiG6Je6mqqcs7mznc7XNqYJDhfQL+W838ilnFJT+oboZHSuOxyHGxkFJns8Y8kpLNPJ1hsU4QN3J1sL7oiIiIiIiMg4GERr6hYuBD7+WLtWKIBNm4BBg2p8iRKlCjcztW/ujRVEk2ZUJbEnmkHSck4buQxeLvYme6yoEG022slbWVCq1CZ7LGskDaL5utmjY6CbyR7L3kaBN4a116zLVAIW/3bRZI9nLDvPJqFU8n0xjgMFiIiIiIiokWAQrSn7+GNgwQLtWiYD1q8Xp3PWQlxGIaTDA40WRJP09mJPNMMSJaWuvm4OUMhlVZxdP5EttX3RCktVuJicV8XZjUtucRmOxWpLWAe294VMZrrXGgAGR/iiTytPzXrvxVQcvJph0sesry0nEzWfezrb4e423hbcDRERERERkfEwiNZUffMN8PLLusdWrgQefbTWlzL2ZM5ygZJMtIz8EpQqm1bWU01JS11NVcpZTjqhEwCON6G+aP9cTodSEi02ZSlnOZlMhrdGREAaF12487zVZgDeyCjAiZvaMt9RXQPq3R+RiIiIiIjIWvDdTVP0v/8Bs2bpHlu2DHjyyTpd7mqaNhtJJgNaeRs/E00QgNRclnRWRtoTzVRDBcoFN3eEj6u2XDSmCQXRpKWcjrYK9JZkiJlSe383PNKjhWZ9JTUfP0bHm+Wxa+tXyUABgKWcRERERETUuDCI1tRs2wZMmiRGpcq9/TYwZ06dLynNRAtq5ggHW0V9dqihHxDSn0JJgCAIOqWu0sCjKchkMp1stOi4LAjS76VGqkylxv5L2mb5/Vt7Ge37vCZevr8NXB2002o/3n0ZOYVlZnv8mlCrBWw5pS3lbOvrig4BpusZR0REREREZG4MojUle/cC48cDKpX22Jw5YhCtHqRBtNY+rvW6lpR+aSIndFZ0u6AUJZIy10ATZ6IBQKRkuEBGfgluZhaa/DEtLSYuC7nFSs16UITpSzmlPF3s8eLA1pp1VmEZPtt31ax7qM7xuNtIyNL+HR3bLdDkPeOIiIiIiIjMiUG0puLQIXFgQGmp9tjMmcBHH4k1mHWkUguIzTD+ZE4A8HPXDQglZbOcU1+y3tRSU2eiARX7okU3gZJOaSmnTAbc187H7HuY1DsEoV7OmvX6I3EV+hFa0hZJKadcBoy5K9CCuyEiIiIiIjI+BtGagpMngWHDgEJJxtCjjwIrVtQrgAYA8bcLdRr+hxupHxoA2Nso4OVip1lzQmdF+iWupu6JBgDt/FzhbKctZYyJy6ri7IZPEASdINpdwR7wcrGv4h6mYWcjx5vD2mvWSrWA93ZdNPs+KlNUqsKusymadb/W3vB1M/33IhERERERkTkxiNbYXbgADBkC5OZqj40aBaxbByjq39OpwmROX+MF0QAgQFLSqZ91RUCyXhDN1NM5AcBGIUe3ltqSzuibjTsT7Xp6vk7JqrlLOaUGtvdB/9ZemvVfl9Lwz5V0i+2n3O4LKcgv0Za7juvGLDQiIiIiImp8GERrzGJjgfvvBzIytMcGDgQ2bgRsbY3yENfS9YJoRiznBAB/SUknM9EqkgYWHW0VcHc0zte1OpEttSWdsekFyMwvMcvjWsKeC2k660HtLRdEk8lkeGtEBOSSBNJ3d15AmUpt+E5msPmkdqCAi70NBkf4WXA3REREREREpsEgWmOVmCgGzJKStMf69BGnczoYr8xKmonm42oPNwfjBnGkPb4YRKtIWs7p7+FgtkbuUZLhAgAQc7PxlnTuk5RytmjuhNZGDhTXVhtfVzzWs6VmfS0tH/87dsti+0nNLcbBq9psuGGd/OBoZ77JpURERERERObCIFpjlJYGDBoExMVpj911F/Dbb4Czs8G71cVVSRDN2FlogG55Ym6xEgWSkjHSzUQzRylnua4tPKCQpEPFNNLhApn5JThxSxsgHNTe1yomTr50fxu4Odho1p/svYLswtIq7mE6W08lQi1o12O7BVlkH0RERERERKbGIFpjk50t9kC7dEl7rF074M8/AQ8Poz6UIAi4LgmimSJDR79RfnIOs9GkpD3R/N3N18jdyc4GHQPcNOvoRjpc4K9LaRAkAaJB7c0/lbMyzZ3tMHtQG806u7AMn+69avZ9CIKAzZKpnIEejuihN72ViIiIiIiosWAQrTHJzxencJ4+rT0WGgrs3Qt4exv94VJzS3SaiZsiE01azgkAidkcLlBOqVIjJVf7eui/VqYWKQmWnEvMQVGpyqyPbw77Lmr7obk62CAq1HoCRE/0bokwb21m6YajN3E1Nc+seziflIsrqdpA+thugZDLLZ+pR0REREREZAoMojUWxcXA6NHAkSPaYwEBwL59QKBpJuVdTdN9w97KxOWcQMVplE1ZWl6JThmdOcs5Ad2+aEq1gNPx2WZ9fFMrLlPhX0mvrwFtfWCrsJ5/Mm0Vcrw1PEKzVqkFLPrtoln3sEUyUABgKScRERERETVu1vOOkOqurAwYPx746y/tMS8vMQMtNNRkDysdKgCYJhPN29UeNpLMlqQcZqKV0y9t1S99NbXuLXWzshpbX7QjsZkolGTXDbSSUk6pAe18cE8bbZbpP1fSsf9SWhX3MJ4ylRrbTmuDaN1aeCDUy7g9F4mIiIiIiKwJg2gNnUoFTJoE7NihPebuDuzeDbRvb9KHlgbR3B1t4e1ib/THUMhl8HXTBoc4oVNLv7TV3OWc3q72OkGT6EY2oVM6ldNGLsO9bawviAYAb41orzPk4d3fLqBMpTb54/57JR2ZBdphBsxCIyIiIiKixo5BtIZMEIBZs4CfftIec3ICdu0Sp3Ga2DW9yZymmloYIMmw4mABLf3S1gAzZ6IBQGRLbUnnyZtZUEnrSxswQRCw94I2o6tHaHO4O9lacEeGhfu44oleLTXr2PQCbDhy0+SPKy3ltFPIMbJzgMkfk4iIiIiIyJIYRGvICguB8+e1azs7YNs2oE8fszy8ThDN2/ilnOWkGVbJHCygkSwpbfVwsoWTnY3Z9xAlGS6QX6LEpZRcs+/BFM4n5eoMbRjY3teCu6ne7EGt4SEJ8n269wpuS7LEjC2nsAx7Lmgz9QZF+FhtkJGIiIiIiMhYGERryJydxbLN++4DFArg55+BQYPM8tBZBaU6pVym6IdWTtrrKzG7CILQOLKd6itRkolm7lLOcpGS4QIAEBPXOEo690pKOQFgkBX2Q5PycLLDS4PaaNa5xUp8sueKyR5v59kklEpKRsfexVJOIiIiIiJq/BhEa+hcXIDffgP27AFGjTLbw15L1xsq4Gu6IJp06mSJUo2swjKTPVZDIi1tDbRAKScAhHo5w9PZTrOObiTDBaRBtDa+Lmjpaf0N8x/t2UInmP3DsZu4nJJXxT3qTlrK6elsh3vaeldxNhERERERUePAIFpj4OAADBhg1oesMJnTTOWcAIcLlJOWtloqE00mk+lko0XH3W7wmYLJOUU4l6gtS7X2Us5ytgo53hoRoVmrBeDdnReM/vW4kVGAE5IhEqO6BsBWwf9KiIiIiIio8eM7H6qTq6naIJqjrUInW8zY/N11s6wYRAOKy1Q65bT+FspEA3T7oqXmliAhq2F/ffZdTNNZD2ogQTQAuKeNN+5rpy09PXgto8Lzqa9fTyborMdxKicRERERETURDKJRnUjLOcO8nSGXm2YyJ4AKATppQ/2mSv81MGUQszqRkiAaAMTcbNglndJSTi8XO3QN9rDcZurgzeHtYSP5+7h410WUKtVV3KPm1GoBW05pSznb+rqiQ4CbUa5NRERERERk7RhEozq5LinnbG3CoQKAOHnSwVb7rZqU07AznYwhWS8bz1LlnADQIcBN5+sT3YCHCxSUKHH4WqZmPaCtDxQmDBCbQitvF0zqHaJZ38gowPojcUa5dnTcbZ1Mw7HdAiGTNazXh4iIiIiIqK4YRKNaKyhR6kyGNOVkTkDsuxUgCRIlZTMTLbFCEM1y5Zy2CjnuCtb2RYtpwMMFDlzN0Jk6OSii4ZRySr04sDWaOdlq1p/tu4rM/JJ6X3ezpJRTLgPG3BVY72sSERERERE1FAyiUa1d15/MaeIgGgAESMoV9bOwmiJpOadMBvhZMIgGAFGS4QJXUvORXVhaxdnWS1rKaWcjR//WXhbcTd25O9lizuC2mnVesRLL9lyp1zWLSlXYdTZFs+4b7gVfN8t+3xEREREREZkTg2hUaxUmc5ohiCbNtGJPNHGCZDkfV3uLT0fU74smnd7YUKjUAv66pG3C37eVJ5zsbCy4o/qZGBWMtr6umvVPx2/hYnJuFfeo2u4LKcgvUWrWD3XnQAEiIiIiImpaGESjWpMG0WzkMrT0dDb5Y/pLMtFScouhUgsmf0xrligpabVkP7Ryd7XwgLR1WEPsi3Y6Pgu3JRNPG2opZzkbhRxvjYjQrNUCsHDHBQhC3f7ubD6pHSjgbKfA4Ai/eu+RiIiIiIioIWEQjWpNGkQL8XI2SxZUoIc2E02lFpCW17Sz0aQlrZaczFnO1cEW7f21UxobYl+0PRfSdNYD2zXsIBoA9GvthUHttc/jSGwmdl9IreIelUvNLcbBq+ma9bBO/nC0Uxhlj0RERERERA0Fg2hUa9IgWri36Us5gYrZVk15uIAgCEiSBNEsOVRAKkpS0vlfQg6Ky1QW3E3tSfuhdQp0t3ifOWN5c3h72Cq0aYLv7bqIEmXtvjbbTidCmvw5jqWcRERERETUBDGIRrVSqlTj5u1Czbq1r3mCaAEeugGNpCY8XCC3WImCUm0QxN8KMtEAIFIyXKBUpcbZxBwL7qZ24jIKdILD0uythi7UyxlT+oRo1jczC7HuUFyN7y8IAjaf0JZyBno4oodeDzwiIiIiIqKmgEE0qpW4zAKdfmTmGCoAVMxEkzbWb2r0n3ugh3VkTEW21A2sRDegkk5pFhoADIrwsdBOTOP5ga3h6WynWX/+1zWk55XU6L7nk3JxOTVPsx7bLRByaQM8IiIiIiKiJoJBNKoV/cmcrcxUzulsbwN3R1vNuimXcybrPXdrGCwAAH7uDghurt1LTAMaLiANogW4OyBC0t+tMXBzsMXLg9tq1vklSizbfblG990iGSgAAGO7sZSTiIiIiIiaJgbRqFaupmqDaDKZ+YJoABAgKVtsyuWciXrP3d9KMtEAIEqSjRYTdxvqBjBFNaewTGea6MD2vpDJGl+m1YSoYLTzc9WsN8bE41w1JbdlKjW2ndYG0bq18ECol+mn8RIREREREVkjBtGoVq6la4NoQc0czTqhL0DS6D05pwlnoknKOe0Ucng521twN7oiJb2ycouVuKqXuWiN/r6SplOiPCii8fRDk1LIZZg/MkKzFgTg3Z0XIAiGA53/XklHZkGpZs0sNCIiIiIiasoYRKNascRkznLSjKsm3RNNUs7p5+5gVf2poiTDBYCG0RdtzwVtKaeznQK9whpv0/w+rbwwpIM2SHjsxm38cS7F4PnSUk47hRwjOvubdH9ERERERETWjEE0qjGVWkCsJBPNXEMFyknLOTPyS1Fcpqri7MZLWs7p7249pZyAWN7r4aTtXRdj5UG0UqUa/1xJ16zvbuMNexvzZVdawhvD2sNOof2nf/Gui5X+XcopLMMeSa+4QRE+8HCyq3AeERERERFRU8EgGtVYQlYhSpRqzdrsQTS9BvopTbSkU1rKGuhhHUMFysnlMkS21GajRVv5cIHouNvIK1Zq1oPaN85STqmWns6Y2i9Es07IKsKaQzcqnLfzbBJKJX/fx97FUk4iIiIiImraGESjGtOfzBnu42rgTNPQz7pKaoIlnWq1oBM8tKahAuWkfdESs4usegiEtJRTLgMGtPOx4G7M57kB4fBy0WaVffnXNaTl6galpaWcns52uKett9n2R0REREREZI0YRKMaqxhEs1w5JwAkZTe9TLSMghKUqrTZQf7u1pWJBgBRIbo9xWJuWmc2miAI2HdJG0Tr3rIZmjs3jXJFVwdbzB3cVrMuKFXhwz8va9ZxGQU4Ifm6jeoaAFsF/7sgIiIiIqKmje+KqMakQTRvV3u4O9pWcbbx+bk7QCbpoZ9sxRlOppKsFzi0tnJOAOgY6AZ7G+0/LdbaF+1Kaj7ib2u/h5pCKafUw5HBiPB306x/OZmAswk5AIAtJxN0zh3HqZxEREREREQMolHNXbXgZE4AsFXI4e1ir1knNcGeaPpTSa2xnNPeRoEuwR6atbX2RdsraZoPAAObWBBNIZfh7ZERmrUgAAt3nodaLWDLKW0pZxtfF3QIcKvsEkRERERERE0Kg2hUI4Ig4LokiNba1/xBNEC3pNOae22ZSqJeJpo1lnMCQFSIdrjApZRc5BaXWXA3lZMG0UK9nNHK29mCu7GMnmGeGNbJT7OOjsvCgh3nkZCl/bs1rlsQZNIUUCIiIiIioiaKQTSqkbS8EuSVaKcYmrsfWrkASeaVflZWUyAtYXWxt4Gbg40Fd2OYdLiAIAAnrawvWlpeMU7HZ2vWg9r7NNlA0byh7WEnKb9df+Sm5nO5DBhzV6AltkVERERERGR1GESjGrmaqjdUwALlnIBu5lVTHCwgnUjq7+5gtYGfbi2a6fSvi7Gyks79l9IgCNp1UyvllApu7oQZ/UIrva1vuBd83ayvZJiIiIiIiMgSGESjGrmWlqeztlwmmjaIll+itMoyQVOSBg79rXCoQDl3R1u09XXVrKOtbLjA3otpms/dHW0R2bJZFWc3fs8MCIe3q32F4xwoQEREREREpMUgGtXItXRtJpqbg02lb7jNIcBdNytGf1plYyctYQ20wqECUlGSks7T8dkoVaotuBut4jIVDlxN16zva+cDG0XT/qfQxd4Grwxpq3PM2U6BIR38DNyDiIiIiIio6Wna7xypxq5JJ3P6uFisjFA/+6opDRcoVaqRlleiWVvrUIFykZLhAiVKNc4l5VhwN1qHrmWguEwb0BvY3seCu7EeD3ULQucgd8169F2BcLRTWHBHRERERERE1oVBNKoR/SCapQToZV8lNaHhAqm5xTp9vPzdG04mGgDEWElJp7SU01Yhw91tvC24G+shl8vw9RPdMapLACZEBuO1B9pZektERERERERWpU5BtL///tvI2yBrll1Yioz8Us26tY9rFWeblpezPWwV2iy4plTOmZyj+1wDrbgnGiD2r5PuMdoKhguo1QL2XUzVrHuFecLNwdaCO7Iu/u6OWD7xLrz/UGe4O/J1ISIiIiIikqpTEO2BBx5Aq1atsGjRIsTHxxt7T2RlpFlogGUz0eRyGfwkGVhNqZxT/7la82CBctKSzpi42xCkqXQWcDYxR6ckdmA7lnISERERERFRzdQpiJaUlIQXX3wRW7ZsQWhoKIYMGYJNmzahtLS0+jvr+eqrrxAaGgoHBwd0794dBw4cMHjulClTIJPJKnx06NChLk+DasiagmgAECDpBdaUyjn1n6u1l3MCQKSkpDOrsAzX0wssuBvoZKEBwMD2vhbaCRERERERETU0dQqiNW/eHC/8f3v3Hh5lfef//zWHZHJOCDkwAyEgRARRq0ApKLqKslW/7Y+2W+m6qz1Ity62imht1R4s9irWrVS7rrRuta673eq2tl13tdvGEx7bCyweKqgBhCAZknDIgYScZu7fH5iZz9yBJCST3DP3PB/XlevKPbln5h0l5uLl+/15X3ut/vznP2vz5s2aNWuWrrnmGgWDQV177bV6/fXXh/U6jz76qFavXq1bb71VW7Zs0ZIlS3TxxRervr7+mPffc889CofDsY89e/aotLRUn/70p0fybWCY6owQLSfL6/gYYch4f/uIo5uZo6sT87OVk5X6h74vMDrRJOfPRas1zkM7ZVKhqkrzHKwGAAAAAJBORr1Y4EMf+pC+/vWv65prrlFHR4cefPBBzZs3T0uWLNFbb7016HPXr1+vq666SitXrtTs2bN19913q6qqShs2bDjm/cXFxZo0aVLsY/PmzTp06JA+//nPj/bbwCDMTrQZ5QXyep3ZzNnP7MAKt3QpGnV2RHC8mOOcwZLU70KTpJMrClWY449dO3ku2vuHOrUt3Ba7vpAuNAAAAADACRhxiNbb26tf/epXuuSSS1RdXa3f//73uvfee9XY2Kj33ntPVVVVg3aI9fT06NVXX9WyZcsSHl+2bJlefvnlYdXwwAMP6MILL1R1dfVx7+nu7lZbW1vCB05Mqmzm7Gd2ovVEojrQceJjxOmowei6M0daU5nX69H8auNctN3OdaI983ZTwvWFcwjRAAAAAADDN6IQ7Stf+YqCwaCuvvpqnXzyydqyZYteeeUVrVy5Uvn5+aqqqtIdd9yht99++7ivsX//fkUiEVVWJv5FtrKyUvv27RuyhnA4rN/97ndauXLloPetW7dOxcXFsY+qqqrhfZOQJHX29Gmv0QE1szwVQrTELqxwhpyLZn6foTRYKtDPPBdt94FONbU5M4JbuzV+Hlp5YUCnTy52pA4AAAAAQHoaUYi2detW/fM//7MaGhp09913a+7cuQPuCYVCevbZZ4d8LY8ncTTQsqwBjx3LQw89pJKSEi1fvnzQ+26++Wa1trbGPtgmemJ2NCUeBJ8KnWhBWxdWJmzo7OzpU0tnb+w6HZYK9FtghGiStHn3+I90tnf16o87D8Sul55S4fhYMgAAAAAgvfiHvmWgp59+eugX9vt13nnnHffrZWVl8vl8A7rOmpqaBnSn2VmWpQcffFBXXHGFsrOzB703EAgoEAgMWS+ObXtze8J1TaXzIZq9C6uhxf3LBezfYzp1op0+pVjZPq96IlFJ0qZdB3XJacFxreGFuv3qjcTPzuM8NAAAAADAiRpRJ9q6dev04IMPDnj8wQcf1Pe///1hvUZ2drbmzZun2trahMdra2u1ePHiQZ+7ceNGbd++XVddddXwi8aImOeh+b0eVU/Md7Cao4py/MrPjm+mzIRxTvv3aB9pTWU5WT6dNiU+OrnZgeUCTxmjnDlZXp09s2zcawAAAAAApLcRhWg/+clPdMoppwx4/NRTT9WPf/zjYb/OmjVr9NOf/lQPPvigtm3bpuuvv1719fW6+uqrJR0dxbzyyisHPO+BBx7QwoULjzlGiuQyQ7TqiXnK8o16oeuoeTweBY1OrMzoREsM0ewjralu/rT4coG3Glp1uLtv3N67LxLVM+/ElwqcM7NMuUYICwAAAADAcIxonHPfvn0KBgeOY5WXlyscDg/7dVasWKEDBw5o7dq1CofDmjt3rp588snYts1wOKz6+vqE57S2tuqxxx7TPffcM5LScYLqUmwzZ79QSW4s4GvIgE40Myj0eT2qKEyvEeUF1aX6iXZKkqKW9Fp9i86pGZ9usD/XtyScJ8coJwAAAABgJEYUolVVVemll17S9OnTEx5/6aWXFAqFTui1Vq1apVWrVh3zaw899NCAx4qLi9XZ2XlC74GR6emLaveB+D/rmopCB6tJFDIO1g9nQCeaOc5ZWRiQPwU6Ak/EvOoJCdebdh0ctxDtqW2NCdcXzK4Yl/cFAAAAALjLiEK0lStXavXq1ert7dUFF1wg6eiygZtuukk33HBDUguEc3Yf6FAkGj+MPZU60cxxxsb2LvVGoikxajpWzE60YBotFeg3IT9bNRUFsc7GzbsPjtt7myHaGVUlqihMn/PkAAAAAACpY0Qh2k033aSDBw9q1apV6unpkSTl5OToa1/7mm6++eakFgjnmOehSakVopkH61uW1NjWpSkT8hysaGyZI6vptJnTNH9aaSxE21LfMi7B547mw9rZ3BG7voguNAAAAADACI3ob7Aej0ff//731dzcrD/+8Y96/fXXdfDgQX3rW99Kdn1wUJ0tRDup3PnNnP3sQVK41b0jnZZlJYysmqOs6WSBsVygsyeibeG2MX/Pp22jnBfO4Tw0AAAAAMDIjKgTrV9BQYEWLFiQrFqQYsxOtCkTcpWXPao/LkkVtAVJ9u2VbtLS2asjvZHYtf17TxcLppUmXG/adUinTykZ0/d8alt8K+fkklzNqkydc/0AAAAAAOllxKnIpk2b9Mtf/lL19fWxkc5+v/71r0ddGJy3PUU3c0oDO9EaXLxcwL59NF3HOadMyFVlUUCNbd2SpM27Duqqc6YP8ayRO9TRo8274mevXTSnUh6PZ8zeDwAAAADgbiMa53zkkUd09tlna+vWrfrNb36j3t5ebd26Vc8884yKi4uTXSMcEIla2tFshGjlqRWi5WT5VJqfHbsOt7q3E82+fTRdQzSPx6P5Rjfapl2HZFnWIM8YnWffaZKxF0MXzmaUEwAAAAAwciMK0b73ve/phz/8of73f/9X2dnZuueee7Rt2zZddtllmjp1arJrhAP2Hjqi7r5o7LqmMrVCNClxrNHN45z2TrR0HeeUpAXV8XPR9h/u1u4DnWP2Xk8bo5yFAb8+PL10kLsBAAAAABjciEK0HTt26NJLL5UkBQIBdXR0yOPx6Prrr9f999+f1ALhjO3N7QnXqTbOKSV2ZLl6nNP43gJ+b0IHXrqZP+BctIPHuXN0uvsi2vhuc+z63FnlyvaP7SZQAAAAAIC7jehvlaWlpWpvPxqyTJ48WX/5y18kSS0tLersHLvOEoyf7bbNnDPLU+9AdnNLpavHOY3vLVSSm9bnep0yqVAFgfhRjJt3HRqT9/nTzoM63N0Xu76IUU4AAAAAwCiNKERbsmSJamtrJUmXXXaZrrvuOn3xi1/U3/7t32rp0qVJLRDOMEO0soKAivOyHKzm2IJGJ9qhzl4d6YkMcnf6MkdV03mUU5L8Pq/OnFoSu960e2w60Z7e1hj73Of16K9mlY/J+wAAAAAAMseItnPee++96uo6OmJ28803KysrSy+++KI++clP6pvf/GZSC4Qz6owQrSYFRzmlY2zobD2iGSm2ACEZzHHOdF0qYFowrVQv1O2XJO1s7tCBw92aWBBI2utblqWnjPPQ5ldPUEle+o7AAgAAAABSwwl3ovX19el//ud/5PUefarX69VNN92kxx9/XOvXr9eECROGeAWkOsuyEjrRUvE8NClxnFMauMXSDSJRS41tRoiW5p1okjR/WuJ/IzbvTu5I57Zwu/Ya3XsXzWGUEwAAAAAweiccovn9fv3jP/6juru7x6IepIDm9m61d8XPk0rZEM3eiebCDZ3N7d3qi1qx66ALOtE+VFUivzd+rtum95I70mmOckrSUs5DAwAAAAAkwYjORFu4cKG2bNmS7FqQIursSwVSNESrKAzIyGLU4MLlAvbvyQ3jnHnZfp06uTh2vSnJnWhPGSHajPJ8TS/LT+rrAwAAAAAy04jORFu1apVuuOEGvf/++5o3b57y8xP/knr66acnpTg4w76ZM1XPRPP7vKosylG49ei4oxvHOe3fkxvGOSVpQfUEvb6nRZL01t5Wdfb0KS97RP85StDY1qXX32+NXV/IKCcAAAAAIElG9LfWFStWSJKuvfba2GMej0eWZcnj8SgSceeWxExhhmiFOX6VFybv0PdkC5XkxkI0V3ai2UZU3TDOKUnzp5Xqpy++J0nqi1p6bU+LFs8oG/XrPvN2U8L1hYxyAgAAAACSZEQh2nvvvZfsOpBC7EsFPB7PIHc7K2h0ZrnxTDQzGCzK8asgMPpurVQwYLnArkNJCdGe2hof5ZyQl6WzprLoBAAAAACQHCP6G3l1dXWy60AKMc9Em1memqOc/cwzwsKtXbFuSLcwxzndcB5av7KCgE4qy9fO/R2SpE27Rr9c4EhPRC9u3x+7vuCUSvm87vmzAAAAAABw1ohCtIcffnjQr1955ZUjKgbOa+3s1f7D8c2rNZUpHqIZnWidPRG1HulVSV62gxUll9mJFnTJeWj95k+bEAvR/rz7kPoiUfl9I9p1Ikl6cft+dfdFY9cXzq4YdY0AAAAAAPQbUYh23XXXJVz39vaqs7NT2dnZysvLI0RLY9ub2xOuU3UzZz/7GWENLV3uCtFc2okmHT0X7b82vy9J6uiJ6O197ZprbO08UeYoZ7bPqyUnl4+6RgAAAAAA+o2o7ePQoUMJH4cPH9Y777yjc845R7/4xS+SXSPGkX0z58zyQocqGZ5QcWKwFHbRcoHuvkhCV6DbQrQF00oTrjePYqQzGrX0tLFUYNGMia45Pw4AAAAAkBpGPjtlU1NTozvuuGNAlxrSS11jPEQL+L2aPCG1g5tQSeKIo5uWC+xr7Uq4dts457SJeSoriHcNbtp9aMSv9fr7LQmBI6OcAAAAAIBkS1qIJkk+n08NDQ3JfEmMs+3N8RBtRnlByh/MXpqfrYA//se4wRY8pTNzlFNyXyeax+PR/Op4N9rmXQdlWdaIXuupbY0J10tnV46qNgAAAAAA7EY07/T4448nXFuWpXA4rHvvvVdnn312UgqDM8xxzlQ/D006GsQEi3O060CnJCnsok40+2iqfXTVDeZPm6D/e2ufJKmxrVvvHzqiqtK8E36dp7bGRzlPDRW5LnAEAAAAADhvRCHa8uXLE649Ho/Ky8t1wQUX6K677kpGXXBAZ0+f9hohVDqEaNLRDq3+EM3evZXO7KOplcUBhyoZO/Zz0TbtOnjCIdqeg516pzG+EIMuNAAAAADAWBhRiBaNRpNdB1LAzuYOmdN06RKiBY0OrQYXLRYwR1PLCwMK+H0OVjM25oSKlJvl05HeiCRp065D+uRZU07oNeyjnBcRogEAAAAAxkBSz0RDerNv5qxJkxDNXC7Q2NalSHRk52qlGnM0NeSypQL9snxenTm1JHY9kg2dZohWWRTQ3MlFySgNAAAAAIAEIwrR/uZv/kZ33HHHgMf/6Z/+SZ/+9KdHXRScYYZoPq9H1RPzHaxm+Mzzr3ojVsKWxnRmjqYGXXgeWr/5xkhnXdNhHeroGfZz27p69aed8eBt6exKeTypvQwDAAAAAJCeRhSibdy4UZdeeumAxz/60Y/q+eefH3VRcIYZolVPzFO2Pz0aFYO2Li37WWLpyhxNdfNB+QumTUi4fnX3oWE/d+M7zeozOg8Z5QQAAAAAjJURpSSHDx9Wdnb2gMezsrLU1tY26qLgjLqm+OHs6TLKKQ0MmMKt6b9coL2rV+1dfbFrc2TVbc6cOkFeo3ls0+7hj3Sao5y5WT4tmjExmaUBAAAAABAzohBt7ty5evTRRwc8/sgjj2jOnDmjLgrjrzcS1e4PNlxK6bNUQHJnJ5o9CHTzOGdBwK85ofg5Zpt3Da8TrTcS1bNvN8Wul9SUKSfLfcsXAAAAAACpYUTbOb/5zW/qU5/6lHbs2KELLrhAkvT000/rF7/4hX75y18mtUCMj90HOhLG4tIpRCvMyVJhjj/WuWWeJZau7EGgmzvRJGl+dan+svdoF+sb77eoqzcyZCC2edchtRndehfOYZQTAAAAADB2RtSJ9vGPf1y//e1vtX37dq1atUo33HCD3n//fT311FNavnx5kkvEeLBv5pxZXuhQJSMTMjq1wq3u60Rz85lokrTAWC7QG7H0xvutQz7HHOX0eKQLTqkYk9oAAAAAAJBG2IkmSZdeeukxlwsgPdU1JoZoMyrSYzNnv1BJjt5pPHqmmxvGOc3vwe/1qKwg4GA1Y2++bbnApl0H9eHppce5W7IsKyFEO7OqxPX/jAAAAAAAzhpRJ9qmTZv0pz/9acDjf/rTn7R58+ZRF4Xxt705HqJNLslVXvaI81VHBI1OrQYXLBYwR1InFefIZ56870KVRTmaWpoXu968a/DlAjuaDyec4ccoJwAAAABgrI0oRLvmmmu0Z8+eAY/v3btX11xzzaiLwvgzxznT6Ty0fiFjuUBze7e6+yIOVjN6ZidayMVLBUxmN9rm3YcUNc7os6vd2pRwfdFsQjQAAAAAwNgaUYi2detWnXXWWQMeP/PMM7V169ZRF4XxFY1a2tGc5iGa7cywxtZuhypJDvNct6DLlwr0M89Fa+/q07tN7ce992ljlHNqaV5a/pkFAAAAAKSXEYVogUBAjY2NAx4Ph8Py+9NrDBDS3pYj6uqNxq5r0jCQCNq6tRrSeLmAZVkJI6luXyrQzwzRJGnTrkPHvO/A4W69Wh//2oWzK+XxuHvcFQAAAADgvBGFaBdddJFuvvlmtbbGN+i1tLTolltu0UUXXZS04jA+BmzmTMMQLWTr1krn5QIHOnrU0xcPNc1RVTebUZ6vCXlZsevjnYv2zNtNsoxJzwvnsJUTAAAAADD2RtQ2dtddd+ncc89VdXW1zjzzTEnSa6+9psrKSv37v/97UgvE2HNDiDbJFjSF03i5QLglsXZ7l51beTwezZ9WqtqtR7tcNx+nE+3pbfHz0Apz/AM62AAAAAAAGAsj6kSbPHmy3njjDd15552aM2eO5s2bp3vuuUdvvvmmqqqqkl0jxpgZopUVZKskL9vBakYm4PeprCAQu07nTjT7KGqmjHNK0gJjucDeliPaa/v32NUb0fN1zbHr82dVKMs3ov+MAQAAAABwQkZ8gFl+fr7OOeccTZ06VT09PZKk3/3ud5Kkj3/848mpDuOizjjAPR270PqFSnK0//DRhQJpHaK12EO0zBjnlKT5tq6yzbsOavKHJseuX9l5QJ098c2rF85hKycAAAAAYHyMKETbuXOnPvGJT+jNN9+Ux+ORZVkJB3tHIpFBno1UYllWQidaWodoxbl64/2j5/Sl9TinUXtulk/FuVmD3O0uc0PFCvi96v7gTLjNuw7p/zNCNHMrp9/r0Xknl497jQAAAACAzDSiOajrrrtO06dPV2Njo/Ly8vSXv/xFGzdu1Pz58/Xcc88luUSMpebD3Wrr6otdzyxP3xAtaHRsuaUTLVSSk1GbJ7P9Xn2oqiR2vclYLmBZlp7aGj8P7cPTSzMqYAQAAAAAOGtEIdorr7yitWvXqry8XF6vVz6fT+ecc47WrVuna6+9Ntk1Ygxtb7QvFSh0qJLRCxkH8Ld19elwd98gd6euxBAtc85D62cuCninsV2tR3olSW81tGlfW7xL78LZjHICAAAAAMbPiEK0SCSigoKjHUtlZWVqaGiQJFVXV+udd95JXnUYc9ubE0O0msr07USzB07hNO1GM8c5g8WZcx5av/nGcgHLkv5cf3RL51PGKKdEiAYAAAAAGF8jCtHmzp2rN954Q5K0cOFC3XnnnXrppZe0du1anXTSSUktEGPLPA+tMOBXRWFgkLtTW9B2AH9DGp6L1heJqtHotsrETrSzqifInGDd/MFIpxminVxZoKkT88a7NAAAAABABhtRiPaNb3xD0ejRg7+/+93vavfu3VqyZImefPJJ/ehHP0pqgRhbZog2o6Igrc/fMsc5pfQ8F62xvVtRK35t/54yQVFOlk6ZVBS73rTrkMKtR/SXvW2xx+hCAwAAAACMtxFt5/zrv/7r2OcnnXSStm7dqoMHD2rChAlpHcJkojojRKtJ482cklReGJDf61HfBylUOo5z2mu2d9dligXTJmhb+Gho9vqeFv3uzX0JX19KiAYAAAAAGGcj6kQ7ltLSUgK0NNN6pFfN7d2x65lpHqL5vB5VFhkbOtNwnNNecyaOc0rSfGO5QHdfVD/euCN2XVaQnbDBEwAAAACA8ZC0EA3pxxzllNI/RJOkyUbolI7jnPaaM3GcUzraiWZqMsLeC06pkM9LYA8AAAAAGF+EaBlshwtDNHP8MZyGnWjmOGdJXpZys30OVuOcYHFuQiBqYpQTAAAAAOAEQrQMVtfUHvs84PdqyoT033YYLE7sRLMsa5C7U485zpmpXWj97N1okpTt92pJTZkD1QAAAAAAMh0hWgYzxzlPKi9wxYjcZKMTrbsvqoMdPQ5Wc+LMcc5Qhi4V6Geei9bvnJllysse0T4UAAAAAABGhRAtg21vjodobhjllBI70aT0G+k0683UpQL9FhwjRFs6u8KBSgAAAAAAIETLWEd6Inr/ULzraWa5S0I0W/dWOi0X6OqNJHTO2QPBTFNTUaCinMSus6WncB4aAAAAAMAZhGgZakfzYZnHhdVUuiNEsx9Gn04h2oDNnBk+zun1erTwpImx6zOmFGtScWb/MwEAAAAAOIfDhTLUjmb3beaUpOLcLOVm+XSkNyIpvcY57bVm+jinJK256GS9va9NfRFL3/rYHKfLAQAAAABkMEK0DGUuFfB5PZo2Md/BapLH4/EoWJKjnc0dkhK3XaY6eydakK4rzQ4W6fmvni/p6L9bAAAAAACcwjhnhjJDtOrSPGX73fNHwRzpTK9xznjg5/FIlUWEaNLR8IwADQAAAADgNPckJzghdU3u28zZz+zgCqdRiBZujddaWZijLB8/ngAAAAAApAr+lp6BeiNR7drfEbt2X4gW70RrbO9WXyTqYDXDZ46e2reMAgAAAAAAZxGiZaDdBzrVF42v5nRbiGaOc0ailpraux2sZvjM0dNQMUsFAAAAAABIJY6HaPfdd5+mT5+unJwczZs3Ty+88MKg93d3d+vWW29VdXW1AoGAZsyYoQcffHCcqnUH8zw0yX0hmr2LyxyTTFWWZSWMnoboRAMAAAAAIKU4up3z0Ucf1erVq3Xffffp7LPP1k9+8hNdfPHF2rp1q6ZOnXrM51x22WVqbGzUAw88oJkzZ6qpqUl9fX3jXHl6297UnnA9o9xlIZqti6uhpUvzqh0qZpjauvrU0ROJXdu/BwAAAAAA4CxHQ7T169frqquu0sqVKyVJd999t37/+99rw4YNWrdu3YD7/+///k8bN27Uzp07VVpaKkmaNm3aeJbsCmYn2uSSXOUHHP1jkHT2Lq502NBpr5FONAAAAAAAUotj45w9PT169dVXtWzZsoTHly1bppdffvmYz3n88cc1f/583XnnnZo8ebJOPvlk3XjjjTpy5PghSXd3t9ra2hI+Mt325niINsNlo5ySlJftV0leVuw6bBzYn6rsI6ehEjrRAAAAAABIJY61IO3fv1+RSESVlZUJj1dWVmrfvn3HfM7OnTv14osvKicnR7/5zW+0f/9+rVq1SgcPHjzuuWjr1q3Td77znaTXn66iUUs7muKbOWtcGKJJR8chWzp7JaVLJ1pi0Mc4JwAAAAAAqcXxxQIejyfh2rKsAY/1i0aj8ng8+vnPf64Pf/jDuuSSS7R+/Xo99NBDx+1Gu/nmm9Xa2hr72LNnT9K/h3Syt+WIjvTGz95y21KBfpONcciGNFgsYAZ92T6vJuZnO1gNAAAAAACwc6wTraysTD6fb0DXWVNT04DutH7BYFCTJ09WcXFx7LHZs2fLsiy9//77qqmpGfCcQCCgQCCQ3OLTmDnKKbk3RDM7ucIt6TDOGa8xWJIjr/fYQTIAAAAAAHCGY51o2dnZmjdvnmpraxMer62t1eLFi4/5nLPPPlsNDQ06fDgeBL377rvyer2aMmXKmNbrFjuabCGayzZz9gsanWgHOnrUZXTfpSKzEy1YzFIBAAAAAABSjaPjnGvWrNFPf/pTPfjgg9q2bZuuv/561dfX6+qrr5Z0dBTzyiuvjN1/+eWXa+LEifr85z+vrVu36vnnn9dXv/pVfeELX1BuLmdIDYe5mbOsIFsTXDo2ONl2MH+qLxcwR05DnIcGAAAAAEDKcWycU5JWrFihAwcOaO3atQqHw5o7d66efPJJVVdXS5LC4bDq6+tj9xcUFKi2tlZf+cpXNH/+fE2cOFGXXXaZvvvd7zr1LaSdOiNEm+HSLjRp4MH84ZYjml6W71A1g4tGLe0zQj42cwIAAAAAkHocDdEkadWqVVq1atUxv/bQQw8NeOyUU04ZMAKK4bEsK6ETza3noUkDRyIbUrgTbX9Ht3ojVuzaHEUFAAAAAACpwfHtnBg/+w/3qPVIb+zazSHapOIcmUtezTPHUk2DbfEB45wAAAAAAKQeQrQMUtfUnnBdU1HoUCVjL8vnVUVhfCtruDV1Q7SwLeBjnBMAAAAAgNRDiJZBBmzmdHEnmpR4Lpq92yuV2EdNGecEAAAAACD1EKJlEPM8tIKAX5VFgUHuTn/mhs7UHueM11YQ8KsoJ8vBagAAAAAAwLEQomWQ7c3GZs6KAnnMQ8NcyFwuEE7hxQLmqGmILjQAAAAAAFISIVoGqWuMh2g1Lh/llKSg0Yl2uLtPbV29g9ztHHPUNMhSAQAAAAAAUhIhWoZo6+pVU3t37Nrt56FJ0mRbV1eqjnSaddGJBgAAAABAaiJEyxDb7UsFyt0fotm7usIpuFygpy+q5sPxcDNEJxoAAAAAACmJEC1DDAjRMqATzb7lsqE19TrRGtu6ZFnxa3MEFQAAAAAApA5CtAxhhmjZfq+qSvMcrGZ8lOUHlO2L/xFPxXFOe02hYsY5AQAAAABIRYRoGcIM0U4qy5fP6+7NnJLk9Xo0ydzQmYLjnPatoSE60QAAAAAASEmEaBnCDNEyYZSzX9AI0VJxnNNe0yQ60QAAAAAASEmEaBmgqzeiPYc6Y9eZFKJNNjq7GlKwE80c55yYn62cLJ+D1QAAAAAAgOMhRMsAO5oPJxxeX1NR6Fwx48xcLrCvtUvRqDXI3ePPHDFllBMAAAAAgNRFiJYBMnEzZ79gcTyY6olEtb+j28FqBtprdKIFGeUEAAAAACBlEaJlgB1GiOb1SNPK3L+Zs99kW3dXqi0XMBcL0IkGAAAAAEDqIkTLANub4yHatIn5Cvgz59wtc5xTksIptFygo7tPrUd6Y9ehEjrRAAAAAABIVYRoGaCuMR6izcigUU5pYHfX3hTqRLMHeuboKQAAAAAASC2EaC7XF4lq14GO2HUmnYcmSUU5WSoI+GPX4ZbU6USzbwulEw0AAAAAgNRFiOZyuw92qjcS30g5szyzQjQp8cB+8wwyp9k70TgTDQAAAACA1EWI5nL2zZw1lZkXopnh1N4U6kQzR0t9Xo8qCulEAwAAAAAgVRGiuZw9RJuRgZ1o5phkKi0WMEdLKwsD8nk9DlYDAAAAAAAGQ4jmcmaIFirOUb5xPlimMA/sb2rvVm8k6mA1ceZoKaOcAAAAAACkNkI0lzNDtEzbzNnPDKgsS9qXIueiNRidaEFCNAAAAAAAUhohmotFo5Z2NMdDtJqKQgercU6oOPGssVRYLmBZlhqM0VJ7jQAAAAAAILUQorlYQ+sRdfZEYtczM7QTzd7llQrnorV09qqrNz5WyjgnAAAAAACpjRDNxexLBTI2RLN1eaXChk57DfYaAQAAAABAaiFEczFCtKNysnyamJ8duw63OD/OaR8ppRMNAAAAAIDURojmYuZ5aBPzs1VqBEmZJlgS7/RKhXFOew2EaAAAAAAApDZCNBera2QzZ79QcTyk2psCnWjmOGfA79WEvCwHqwEAAAAAAEMhRHMpy7K03ehEy9RRzn5mp1dKdKIZQV6oJFcej8fBagAAAAAAwFAI0VzqQEePWjp7Y9czyzM7RDMP7m/p7FVnT5+D1SQGeaESlgoAAAAAAJDqCNFcyhzllKSayswO0exnjjU4PNJpvn+wmPPQAAAAAABIdYRoLmWOckqMc9q7vZwc6YxELe1rM8Y5i+lEAwAAAAAg1RGiudSOpniIVhDwa1JRZgc19m6vsIOdaM3t3YpErdg1mzkBAAAAAEh9hGgutb0pcTNnph9cX1EYkM8b/2dgbsccb/b3DhKiAQAAAACQ8gjRXKquqT32eaYvFZAkv8+rysJA7NrJcU77ezPOCQAAAABA6iNEc6G2rl41tnXHrjP9PLR+ZsdXuNW5cU77KCmdaAAAAAAApD5CNBcyz0OTCNH6mWePpco4Z1GOXwUBv2O1AAAAAACA4SFEc6HtthCthhBNUuLYZLilS5ZlDXL32DHHOVkqAAAAAABAeiBEcyEzRMv2e1VVmudgNakjaIRoR3ojaj3S60gd5igpIRoAAAAAAOmBEM2FzBDtpLL8hK2UmcweWDk10tlgvG+QpQIAAAAAAKQFQjQX2t4cD9FmMMoZYw/R7Af8j4fuvoj2H+6JXdOJBgAAAABAeiBEc5mu3oj2HOyMXXMeWpy968s8m2y87LNtBQ2V0IkGAAAAAEA6IERzmZ3NHYoa5+WzmTOuND9bAX/8j/xeBzrR7COkwWI60QAAAAAASAeEaC5jjnJKhGgmj8eTMD7pRCeafYR0MuOcAAAAAACkBUI0lzGXCng90vSyfAerST3mSKcTZ6KZwZ3HI1UWMc4JAAAAAEA6IERzmR1GiFY9MV8Bv8/BalKP2YnmxHZOc4S0rCCgbD8/ggAAAAAApAP+Bu8ydU3tsc9nlDPKaRcyOtEa27oUMQ+QGwdmJxqbOQEAAAAASB+EaC7SF4nqvf0dsWvOQxsoaARXfVFL+w93j+v7myOkoWJGOQEAAAAASBeEaC5Sf7BTvZF4ZxUh2kD27q/xHulsMN6PzZwAAAAAAKQPQjQXMZcKSFINIdoA9u6v8Vwu0N7Vq/buvngtJXSiAQAAAACQLgjRXKTOFqLNIEQbIGjrRDPPKBtr4dbEwI4z0QAAAAAASB+EaC5ibuYMFueoIOB3sJrUVBDwqygn/s9lPMc57e8V5Ew0AAAAAADSBiGai2xvjodonId2fGYH2HiOc9rfazKdaAAAAAAApA1CNJewLCvhTDRCtOMzO8DGd5wz/l5ZPo/KCgLj9t4AAAAAAGB0CNFcoqG1S509kdg1IdrxmZ1oe8exE80c56wsypHX6xm39wYAAAAAAKNDiOYS9s2cM8sJ0Y7HDNH2H+5Wd19kkLuTxxznZKkAAAAAAADphRDNJewhWk1loUOVpL5QSeKB/o2t3ePyvuY4Z4ilAgAAAAAApBVCNJcwQ7TS/GyV5mc7WE1qCxYndoGNx4ZOy7LU0BrvRAvSiQYAAAAAQFohRHOJ7U3tsc8Z5RxcyBaijcdygQMdPerpi8ZrIEQDAAAAACCtEKK5hNmJNoOlAoOqLA7IY5zpH24d++UCYdsCA8Y5AQAAAABIL4RoLnDgcLcOdfbGrmsI0QYV8PtUVhCIXY/HOKf9PewjpQAAAAAAILU5HqLdd999mj59unJycjRv3jy98MILx733ueeek8fjGfDx9ttvj2PFqafOvpmTEG1IZidYeBxCNPvI6GTGOQEAAAAASCuOhmiPPvqoVq9erVtvvVVbtmzRkiVLdPHFF6u+vn7Q573zzjsKh8Oxj5qamnGqODXZN3MSog3NPJNsXMY5jffIy/apKNc/5u8JAAAAAACSx9EQbf369brqqqu0cuVKzZ49W3fffbeqqqq0YcOGQZ9XUVGhSZMmxT58Pt84VZyazBAtP9unIOdtDckcpxzvcc5gcY485qFsAAAAAAAg5TkWovX09OjVV1/VsmXLEh5ftmyZXn755UGfe+aZZyoYDGrp0qV69tlnB723u7tbbW1tCR9us6M5HqLNrCggoBmGUEk8aGzv6lN7V+8gd4+eOTLKZk4AAAAAANKPYyHa/v37FYlEVFlZmfB4ZWWl9u3bd8znBINB3X///Xrsscf061//WrNmzdLSpUv1/PPPH/d91q1bp+Li4thHVVVVUr+PVFDXyGbOE2UPssZ6pLPB2M4ZYqkAAAAAAABpx/GDmexdU5ZlHbeTatasWZo1a1bsetGiRdqzZ49+8IMf6Nxzzz3mc26++WatWbMmdt3W1uaqIK29q1f72uIBDeehDY995LWh5YhOriwck/fqi0TV1B7/dxQsYdwWAAAAAIB041gnWllZmXw+34Cus6ampgHdaYP5yEc+orq6uuN+PRAIqKioKOHDTXY0dyRczywnRBuO8exEa2zvVtQ6/nsDAAAAAIDU51iIlp2drXnz5qm2tjbh8draWi1evHjYr7NlyxYFg8Fkl5c27Js5a8aom8ptygsCyvLFOx4bxnC5gP21GecEAAAAACD9ODrOuWbNGl1xxRWaP3++Fi1apPvvv1/19fW6+uqrJR0dxdy7d68efvhhSdLdd9+tadOm6dRTT1VPT4/+4z/+Q4899pgee+wxJ78NR9U1tcc+z/Z5VTWBgGY4vF6PKoty9P6howGXeWZZstlDNMY5AQAAAABIP46GaCtWrNCBAwe0du1ahcNhzZ07V08++aSqq6slSeFwWPX19bH7e3p6dOONN2rv3r3Kzc3VqaeeqieeeEKXXHKJU9+C4w4e7ol9Pr0sX36fY82FaSdUnBsL0cKtY9eJZh8VpRMNAAAAAID047Esyxr6Nvdoa2tTcXGxWltbXXM+Wkd3n3Y0H9aRnogWnjTR6XLSxupHtui3rzVIkqZNzNNzXz1/TN7nW//9Fz38ym5J0oS8LG351rIxeR8AAAAAAHDihpsVOb6dE6OXH/Dr9CklTpeRdoLGAf/h1q5BN8OOhjkqGqQLDQAAAACAtMTsHzJWqDh+Nll3X1QHO3oGuXvkzFFRNnMCAAAAAJCeCNGQseyB1lgtFzAXC4RYKgAAAAAAQFoiREPGso9WNozBcoEjPREd6uw97nsCAAAAAID0QIiGjGXvCgu3JD9Es2/9pBMNAAAAAID0RIiGjFWcm6W8bF/suqE1+eOc9hFRzkQDAAAAACA9EaIhY3k8HgWN5QINY9CJZh8RNd8PAAAAAACkD0I0ZDSzMyw8Bp1oYaMTzeuRKosI0QAAAAAASEeEaMhoIeOg/zHpRDNes6IwR1k+fuQAAAAAAEhH/I0eGS1oHPTf2Nalvkg0qa9vjnMGWSoAAAAAAEDaIkRDRjM70aKW1NTendTXN0dEWSoAAAAAAED6IkRDRrMHW8kc6bQsK+H1QiwVAAAAAAAgbRGiIaPZRywbkrhcoO1Inzp7IvH3KqYTDQAAAACAdEWIhowWsgVb4SR2opnnoUmMcwIAAAAAkM4I0ZDRcrN9mpCXFbtO5jin/bVCLBYAAAAAACBtEaIh45ljlskc57S/FuOcAAAAAACkL0I0ZDyzQyzcmrxONHM0NNvv1cT87KS9NgAAAAAAGF+EaMh45lllDS1J7EQzQrRgcY68Xk/SXhsAAAAAAIwvQjRkPHPM8mBHj7p6I4PcPXzmOGewmPPQAAAAAABIZ4RoyHj2A//DSToXzRwNZTMnAAAAAADpjRANGc8ecCVjQ2c0ammfEcaFWCoAAAAAAEBaI0RDxrOPWiYjRNt/uFu9ESv+HiWMcwIAAAAAkM4I0ZDxKoty5DHO/E/GOGeD7TUY5wQAAAAAIL0RoiHjZfm8qiyMd4oloxPN/hqMcwIAAAAAkN4I0QAljlvau8hGwh6iMc4JAAAAAEB6I0QDlDhuGU5CJ5o5EloY8KsoJ2vUrwkAAAAAAJxDiAZIChUnjnNaljXI3UMzO9HoQgMAAAAAIP0RogGSgsaZZR09EbV19Y3q9cyR0CDnoQEAAAAAkPYI0QAN3J4Zbh3dSKc5EspmTgAAAAAA0h8hGiApZBu5HM2Gzp6+qJoPd8dfu5hxTgAAAAAA0h0hGqCBI5cNLSPf0NnY1iXzSLUgnWgAAAAAAKQ9QjRA0sT8bGX74z8OoxnntHex2bvcAAAAAABA+iFEAyR5vR4FEzZ0jrwTrcEWwIVYLAAAAAAAQNojRAM+kBiijaYTLTGAm8SZaAAAAAAApD1CNOAD5hbNcOvIO9HMUdCygmzlZPlGVRcAAAAAAHAeIRrwAXPsMtx6RNGoNcjdx2d2otkXFgAAAAAAgPREiAZ8IGgsAOiNWNrf0T2i1zFHQVkqAAAAAACAOxCiAR8wxzklKTzC5QLmKCidaAAAAAAAuAMhGvAB+xbNkSwX6OjuU+uR3vhr0okGAAAAAIArEKIBHwjaAq+GESwXMJcKSAO72wAAAAAAQHoiRAM+UJSTpcKAP3YdHkEnWoNtBJRxTgAAAAAA3IEQDTCY3WgNrSMJ0eydaIxzAgAAAADgBoRogMHsHLN3lQ2HOQLq83pUUUiIBgAAAACAGxCiAQbzDLORLBYwnzOpKEc+rycpdQEAAAAAAGcRogGGUHG8c6z5cLd6+qIn9HxzsUCwmC40AAAAAADcghANMASNTjTLkhrbTmykM2yMgLKZEwAAAAAA9yBEAwz2RQAnMtJpWZb2GvcHWSoAAAAAAIBrEKIBhlBxYvdYuHX4nWiHOnvVbYx/2l8LAAAAAACkL0I0wDDJdo5ZQ+vwO9HsXWuMcwIAAAAA4B6EaIAhJ8unsoLs2PWJjHPa72WxAAAAAAAA7kGIBtgEjTFMc1HAUOyjn3SiAQAAAADgHoRogI3ZQdZwAmeimaOfOVleTcjLSmpdAAAAAADAOYRogI3ZQXZi45zxwC1UnCuPx5PUugAAAAAAgHMI0QCbUEm8E631SK86e/qG9bywEbgFSzgPDQAAAAAANyFEA2zMM9GkxA6zwZhnooWKOQ8NAAAAAAA3IUQDbOwLAYYz0hmJWtrXFg/RgiwVAAAAAADAVQjRAJuQbRQz3Dp0iNbU3qVI1Iq/RjHjnAAAAAAAuAkhGmBTUZgjnze+FGA445z2e+zdbAAAAAAAIL0RogE2Pq9Hk4rinWTDGee032PvZgMAAAAAAOmNEA04hqAxjmkuDDge+8infTkBAAAAAABIb4RowDGYiwEahnEmmjnOWZybpfyAf0zqAgAAAAAAziBEA47BHMdsaDkiy7IGuTtxnDPIUgEAAAAAAFyHEA04hpAxjtnVG1VLZ++g95sjnywVAAAAAADAfRwP0e677z5Nnz5dOTk5mjdvnl544YVhPe+ll16S3+/Xhz70obEtEBnJ3k021EineSYaSwUAAAAAAHAfR0O0Rx99VKtXr9att96qLVu2aMmSJbr44otVX18/6PNaW1t15ZVXaunSpeNUKTKNvZvMPPPMrqs3ov2He2LXLBUAAAAAAMB9HA3R1q9fr6uuukorV67U7Nmzdffdd6uqqkobNmwY9Hlf+tKXdPnll2vRokXjVCkyjT1Es2/fNO2zbe+kEw0AAAAAAPdxLETr6enRq6++qmXLliU8vmzZMr388svHfd7PfvYz7dixQ9/+9reH9T7d3d1qa2tL+ACGMiEvSzlZ8R+PwTrR7KOeITrRAAAAAABwHcdCtP379ysSiaiysjLh8crKSu3bt++Yz6mrq9PXv/51/fznP5ff7x/W+6xbt07FxcWxj6qqqlHXDvfzeDwJYZi5fdPOHrCxWAAAAAAAAPdxfLGAx+NJuLYsa8BjkhSJRHT55ZfrO9/5jk4++eRhv/7NN9+s1tbW2MeePXtGXTMyQ9AYyxxsnDNsBGwej1RZxDgnAAAAAABuM7x2rjFQVlYmn883oOusqalpQHeaJLW3t2vz5s3asmWLvvzlL0uSotGoLMuS3+/XH/7wB11wwQUDnhcIBBQIBMbmm4CrJXaiDTbOGf9aeUFA2X7Hs2kAAAAAAJBkjv1tPzs7W/PmzVNtbW3C47W1tVq8ePGA+4uKivTmm2/qtddei31cffXVmjVrll577TUtXLhwvEpHhggaY5n72roUiVrHvM8c9QwyygkAAAAAgCs51okmSWvWrNEVV1yh+fPna9GiRbr//vtVX1+vq6++WtLRUcy9e/fq4Ycfltfr1dy5cxOeX1FRoZycnAGPA8kQKo6PZUailprbuzWpeOCopjnqGTrG1wEAAAAAQPpzNERbsWKFDhw4oLVr1yocDmvu3Ll68sknVV1dLUkKh8Oqr693skRkMPuCgIbWI8cO0YxRT5YKAAAAAADgTh7Lso49o+ZSbW1tKi4uVmtrq4qKipwuBylse1O7Llz/fOz63svP1P87PZRwT1tXr06/7Q+x629cOlsrl5w0bjUCAAAAAIDRGW5WxAnowHEEixO7ysLHWC5gf4xONAAAAAAA3IkQDTiO/IBfxblZsesG4+yz4z1GiAYAAAAAgDsRogGDCBpnoJlbOI/3GIsFAAAAAABwJ0I0YBBmZ1m4dfBxziyfR2UFgXGpCwAAAAAAjC9CNGAQoRKzE21giGaOc04qzpHX6xmXugAAAAAAwPgiRAMGYS4X2H+4W919kYSvm+Oc9kUEAAAAAADAPQjRgEGYnWiStM820mmOeHIeGgAAAAAA7kWIBgwiZOsuM0c6o1ErMURjMycAAAAAAK5FiAYMwh6MmeObBzp61NMXjV0HCdEAAAAAAHAtQjRgEJVFOfIYuwLCxiIB83OJcU4AAAAAANyMEA0YRLbfq/KCQOy6wRjftG/rZJwTAAAAAAD3IkQDhmCOaZrjnObn0sDz0wAAAAAAgHsQogFDMMc0w0b3mTnOmZftU1Guf1zrAgAAAAAA44cQDRiCOabZYARnDbbNnB7z8DQAAAAAAOAqhGjAEIJGJ1p7V5/au3olJY5zBlkqAAAAAACAqxGiAUOwLwwIf9CBZo52ch4aAAAAAADuRogGDMEeojW0HFFvJKqm9q7j3gMAAAAAANyFEA0YQsg2qtnQ0qXGti5FrfhjwRLGOQEAAAAAcDNCNGAIZQUBZfniSwPCrUdiI539GOcEAAAAAMDdCNGAIXi9Hk0yutEaWroSlgpIUohONAAAAAAAXI0QDRiGoNFp1tByRA0tXcf9OgAAAAAAcB9CNGAYzHPRjo5zxjvRJuRlKTfb50RZAAAAAABgnBCiAcNgbt9saO3S3kNHjvk1AAAAAADgToRowDAEjaCspy+qvzS0xr/GKCcAAAAAAK5HiAYMgznOKUmNbd3xr7FUAAAAAAAA1yNEA4ZhsJFNxjkBAAAAAHA/QjRgGEKDjGwGi+lEAwAAAADA7QjRgGEoyvUr7zgbOCfTiQYAAAAAgOsRogHD4PF4jju2GSREAwAAAADA9QjRgGE61tim1yNVFgYcqAYAAAAAAIwnQjRgmI41tllZlCO/jx8jAAAAAADcjr/9A8MUPMZyAZYKAAAAAACQGQjRgGEKlgwMzDgPDQAAAACAzECIBgzTscY52cwJAAAAAEBmIEQDhulYo5uMcwIAAAAAkBkI0YBhOvaZaHSiAQAAAACQCQjRgGHKzfapND874THGOQEAAAAAyAyEaMAJsI9vHmvZAAAAAAAAcB9CNOAEmOOb2X6vJto60wAAAAAAgDsRogEnYE6wMPb57EmF8ng8DlYDAAAAAADGi9/pAoB08tnF0/T6+61qau/WLZfMdrocAAAAAAAwTgjRgBMwsSCgf/vCh50uAwAAAAAAjDPGOQEAAAAAAIAhEKIBAAAAAAAAQyBEAwAAAAAAAIZAiAYAAAAAAAAMgRANAAAAAAAAGAIhGgAAAAAAADAEQjQAAAAAAABgCIRoAAAAAAAAwBAI0QAAAAAAAIAhEKIBAAAAAAAAQyBEAwAAAAAAAIZAiAYAAAAAAAAMgRANAAAAAAAAGAIhGgAAAAAAADAEQjQAAAAAAABgCIRoAAAAAAAAwBAI0QAAAAAAAIAhEKIBAAAAAAAAQyBEAwAAAAAAAIZAiAYAAAAAAAAMgRANAAAAAAAAGILf6QLGm2VZkqS2tjaHKwEAAAAAAIDT+jOi/szoeDIuRGtvb5ckVVVVOVwJAAAAAAAAUkV7e7uKi4uP+3WPNVTM5jLRaFQNDQ0qLCyUx+NxupykaGtrU1VVlfbs2aOioiKnywEgfi6BVMTPJZBa+JkEUg8/l8hUlmWpvb1doVBIXu/xTz7LuE40r9erKVOmOF3GmCgqKuI/dECK4ecSSD38XAKphZ9JIPXwc4lMNFgHWj8WCwAAAAAAAABDIEQDAAAAAAAAhkCI5gKBQEDf/va3FQgEnC4FwAf4uQRSDz+XQGrhZxJIPfxcAoPLuMUCAAAAAAAAwImiEw0AAAAAAAAYAiEaAAAAAAAAMARCNAAAAAAAAGAIhGgAAAAAAADAEAjRXOC+++7T9OnTlZOTo3nz5umFF15wuiQgY912223yeDwJH5MmTXK6LCBjPP/88/rYxz6mUCgkj8ej3/72twlftyxLt912m0KhkHJzc/VXf/VXeuutt5wpFsgQQ/1cfu5znxvwu/MjH/mIM8UCGWDdunVasGCBCgsLVVFRoeXLl+udd95JuIffl8CxEaKluUcffVSrV6/Wrbfeqi1btmjJkiW6+OKLVV9f73RpQMY69dRTFQ6HYx9vvvmm0yUBGaOjo0NnnHGG7r333mN+/c4779T69et17733atOmTZo0aZIuuugitbe3j3OlQOYY6udSkj760Y8m/O588sknx7FCILNs3LhR11xzjf74xz+qtrZWfX19WrZsmTo6OmL38PsSODaPZVmW00Vg5BYuXKizzjpLGzZsiD02e/ZsLV++XOvWrXOwMiAz3Xbbbfrtb3+r1157zelSgIzn8Xj0m9/8RsuXL5d09P+qh0IhrV69Wl/72tckSd3d3aqsrNT3v/99felLX3KwWiAz2H8upaOdaC0tLQM61ACMj+bmZlVUVGjjxo0699xz+X0JDIJOtDTW09OjV199VcuWLUt4fNmyZXr55ZcdqgpAXV2dQqGQpk+frs985jPauXOn0yUBkPTee+9p3759Cb83A4GAzjvvPH5vAg577rnnVFFRoZNPPllf/OIX1dTU5HRJQMZobW2VJJWWlkri9yUwGEK0NLZ//35FIhFVVlYmPF5ZWal9+/Y5VBWQ2RYuXKiHH35Yv//97/Wv//qv2rdvnxYvXqwDBw44XRqQ8fp/N/J7E0gtF198sX7+85/rmWee0V133aVNmzbpggsuUHd3t9OlAa5nWZbWrFmjc845R3PnzpXE70tgMH6nC8DoeTyehGvLsgY8BmB8XHzxxbHPTzvtNC1atEgzZszQv/3bv2nNmjUOVgagH783gdSyYsWK2Odz587V/PnzVV1drSeeeEKf/OQnHawMcL8vf/nLeuONN/Tiiy8O+Bq/L4GB6ERLY2VlZfL5fAP+b0BTU9OA/2sAwBn5+fk67bTTVFdX53QpQMbr35TL700gtQWDQVVXV/O7ExhjX/nKV/T444/r2Wef1ZQpU2KP8/sSOD5CtDSWnZ2tefPmqba2NuHx2tpaLV682KGqAJi6u7u1bds2BYNBp0sBMt706dM1adKkhN+bPT092rhxI783gRRy4MAB7dmzh9+dwBixLEtf/vKX9etf/1rPPPOMpk+fnvB1fl8Cx8c4Z5pbs2aNrrjiCs2fP1+LFi3S/fffr/r6el199dVOlwZkpBtvvFEf+9jHNHXqVDU1Nem73/2u2tra9NnPftbp0oCMcPjwYW3fvj12/d577+m1115TaWmppk6dqtWrV+t73/ueampqVFNTo+9973vKy8vT5Zdf7mDVgLsN9nNZWlqq2267TZ/61KcUDAa1a9cu3XLLLSorK9MnPvEJB6sG3Ouaa67Rf/7nf+q///u/VVhYGOs4Ky4uVm5urjweD78vgePwWJZlOV0ERue+++7TnXfeqXA4rLlz5+qHP/yhzj33XKfLAjLSZz7zGT3//PPav3+/ysvL9ZGPfES333675syZ43RpQEZ47rnndP755w94/LOf/aweeughWZal73znO/rJT36iQ4cOaeHChfqXf/mX2GHKAJJvsJ/LDRs2aPny5dqyZYtaWloUDAZ1/vnn6/bbb1dVVZUD1QLud7xzzX72s5/pc5/7nCTx+xI4DkI0AAAAAAAAYAiciQYAAAAAAAAMgRANAAAAAAAAGAIhGgAAAAAAADAEQjQAAAAAAABgCIRoAAAAAAAAwBAI0QAAAAAAAIAhEKIBAAAAAAAAQyBEAwAAAAAAAIZAiAYAAIBhe+655+TxeNTS0uJ0KQAAAOOKEA0AAAAAAAAYAiEaAAAAAAAAMARCNAAAgDRiWZbuvPNOnXTSScrNzdUZZ5yhX/3qV5Lio5ZPPPGEzjjjDOXk5GjhwoV68803E17jscce06mnnqpAIKBp06bprrvuSvh6d3e3brrpJlVVVSkQCKimpkYPPPBAwj2vvvqq5s+fr7y8PC1evFjvvPPO2H7jAAAADiNEAwAASCPf+MY39LOf/UwbNmzQW2+9peuvv15///d/r40bN8bu+epXv6of/OAH2rRpkyoqKvTxj39cvb29ko6GX5dddpk+85nP6M0339Rtt92mb37zm3rooYdiz7/yyiv1yCOP6Ec/+pG2bdumH//4xyooKEio49Zbb9Vdd92lzZs3y+/36wtf+MK4fP8AAABO8ViWZTldBAAAAIbW0dGhsrIyPfPMM1q0aFHs8ZUrV6qzs1P/8A//oPPPP1+PPPKIVqxYIUk6ePCgpkyZooceekiXXXaZ/u7v/k7Nzc36wx/+EHv+TTfdpCeeeEJvvfWW3n33Xc2aNUu1tbW68MILB9Tw3HPP6fzzz9dTTz2lpUuXSpKefPJJXXrppTpy5IhycnLG+J8CAACAM+hEAwAASBNbt25VV1eXLrroIhUUFMQ+Hn74Ye3YsSN2nxmwlZaWatasWdq2bZskadu2bTr77LMTXvfss89WXV2dIpGIXnvtNfl8Pp133nmD1nL66afHPg8Gg5KkpqamUX+PAAAAqcrvdAEAAAAYnmg0Kkl64oknNHny5ISvBQKBhCDNzuPxSDp6plr/5/3MwYTc3Nxh1ZKVlTXgtfvrAwAAcCM60QAAANLEnDlzFAgEVF9fr5kzZyZ8VFVVxe774x//GPv80KFDevfdd3XKKafEXuPFF19MeN2XX35ZJ598snw+n0477TRFo9GEM9YAAABAJxoAAEDaKCws1I033qjrr79e0WhU55xzjtra2vTyyy+roKBA1dXVkqS1a9dq4sSJqqys1K233qqysjItX75cknTDDTdowYIFuv3227VixQq98soruvfee3XfffdJkqZNm6bPfvaz+sIXvqAf/ehHOuOMM7R79241NTXpsssuc+pbBwAAcBwhGgAAQBq5/fbbVVFRoXXr1mnnzp0qKSnRWWedpVtuuSU2TnnHHXfouuuuU11dnc444ww9/vjjys7OliSdddZZ+q//+i9961vf0u23365gMKi1a9fqc5/7XOw9NmzYoFtuuUWrVq3SgQMHNHXqVN1yyy1OfLsAAAApg+2cAAAALtG/OfPQoUMqKSlxuhwAAABX4Uw0AAAAAAAAYAiEaAAAAAAAAMAQGOcEAAAAAAAAhkAnGgAAAAAAADAEQjQAAAAAAABgCIRoAAAAAAAAwBAI0QAAAAAAAIAhEKIBAAAAAAAAQyBEAwAAAAAAAIZAiAYAAAAAAAAMgRANAAAAAAAAGML/D8eax5vp9+nGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/3330063544.py:38: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(generator_test)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.load_model(weight)\n",
    "evaluate_(model, generator_test)\n",
    "plot_graphs(history, generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b2432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
